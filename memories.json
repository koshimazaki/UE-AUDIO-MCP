{
  "memories": [
    {
      "id": "mem_1770385162176_1q1l3g5xr",
      "content": "## UE5-WWISE Project - Complete Exploration Summary\n\n### Project Overview\n- **Name**: UE Audio MCP (Unreal Engine Audio MCP Server)\n- **Creator**: Koshi (creator of SIDKIT, VibeComfy MCP)\n- **Status**: Early development, building in public\n- **Phase**: Research and planning phase (no implementation code yet)\n- **Goal**: Build complete game audio systems from natural language descriptions using MCP protocol\n\n### Architecture\nThe project applies SIDKIT's agent-generated audio systems philosophy to game engines. Three-layer architecture:\n1. **Blueprint** (WHEN) - Game event detection, parameter setting - UE5 Remote Control API\n2. **MetaSounds** (WHAT) - Procedural DSP synthesis, audio generation - Builder API via plugin\n3. **Wwise** (HOW) - Mixing, buses, spatialization, RTPC - WAAPI (WebSocket :8080)\n\n### File Tree Structure\n```\n/UE5-WWISE/\n├── README.md (11k) - Project vision, architecture, tool groups\n├── ROADMAP.md (9.5k) - 5-phase development plan with dependencies\n├── .gitignore - Standard Python, Node, UE5 ignores\n├── research/ - Research documentation (80KB total)\n│   ├── research_waapi_mcp_server.md (69KB) - Complete WAAPI API reference, 87 functions\n│   └── research_metasounds_game_audio.md (11KB) - MetaSounds patterns and Builder API\n├── src/ - (Directory structure only, no files yet)\n│   ├── tools/\n│   │   ├── wwise/\n│   │   ├── metasounds/\n│   │   └── blueprints/\n│   ├── knowledge/\n│   ├── protocol/\n│   └── systems/\n├── templates/ - (Empty directory)\n├── tests/ - (Empty directory)\n├── .claude/ - (Claude workspace, empty)\n├── logs/ - Application logs (LMStudio health checks)\n└── memories.json - (Empty memories file)\n```\n\n### Git History\n- Commit 5c984e6: \"Add research files, .gitignore, and project structure\" (latest)\n- Commit 33ba52d: \"Initial project setup: UE Audio MCP\"\n- Branch: master (up to date with origin)\n- Untracked: memories.json\n\n### Key MCP Servers Referenced\n1. **SIDKIT** - Hardware synthesis agent, generates C++ firmware for Teensy ARM\n2. **VibeComfy MCP** - ComfyUI nodes (8,400+ nodes) via MCP\n3. **Blender MCP** - Controls Blender via MCP (16.9k stars reference)\n4. **unreal-mcp** - Controls UE5 editor (chongdashu) - no audio support\n\n### Research Documentation Summary\n\n#### WAAPI (Wwise Authoring API)\n- **Protocol**: WAMP (WebSocket) on ws://127.0.0.1:8080/waapi or HTTP POST on :8090\n- **Status**: 87+ API functions, fully documented\n- **Libraries**: waapi-client (official Python), pywwise (Pythonic wrapper)\n- **Key limitation**: Wwise Authoring App MUST be running (no true headless mode)\n- **Functions**:\n  - Object CRUD: create, delete, get, move, copy, setProperty, setReference\n  - Audio import with multiple operation modes (createNew, useExisting, replaceExisting)\n  - Switch containers and state groups with assignments\n  - RTPC curve management\n  - Attenuation curve configuration\n  - SoundBank generation\n  - Transport control for previewing\n  - WAQL (Wwise Authoring Query Language) for object search\n\n#### MetaSounds & Builder API\n- **Asset types**: Source (playable), Patch (reusable subgraph), Preset (parameter overrides)\n- **Graph model**: Flow graph with sample-accurate timing, signal-by-reference\n- **Data types**: Audio, Trigger, Float, Int32, Bool, Time, String, UObject, Enum, WaveAsset, Arrays\n- **80+ nodes**: Generators, Wave Players, Envelopes, Filters, Delays, Dynamics, Triggers, Arrays, Math, Mix, Spatialization, Music, Random\n- **Builder API**: Experimental (UE 5.4+), enables runtime graph creation\n- **Key interfaces**: UE.Source.OneShot, UE.Attenuation, UE.Spatialization\n- **Six game audio patterns**: Gunshots, Footsteps, Ambient, Spatial (Panning), UI Sounds, Weather/State Switches\n\n#### Audio Link Bridge\n- **Purpose**: Enables MetaSounds + Wwise coexistence (UE 5.1+)\n- **Direction**: One-way only (MetaSounds → Wwise via Audio Input Events)\n- **Use**: Procedural audio synthesis through Wwise mixing pipeline\n\n### A2HW Protocol (Agent-to-Hardware)\n- **Purpose**: Shared language between SIDKIT and UE Audio MCP\n- **Concept**: One synthesis description maps to multiple targets:\n  - SIDKIT: SysEx → Teensy ARM (hardware synth)\n  - Browser: JS → ModuleRunner (web preview)\n  - MetaSounds: Builder API → UE5 (game engine)\n  - Wwise: WAAPI → mixing pipeline (middleware)\n- **Status**: Planned Phase 5 (spec and standardization)\n\n### Development Roadmap (5 Phases)\n1. **Phase 1 (Weekend)**: Wwise MCP standalone via WAAPI\n2. **Phase 2 (1-2 days)**: MetaSounds knowledge base (node database)\n3. **Phase 3 (1 week)**: UE5 audio plugin (Builder API bridge)\n4. **Phase 4 (1-2 weeks)**: Systems orchestration layer\n5. **Phase 5 (Ongoing)**: A2HW protocol specification and standardization\n\n### Tech Stack\n- **MCP Server**: Python (FastMCP)\n- **Wwise Bridge**: waapi-client (official Audiokinetic Python library)\n- **UE5 Bridge**: Custom C++ plugin with TCP server (Builder API + Remote Control)\n- **Knowledge Base**: JSON node databases\n- **Templates**: Parameterized patterns for common game audio systems\n\n### Higher-Level Tool Groups\n**Systems Layer** (Phase 4 - orchestrates all three):\n- build_system - Generic audio system from text description\n- build_footsteps - Complete surface-reactive footstep system\n- build_weapon_audio - Gunshot + shell + tail + distance\n- build_ambient - Zone-based ambient with layers\n- build_ui_audio - Procedural UI sound set\n- build_weather - State-driven weather audio system\n\n### Important Notes\n- **No existing Wwise MCP server** - This would be first-of-its-kind\n- **No existing MetaSounds MCP integration** - Gap confirmed\n- **SIDKIT inspiration**: Same 3-layer architecture philosophy applied to game engines\n- **Lyra Starter Game**: Reference implementation for MetaSounds patterns\n- **Builder API experimental**: May change between UE versions\n- **AudioLink setup**: MetaSounds side requires custom patches, UE5 side requires Wwise Audio Input Events\n\n### Current Project State\n- Research phase complete (80KB+ of detailed documentation)\n- Directory structure created but empty (src/, templates/, tests/, .claude/)\n- No implementation code yet\n- Ready for Phase 1 (Wwise MCP) development\n- All dependencies and APIs researched and documented\n",
      "type": "config",
      "tags": [
        "config",
        "python",
        "api",
        "database",
        "UE5-WWISE",
        "MCP-servers",
        "audio-systems",
        "game-audio",
        "architecture",
        "WAAPI",
        "MetaSounds",
        "project-structure"
      ],
      "timestamp": "2026-02-06T13:39:22.175Z",
      "context": "Exploration of UE5-WWISE project at /Users/radek/Documents/GIthub/UE5-WWISE",
      "accessCount": 1,
      "lastAccessed": "2026-02-07T01:33:25.182Z",
      "lastVerified": "2026-02-06T13:39:22.175Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770385395012_sc5fsab52",
      "content": "UE5-WWISE project setup complete. Created .claude/CLAUDE.md (main prompt), 3 slash commands (/ue-agent, /wwise-agent, /build-system), settings.json, and auto memory. Project builds first MCP server for game audio — Wwise + MetaSounds + Blueprint pipeline from natural language. Phase 1 (Wwise MCP) ready to start coding with waapi-client Python library.",
      "type": "config",
      "tags": [
        "config",
        "python",
        "ue5-wwise",
        "project-setup",
        "mcp",
        "game-audio"
      ],
      "timestamp": "2026-02-06T13:43:15.012Z",
      "context": "Initial project agent setup for UE Audio MCP",
      "accessCount": 1,
      "lastAccessed": "2026-02-07T01:33:25.182Z",
      "lastVerified": "2026-02-06T13:43:15.012Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770385564956_5k72eql7d",
      "content": "## SIDKIT Agent Architecture - Complete Reference\n\n### Project Overview\nSIDKIT Agent is a Rust-based LLM-powered C++ code generation system for the SIDKIT synthesizer platform (Teensy 4.1). It features:\n- Agentic tool-use loop with Claude API\n- Autonomous GCC compilation & error fixing\n- Teensy hardware flashing via USB\n- SQLite-based learning (error patterns, build history)\n- Semantic knowledge base search\n- Dual-mode operation: Full agent server vs. LLM-agnostic tool server\n\n### Tech Stack\n- **Language**: Rust 2021 edition\n- **LLM**: Claude API (Haiku/Sonnet/Opus models)\n- **Web Framework**: Axum 0.7 (async HTTP)\n- **Compilation**: arm-none-eabi-gcc wrapper\n- **Hardware**: teensy_loader_cli for flashing\n- **Storage**: SQLite with rusqlite\n- **Serialization**: serde/serde_json\n\n### File Structure\n```\nsidkit-agent/\n├── src/\n│   ├── main.rs                  # CLI entry (Serve/Tools/Build/Flash/Devices)\n│   ├── agent.rs                 # Core agent + ToolExecutor impl\n│   ├── llm/\n│   │   ├── mod.rs              # Exports\n│   │   ├── claude.rs           # Agentic loop, API calls\n│   │   ├── tools.rs            # Tool defs + knowledge types\n│   │   └── prompts.rs          # System prompts, templates\n│   ├── server/\n│   │   ├── mod.rs              # Exports\n│   │   ├── http.rs             # Agentic server (Axum)\n│   │   └── tools.rs            # Pure tool server (no LLM)\n│   ├── knowledge/\n│   │   ├── mod.rs              # SDK reference constants\n│   │   └── base.rs             # Semantic search, JSON loading\n│   ├── storage/\n│   │   ├── mod.rs              # Exports\n│   │   └── db.rs               # SQLite wrapper\n│   ├── toolchain/\n│   │   ├── mod.rs              # Exports\n│   │   ├── gcc.rs              # arm-none-eabi-gcc wrapper\n│   │   └── errors.rs           # Error parsing\n│   └── flasher/\n│       ├── mod.rs              # Exports\n│       ├── teensy.rs           # USB bootloader\n│       └── intel_hex.rs        # HEX file parsing\n├── knowledge/                   # JSON knowledge base\n│   ├── games.json\n│   ├── patches.json\n│   ├── synthesis.json\n│   └── inspirations.json\n├── templates/                   # (empty, templates in code)\n├── migrations/                  # (empty)\n├── scripts/\n│   └── create-macos-app.sh     # macOS menubar build\n├── Cargo.toml\n└── README.md\n```\n\n### Core Components\n\n#### 1. Agent Loop (src/agent.rs)\n- **SidkitAgent**: Main agent orchestrating tools\n- **BuildSession**: Tracks state during build\n- **ToolExecutor trait**: Executes tools for LLM\n- Tools: generate_code, compile, search_knowledge, read_sdk, search_patterns, flash, report_status, complete\n\n#### 2. LLM Client (src/llm/claude.rs)\n- **AgenticClient**: Manages API calls & tool loops\n- **Models**: Haiku, Sonnet, Opus with model IDs\n- **Tool loop**: Call → Get blocks → Execute → Feedback → Repeat\n- System prompt includes SDK reference\n- Max iterations: 10 (configurable)\n\n#### 3. Tool Definitions (src/llm/tools.rs)\n- 8 tools exposed to Claude\n- **Knowledge types**: 19 categories (patches, templates, sdk, synthesis, games, shaders, algorithms, chips, engines, design, inspirations, guides, schemas, patterns, effects, ui-ux, platform, webui, faq)\n- **Metadata**: difficulty, cpu_cost, dependencies, voice_count, author, source\n- Search: embedding-based (if available) + keyword + tag matching\n\n#### 4. HTTP Servers (src/server/)\n\n**Full Agent Server** (/serve):\n- /build (POST) - Start agentic build\n- /build/:id/status - Get status\n- /build/:id/events - Stream events\n- /build/:id/download - Get hex\n- /flash, /devices, /history\n\n**Pure Tool Server** (/tools):\n- /compile (POST) - GCC compile only\n- /flash (POST) - Flash hex\n- /pio/build, /pio/upload - PlatformIO\n- /search (GET) - Knowledge API proxy\n- /doc/:id (GET) - Fetch doc\n- /devices - List Teensy\n\n#### 5. Knowledge Base (src/knowledge/)\n- **SDK constants**: IModule, Display (Adafruit GFX), Audio (48kHz), MIDI, Events, Examples, Templates\n- **File format**: MCP-server JSON with title, category, description, tags, content\n- **Search**: Loads from ~/.sidkit-agent/knowledge/ (or custom dir)\n- Categories indexed by hash maps\n\n#### 6. Storage (src/storage/db.rs)\n- **Location**: ~/.sidkit-agent/sidkit.db (SQLite)\n- **Tables**: \n  - builds (id, prompt, module_type, attempts, final_code, success, duration_ms, created_at)\n  - error_patterns (error_signature, successful_fix, fix_explanation, occurrences, successes)\n- **Auto-learning**: Patterns stored after successful fixes\n\n#### 7. Toolchain (src/toolchain/gcc.rs)\n- **Compiler**: arm-none-eabi-gcc (Cortex-M7)\n- **Flags**: -std=c++17, -O2, cortex-m7, thumb, hard float\n- **Error parsing**: Regex-based GCC output parsing\n- **Output**: firmware.hex (linker step handled externally)\n- **Includes**: SIDKIT_FIRMWARE_PATH env var for SDK headers\n\n#### 8. Flasher (src/flasher/teensy.rs)\n- **Protocol**: teensy_loader_cli binary\n- **USB IDs**: 0x16C0 vendor, 0x0478 bootloader, 0x0476 running\n- **Method**: Looks for teensy_loader_cli in PATH, Homebrew, Teensyduino\n- **Input**: .hex file path\n- **Features**: List devices, detect bootloader, reboot to bootloader\n\n### Agent Execution Flow\n1. User calls `build` with prompt\n2. Agent creates BuildSession\n3. LLM loop (0-10 iterations):\n   - Send prompt + SDK + tools to Claude\n   - Claude picks tool(s) to call\n   - Agent executes tool (generate_code → write file → compile → parse errors)\n   - Feed results back to Claude\n   - Handle special tools: generate_code, compile, complete (signal finish)\n4. Store result: SQLite build record + error patterns learned\n5. Return BuildResult::Success or Failed\n\n### System Prompts & Templates\n**Three module types**:\n- Game (SlotType::ADVANCED, 25 CPU bits, 0 voices)\n- Synth (SlotType::SYNTH, 10 CPU bits, 4 voices, MIDI)\n- Sequencer (SlotType::SEQUENCER, 5 CPU bits, pattern trigger)\n\nTemplates include:\n- Full class structure with virtual methods\n- Example parameter handling\n- Display/MIDI/event handling skeletons\n\n### Knowledge Base Structure\n**Format**: JSON array of entries:\n```json\n{\n  \"id\": \"game-space-shooter\",\n  \"category\": \"games\",\n  \"title\": \"Space Shooter\",\n  \"description\": \"...\",\n  \"content\": \"// C++ code ...\",\n  \"tags\": [\"game\", \"shooter\"],\n  \"metadata\": {\"difficulty\": \"intermediate\", \"cpu_cost\": \"low\"}\n}\n```\n\n### CLI Commands\n```bash\nsidkit-agent serve --port 3001              # Full agentic server\nsidkit-agent tools --port 3002              # Tool server only\nsidkit-agent build \"prompt\" --model haiku   # Agentic CLI build\nsidkit-agent flash firmware.hex             # Flash hex directly\nsidkit-agent devices                        # List Teensy devices\nsidkit-agent history --limit 10             # Build history\nsidkit-agent models                         # Show available models\n```\n\n### Environment Variables\n- ANTHROPIC_API_KEY - Claude API auth\n- SIDKIT_FIRMWARE_PATH - Path to firmware SDK\n- RUST_LOG - Logging level\n\n### Key Design Patterns\n1. **Async throughout**: tokio for concurrency\n2. **Error learning**: Auto-stores fixes in DB\n3. **Semantic search**: Embedding + keyword fallback\n4. **Streaming events**: AgentEvent enum for UI\n5. **Dual servers**: Flexible deployment (agent-only or tool-only)",
      "type": "config",
      "tags": [
        "config",
        "rust",
        "c++",
        "api",
        "deployment",
        "sidkit",
        "architecture",
        "llm",
        "agent",
        "reference"
      ],
      "timestamp": "2026-02-06T13:46:04.956Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T13:46:04.956Z",
      "lastVerified": "2026-02-06T13:46:04.956Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770385795551_sf7oos6bn",
      "content": "UE MCP Landscape Research (2026-02-06):\n\nKEY REPOS:\n1. chongdashu/unreal-mcp (1,370 stars) - Leader. C++ plugin + Python FastMCP. TCP port 55557. Tools: blueprint, editor, node, project, umg. No audio.\n2. flopperam/unreal-engine-mcp (431 stars) - 40+ tools, blueprint analysis, 3D gen. No audio.\n3. kvick-games/UnrealMCP (493 stars) - Basic, inspired by blender-mcp. MetaSound on roadmap.\n4. runreal/unreal-mcp (70 stars) - NO PLUGIN needed, uses UE built-in Python remote execution. TypeScript MCP server.\n5. BilkentAudio/Wwise-MCP (23 stars) - Wwise-only MCP via WAAPI. Python/FastMCP. Comprehensive WAAPI wrapper in wwise_python_lib.py. Plan execution pattern.\n6. ahujasid/blender-mcp (16,899 stars) - Gold standard architecture. Two components: addon (socket server in Blender) + MCP server (FastMCP). JSON over TCP.\n\nDECISION: Build from scratch, NOT fork. Reasons:\n- No existing project combines Wwise + MetaSounds + Blueprint audio\n- Forking means maintaining 80% code we don't need + adding 100% audio code ourselves\n- Adopt PATTERNS not codebases: blender-mcp two-component architecture, chongdashu modular tools, BilkentAudio WAAPI wrapper reference, runreal plugin-free approach for Blueprints\n\nARCHITECTURE:\n- Python FastMCP server with 3 communication channels:\n  1. WAAPI WebSocket (port 8080) -> Wwise\n  2. TCP Socket (port 9877) -> Custom C++ UE Plugin (for MetaSounds Builder API)\n  3. Python Remote Execution -> UE5 Editor (for Blueprint tools, NO plugin needed)",
      "type": "warning",
      "tags": [
        "warning",
        "python",
        "typescript",
        "api",
        "architecture",
        "research",
        "unreal-mcp",
        "wwise-mcp",
        "decision"
      ],
      "timestamp": "2026-02-06T13:49:55.551Z",
      "context": "Research for UE5-WWISE project - deciding build vs fork strategy for game audio MCP server",
      "accessCount": 1,
      "lastAccessed": "2026-02-07T01:33:25.182Z",
      "lastVerified": "2026-02-06T13:49:55.551Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770386499116_3irvp8eno",
      "content": "UE5-WWISE Knowledge Architecture Decision (2026-02-06):\n- Cloudflare D1 for structured knowledge storage (6 tables: metasound_nodes, waapi_functions, wwise_types, audio_patterns, error_patterns, ue_game_examples)\n- Cloudflare Vectorize for semantic search (embeddings over same D1 data)\n- Two search paths: agent queries by TYPE (D1 SQL) or by MEANING (Vectorize embeddings)\n- Share Cloudflare infrastructure with SIDKIT (same account, reuse embedding pipeline)\n- Error learning: SIDKIT pattern — store error_signature + successful_fix in D1, query before generating\n- All UE5 tools (MetaSounds + Blueprint) route through single C++ plugin on port 9877 (not split across Python remote exec)",
      "type": "error",
      "tags": [
        "error",
        "python",
        "ue5-wwise",
        "architecture",
        "cloudflare",
        "d1",
        "vectorize",
        "knowledge-base"
      ],
      "timestamp": "2026-02-06T14:01:39.116Z",
      "context": "Architecture decision for UE Audio MCP knowledge storage",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T14:01:39.116Z",
      "lastVerified": "2026-02-06T14:01:39.116Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770388164433_6bifylmv5",
      "content": "WAAPI Python Code Examples - Exact Implementations\n\n1. WAAPI CONNECTION (waapi-client):\n```python\nfrom waapi import WaapiClient, CannotConnectToWaapiException\nwith WaapiClient() as client:\n    info = client.call(\"ak.wwise.core.getInfo\")\n    handler = client.subscribe(\"ak.wwise.core.object.created\", lambda obj: print(obj))\n```\n\n2. CREATE_OBJECT (ak.wwise.core.object.create):\n```python\nresult = client.call(\"ak.wwise.core.object.create\", {\n    \"parent\": \"\\\\Actor-Mixer Hierarchy\\\\Default Work Unit\",\n    \"type\": \"RandomSequenceContainer\",\n    \"name\": \"Gunshot_Variations\",\n    \"onNameConflict\": \"merge\"\n})\ncontainer_id = result[\"id\"]\n```\n\n3. SET_PROPERTY (ak.wwise.core.object.setProperty):\n```python\nclient.call(\"ak.wwise.core.object.setProperty\", {\n    \"object\": \"\\\\Actor-Mixer Hierarchy\\\\Default Work Unit\\\\Weapons\",\n    \"property\": \"Volume\",\n    \"value\": -3.0\n})\n```\n\n4. SET_REFERENCE (ak.wwise.core.object.setReference):\n```python\nclient.call(\"ak.wwise.core.object.setReference\", {\n    \"object\": \"\\\\Actor-Mixer Hierarchy\\\\Default Work Unit\\\\Weapons\",\n    \"reference\": \"OutputBus\",\n    \"value\": \"\\\\Master-Mixer Hierarchy\\\\Default Work Unit\\\\Master Audio Bus\\\\SFX\"\n})\n```\n\n5. IMPORT_AUDIO (ak.wwise.core.audio.import):\n```python\nresult = client.call(\"ak.wwise.core.audio.import\", {\n    \"importOperation\": \"useExisting\",\n    \"default\": {\"importLanguage\": \"SFX\"},\n    \"imports\": [\n        {\"audioFile\": \"C:\\\\Audio\\\\rifle_shot_01.wav\",\n         \"objectPath\": \"\\\\Actor-Mixer Hierarchy\\\\Default Work Unit\\\\Weapons\\\\Gunshot_Rifle\\\\<Sound>Rifle_Shot_01\"}\n    ]\n})\n```\n\n6. CREATE_EVENT (ak.wwise.core.object.create with Action child):\n```python\nevent_result = client.call(\"ak.wwise.core.object.create\", {\n    \"parent\": \"\\\\Events\\\\Default Work Unit\",\n    \"type\": \"Event\",\n    \"name\": \"Play_Gunshot_Rifle\",\n    \"onNameConflict\": \"merge\",\n    \"children\": [{\n        \"type\": \"Action\",\n        \"name\": \"\",\n        \"@ActionType\": 1,\n        \"@Target\": \"\\\\Actor-Mixer Hierarchy\\\\Default Work Unit\\\\Weapons\\\\Gunshot_Rifle\"\n    }]\n})\n```\n\n7. ASSIGN_SWITCH (ak.wwise.core.switchContainer.addAssignment):\n```python\nclient.call(\"ak.wwise.core.switchContainer.addAssignment\", {\n    \"child\": child_object_id,\n    \"stateOrSwitch\": switch_value_id\n})\n```\n\n8. SET_ATTENUATION (ak.wwise.core.object.setAttenuationCurve):\n```python\nclient.call(\"ak.wwise.core.object.setAttenuationCurve\", {\n    \"object\": attenuation_id,\n    \"curveType\": \"VolumeDryUsage\",\n    \"use\": \"Custom\",\n    \"points\": [\n        {\"x\": 0, \"y\": 0, \"shape\": \"Linear\"},\n        {\"x\": 50, \"y\": -6, \"shape\": \"Linear\"},\n        {\"x\": 100, \"y\": -200, \"shape\": \"Exp3\"}\n    ]\n})\n```\n\n9. SET_RTPC/GENERATE BANKS (ak.wwise.core.soundbank.setInclusions/generate):\n```python\nclient.call(\"ak.wwise.core.soundbank.setInclusions\", {\n    \"soundbank\": soundbank_id,\n    \"operation\": \"add\",\n    \"inclusions\": [{\"object\": event_id, \"filter\": [\"events\", \"structures\", \"media\"]}]\n})\nclient.call(\"ak.wwise.core.soundbank.generate\", {\n    \"soundbanks\": [{\"name\": \"Weapons_Bank\"}]\n})\n```\n\n10. TRANSPORT/PREVIEW (ak.wwise.core.transport.create/executeAction):\n```python\ntransport = client.call(\"ak.wwise.core.transport.create\", {\n    \"object\": \"\\\\Events\\\\Default Work Unit\\\\Play_Gunshot_Rifle\"\n})\nclient.call(\"ak.wwise.core.transport.executeAction\", {\n    \"transport\": transport[\"transport\"],\n    \"action\": \"play\"\n})\n```",
      "type": "code",
      "tags": [
        "code",
        "python",
        "WAAPI",
        "Python",
        "code-examples",
        "exact-specs"
      ],
      "timestamp": "2026-02-06T14:29:24.433Z",
      "context": "Extracted from research_waapi_mcp_server.md - all 10 core WAAPI operations with exact code",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T14:29:24.433Z",
      "lastVerified": "2026-02-06T14:29:24.433Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770388232999_vz3hyj07g",
      "content": "WWISE-MCP AND BLENDER-MCP ARCHITECTURE PATTERNS\n\n## FastMCP Tool Registration Pattern (Wwise-MCP)\n- Single FastMCP instance instantiated without lifespan initially\n- Tools exposed: list_wwise_commands() and execute_plan(plan: list[str])\n- No decorator stacking - direct @mcp.tool() usage\n- Return types: dict with command metadata, dict with results and store\n\n## Blender-MCP Tool Registration Pattern  \n- FastMCP with lifespan context manager: mcp = FastMCP(\"BlenderMCP\", lifespan=server_lifespan)\n- Stacked decorators: @telemetry_tool(\"tool_name\") + @mcp.tool()\n- Global _blender_connection maintained at module level\n- Lazy initialization on first tool call via get_blender_connection()\n- Return types vary: strings, base64 images, JSON strings, exceptions\n\n## WAAPI Connection Management (Wwise-MCP)\n- Single global connection using WaapiClient\n- Thread-safe with locks (_client, _dispatcher, _reconnecting flag)\n- Priority queue-based request scheduling with due_in parameter\n- connect_to_waapi() phases: mark reconnecting → shutdown resources → create new instances → restore globals\n- Blocks new calls during reconnection with \"WAAPI is reconnecting\" error\n\n## WAAPI Wrapper Functions Available (wwise_python_lib.py - 62 KB)\nProject info: get_project_info(), get_all_languages(), get_all_platforms(), get_all_soundbanks()\nGame objects: ensure_game_obj(), set_game_obj_position(), start_position_ramp()\nEvent control: create_event(), list_all_event_names(), post_event(), stop_event()\nGame syncs: create_rtpc(), set_state(), set_switch(), ramp_rtpc()\nObject manipulation: get_object_at_path(), rename_objects(), move_object_by_path(), set_property()\nAudio import: import_audio_files(), list_audio_files_at_path_file_explorer()\nCustom exceptions: WwiseValidationError, WwiseObjectNotFoundError, WwiseApiError\n\n## Wwise-MCP Command Execution Pattern\n- Command dataclass-based registry\n- _run_plan_sync() maintains store dict for inter-step variables\n- Variable resolution: $variable (scalars), $last (previous), $last.id (attribute access), recursive dict/list resolution\n- Validates signatures before execution, logs each step\n\n## Project Configuration (pyproject.toml) Patterns\nWwise-MCP: Python 3.13+, FastMCP-based, modules in app/scripts/\nBlender-MCP: Python 3.10+, FastMCP with mcp[cli]≥1.3.0, src/blender_mcp/ layout\nEntry point format: package_name = \"module.submodule:function_name\"\nExample: blender-mcp = \"blender_mcp.server:main\"\n\n## Connection Health Checking (Blender-MCP)\n- Lazy init via get_blender_connection()\n- Verifies connection validity before reuse\n- Recreates if invalid\n- Socket implementation with chunked JSON handling and timeout resilience",
      "type": "config",
      "tags": [
        "config",
        "python",
        "wwise-mcp",
        "blender-mcp",
        "fastmcp",
        "waapi",
        "architecture",
        "patterns"
      ],
      "timestamp": "2026-02-06T14:30:32.998Z",
      "context": "Research completed on BilkentAudio/Wwise-MCP and ahujasid/blender-mcp repositories to understand MCP server patterns for reference in UE5-WWISE project",
      "accessCount": 1,
      "lastAccessed": "2026-02-07T01:33:25.182Z",
      "lastVerified": "2026-02-06T14:30:32.998Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770388338005_1twg2y130",
      "content": "Phase 1 Implementation Plan designed for UE Audio MCP Wwise server. 10 steps, 20 tools across 5 modules (core, objects, events, preview, templates). File structure: src/ue_audio_mcp/ with server.py, connection.py, tools/*.py, knowledge/wwise_types.py, templates/wwise/*.json. Key decisions: FastMCP + waapi-client, Python 3.10+, sync WAAPI (no async wrapping), JSON returns with status field, mock WaapiClient in tests, undo groups for templates. Must remove old empty scaffolding dirs (src/tools/, src/knowledge/, src/protocol/, src/systems/).",
      "type": "general",
      "tags": [
        "general",
        "python",
        "ue5-wwise",
        "phase1",
        "implementation-plan",
        "architecture"
      ],
      "timestamp": "2026-02-06T14:32:18.005Z",
      "context": "Phase 1 implementation planning for UE5-WWISE project",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T14:32:18.005Z",
      "lastVerified": "2026-02-06T14:32:18.005Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770388761637_6gi97qnig",
      "content": "FastMCP (mcp>=1.26.0) uses `instructions` parameter, NOT `description`. The constructor signature changed from older versions.",
      "type": "general",
      "tags": [
        "general",
        "fastmcp",
        "gotcha",
        "api-change"
      ],
      "timestamp": "2026-02-06T14:39:21.637Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T14:39:21.637Z",
      "lastVerified": "2026-02-06T14:39:21.637Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770389223394_mudx7ho3m",
      "content": "Phase 1 Wwise MCP Server COMPLETE. 20 tools, 48 tests, all passing.\n\nFiles created (23):\n- pyproject.toml\n- src/ue_audio_mcp/__init__.py, server.py, connection.py\n- src/ue_audio_mcp/tools/__init__.py, core.py (5 tools), objects.py (4 tools), events.py (4 tools), preview.py (2 tools), templates.py (5 tools)\n- src/ue_audio_mcp/knowledge/__init__.py, wwise_types.py (19 types, 24 props, 18 actions, 9 paths)\n- src/ue_audio_mcp/templates/wwise/ (5 JSON specs)\n- tests/__init__.py, conftest.py, test_connection.py, test_core_tools.py, test_object_tools.py, test_event_tools.py, test_preview_tools.py, test_templates.py\n\nKey patterns:\n- FastMCP lifespan = asynccontextmanager yielding None\n- mcp defined BEFORE tool imports (blender-mcp pattern)\n- All tools return JSON: {\"status\": \"ok/error\", ...}\n- Templates wrapped in undo groups (beginGroup/endGroup/cancelGroup)\n- MockWaapiClient in conftest.py with set_response() for per-URI mocking",
      "type": "error",
      "tags": [
        "error",
        "phase1",
        "wwise-mcp",
        "complete",
        "architecture"
      ],
      "timestamp": "2026-02-06T14:47:03.394Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T14:47:03.394Z",
      "lastVerified": "2026-02-06T14:47:03.394Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770390564940_mc6034jus",
      "content": "## Phase 2: MetaSounds Knowledge Base - Complete Scope (2026-02-06)\n\n### What Phase 2 Delivers\n**Goal**: Build a node database + graph specification format for MetaSounds. Generates JSON intermediate representation (independent of UE5 at runtime) that maps 1:1 to Builder API calls. Works offline.\n\n**Timeline**: 1-2 days\n**Deliverable**: MetaSounds knowledge base + graph spec generator. Output: JSON specs documenting exact graph structure, useful even without UE5.\n\n### What Data Needs to be in Knowledge Base\n**Source**: research/research_metasounds_game_audio.md (80+ nodes catalogued)\n\n#### Categories (13):\n1. **Generators** (5): Additive Synth, Saw, Sine, Square, Triangle\n2. **Generators Advanced** (5): SuperOscillator, WaveTable Oscillator, WaveTable Player, Low Frequency Noise, LFO, Noise (pink/white), Perlin Noise\n3. **Wave Players** (7): Wave Player Mono/Stereo/Quad/5.1/7.1, properties (Loop, LoopStart, LoopDuration, StartTime, PitchShift)\n4. **Envelopes** (5): AD, ADSR, Crossfade, WaveTable Envelope, Evaluate WaveTable (audio-rate + float-rate versions)\n5. **Filters** (8): Biquad, Dynamic, Ladder, State Variable, One-Pole HP/LP, Sample And Hold, Bitcrusher, Mono/Stereo Band Splitter\n6. **Delays** (4): Delay, Stereo Delay, Delay Pitch Shift, Diffuser, Grain Delay\n7. **Dynamics** (4): Compressor, Limiter, Decibels to Linear Gain, Linear Gain to Decibels\n8. **Triggers** (12): Accumulate, Any, Compare, Control, Counter, Delay, Filter, Once, On Threshold, On Value Change, Pipe, Repeat, Route\n9. **Arrays** (6): Get, Set, Num, Random Get (w/ weight), Shuffle, Concatenate, Subset\n10. **Math** (13): Add, Subtract, Multiply, Divide, Abs, Clamp, Log, Power, Modulo, Map Range, Min, Max, Filter Q To Bandwidth, Linear To Log Frequency\n11. **Mix** (2): Mono Mixer (N→1), Stereo Mixer (N stereo→1)\n12. **Spatialization** (3): ITD Panner, Stereo Panner, Mid-Side Encode/Decode\n13. **Music/Utility** (12+): Frequency To MIDI, MIDI To Frequency, MIDI Note Quantizer, Scale to Note Array, BPM To Seconds, Random Bool/Float/Int/Time, Get Wave Info, Print Log, Audio Bus Reader, Wave Writer, Envelope Follower, Flanger, RingMod, WaveShaper, InterpTo, Get WaveTable From Bank\n\n**Data Per Node**:\n- Node class name (from Builder API discovery via Shift+hover)\n- Category\n- Inputs (pin name, data type: Audio/Trigger/Float/Int32/Bool/Time/String/UObject/Enum/WaveAsset/Array variants)\n- Outputs (same types)\n- Default values\n- Tags/capabilities (e.g., \"synthesis\", \"modulation\", \"spatial\", \"percussive\")\n\n### D1 Schema (6 Tables)\n**Database**: `ue-audio-knowledge` (independent from SIDKIT)\n\n**Table 1: metasound_nodes** (~80 rows)\n```sql\nid (TEXT PK)\nname (TEXT) -- e.g., \"Sine\", \"Biquad Filter\"\ncategory (TEXT) -- Generators, Filters, Envelopes, etc.\nclass_name (TEXT) -- Full C++ class for Builder API, e.g., \"Metasound::FSineNode\"\ndescription (TEXT)\ndata_type (TEXT) -- Primary output type: Audio/Trigger/Float/Int32/Bool\ninputs (JSON) -- [{pin_name, type, default_value}, ...]\noutputs (JSON) -- [{pin_name, type}, ...]\ntags (JSON) -- [\"modulation\", \"percussive\", \"spatial\", ...]\ncomplexity (INT) -- 1-5 for difficulty\n```\n\n**Table 2: waapi_functions** (87 rows from WAAPI reference)\n```sql\nid (TEXT PK)\nnamespace (TEXT) -- e.g., \"ak.wwise.core.object\"\noperation (TEXT) -- e.g., \"create\"\nfull_name (TEXT) -- \"ak.wwise.core.object.create\"\ndescription (TEXT)\nparameters (JSON) -- [{param_name, type, required, description}, ...]\nreturns (JSON) -- [{field_name, type}, ...]\nobject_types (JSON) -- Array of object types it applies to\nexamples (JSON) -- Code snippets\n```\n\n**Table 3: wwise_types** (16 rows)\n```sql\ntype_name (TEXT PK) -- Sound, RandomSequenceContainer, SwitchContainer, etc.\ndescription (TEXT)\nproperties (JSON) -- [{prop_name, type, default, description}, ...]\nhierarchy_allowed (BOOL) -- Can it have children?\nevents_applicable (BOOL) -- Can events play it?\ngame_parameters (JSON) -- [\"Volume\", \"Pitch\", ...]\n```\n\n**Table 4: audio_patterns** (6 rows initially)\n```sql\npattern_type (TEXT PK) -- gunshot, footsteps, ambient, spatial, ui_sound, weather\ndescription (TEXT)\nmetasounds_graph (JSON) -- Template graph spec (nodes + connections)\nwwise_equivalent (JSON) -- Equivalent Wwise structure\nblueprint_logic (TEXT) -- Blueprint trigger/parameter setup\ncomplexity (INT) -- 1-5\ngame_examples (JSON) -- [\"Lyra\", \"Fortnite\", ...]\n```\n\n**Table 5: error_patterns** (grows over time)\n```sql\nerror_hash (TEXT PK) -- hash(error_signature + template + params)\nerror_signature (TEXT) -- e.g., \"node_type_mismatch\"\ntemplate_used (TEXT) -- Which pattern failed\nparameters (JSON) -- What was being generated\nsuccessful_fix (TEXT) -- What worked\nsuccess_rate (FLOAT) -- % of times this fix works\nmetadata (JSON) -- {\"first_seen\": date, \"last_seen\": date}\n```\n\n**Table 6: ue_game_examples** (reference only)\n```sql\ngame_name (TEXT PK)\nsystem_type (TEXT) -- footsteps, weapons, ambient, etc.\ndescription (TEXT)\nreference_docs (JSON) -- Links to source files\nmetasounds_patches (JSON) -- Which patches used\nwwise_hierarchy (JSON) -- Wwise structure\ncomplexity (INT)\n```\n\n### Vectorize Semantic Search\n**Index**: `ue-audio-index` (independent embeddings)\n**Purpose**: Semantic queries alongside D1 structured queries\n\n**Embedding strategy**:\n- Embed node descriptions + tags → `metasound_nodes` index\n- Embed pattern descriptions + use cases → `audio_patterns` index\n- Embed error signatures + fixes → `error_patterns` index\n\n**Example queries**:\n- \"make it sound underwater\" → finds [Lowpass, Biquad, wet reverb pattern]\n- \"add spatial movement\" → finds [ITD Panner, Stereo Panner, Doppler effect]\n- \"weapon fire repetition issue\" → finds stored fixes for gunshot repetition\n\n**Implementation**: \n- Use Cloudflare's built-in embeddings API (same as SIDKIT)\n- Vectorize at seed time (one-time from research data)\n- Update incrementally as errors are learned\n\n### Cloudflare Workers Needed\n**Purpose**: API endpoints for MCP server to query D1 + Vectorize\n\n**Worker 1: D1 Query Endpoint** (`/api/d1-query`)\n```\nPOST /api/d1-query\nBody: {\n  table: \"metasound_nodes\",\n  where: {category: \"Filters\"},\n  limit: 50\n}\nReturns: JSON rows from D1\n```\n\n**Worker 2: Vectorize Search Endpoint** (`/api/vectorize-search`)\n```\nPOST /api/vectorize-search\nBody: {\n  index: \"ue-audio-index\",\n  query: \"make it underwater\",\n  limit: 10\n}\nReturns: Top 10 semantic matches with scores\n```\n\n**Worker 3: Knowledge Upsert** (`/api/upsert-knowledge`)\n```\nPOST /api/upsert-knowledge\nBody: {\n  table: \"metasound_nodes\",\n  data: {...node definition...}\n}\nWrites to D1 + re-embeds for Vectorize\n```\n\n**Worker 4: Error Learning** (`/api/store-error`)\n```\nPOST /api/store-error\nBody: {\n  error_signature: \"...\",\n  template_used: \"...\",\n  successful_fix: \"...\"\n}\nStores to error_patterns table + updates success_rate\n```\n\n### D1 Seeding Strategy\n**One-time bootstrap** (2-3 hours):\n1. Parse `research_metasounds_game_audio.md` → extract 80+ nodes\n2. Generate structured JSON for each node\n3. Parse `research_waapi_mcp_server.md` section 4 (87 WAAPI functions)\n4. Extract Wwise types from CLAUDE.md (16 object types)\n5. Build 6 pattern templates (gunshot, footsteps, etc.) as graph specs\n6. Upload all to D1 via Worker\n7. Run Vectorize embeddings via Cloudflare API\n\n**Ongoing growth**:\n- Each build failure stores error_signature + fix in `error_patterns`\n- New patterns discovered in Phase 4 added to `audio_patterns`\n- Custom nodes from community projects indexed as needed\n\n### Phase 2 Dependencies & Blockers\n**No blockers**: Knowledge base is purely data + offline.\n\n**Dependencies on Phase 2**:\n- Phase 3 (UE5 Plugin) needs Phase 2's node database + graph spec format (to feed to Builder API)\n- Phase 4 (Systems Layer) needs Phase 2's pattern templates + error learning\n\n**External dependencies**:\n- Cloudflare account setup (D1 database + Vectorize index) — ALREADY DONE in previous work\n- waapi-client library documentation (for WAAPI function params) — available\n- UE5 source code access (for node class names) — public, can Shift+hover in Editor\n\n### Key Questions Answered\n1. **\"What goes in the knowledge base?\"** → 80+ MetaSounds nodes, 87 WAAPI functions, 16 Wwise types, 6 game patterns, error→fix mappings, game examples\n2. **\"How is it structured?\"** → 6 D1 tables, Vectorize index for semantic search, Cloudflare Workers for API endpoints\n3. **\"How does it serve Phase 3?\"** → UE5 plugin queries D1 for node class names, validates graph specs against schema before sending to Builder API\n4. **\"How does error learning work?\"** → Same SIDKIT pattern: error_signature (hash of error + context) → successful_fix mapping, stored in D1, queryable for next generation attempt\n5. **\"Cloudflare setup?\"** → Own D1 database `ue-audio-knowledge` + own Vectorize index `ue-audio-index`, separate Workers, fully independent from SIDKIT at runtime\n",
      "type": "config",
      "tags": [
        "config",
        "database",
        "api",
        "phase-2",
        "metasounds",
        "knowledge-base",
        "d1-schema",
        "vectorize",
        "cloudflare-workers",
        "architecture"
      ],
      "timestamp": "2026-02-06T15:09:24.940Z",
      "context": "Phase 2 comprehensive analysis for UE5-WWISE MCP project",
      "accessCount": 2,
      "lastAccessed": "2026-02-07T11:54:06.223Z",
      "lastVerified": "2026-02-06T15:09:24.940Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770393132925_d8harfuq3",
      "content": "Phase 2 (MetaSounds Knowledge Base) COMPLETE — 2026-02-06. 7 new MCP tools, 40 new tests, 92 total passing. SQLite DB with 8 tables (234 entries), TF-IDF semantic search via numpy, 7-stage graph validator, 6 MetaSounds templates. Total project: 27 tools (20 Wwise + 7 MetaSounds). Next: Phase 3 (UE5 C++ Plugin with TCP server on port 9877, UEdGraphSchema_K2 for runtime node discovery).",
      "type": "general",
      "tags": [
        "general",
        "ue5-wwise",
        "phase2",
        "milestone",
        "complete"
      ],
      "timestamp": "2026-02-06T15:52:12.925Z",
      "context": "Phase 2 implementation of UE Audio MCP project",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T15:52:12.925Z",
      "lastVerified": "2026-02-06T15:52:12.925Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770394913628_hmzbx2fol",
      "content": "MetaSound Builder API (UMetaSoundBuilderBase) - 113 public methods documented at dev.epicgames.com. Key functions: CreateSourceBuilder, CreatePatchBuilder, AddNodeByClassName, AddInterface, ConnectNodes, FindNodeInputByName, FindNodeOutputByName, AddGraphInputNode, AddGraphOutputNode, SetNodeInputDefault, SetNodeLocation, BuildNewMetaSound, Build, Audition. Key UStructs: FMetaSoundNodeHandle, FMetaSoundBuilderNodeInputHandle, FMetaSoundBuilderNodeOutputHandle. Limitations: no variable support, paged inputs limited, live updates beta (5.5+). Template nodes only in C++ not Blueprint.",
      "type": "general",
      "tags": [
        "general",
        "api",
        "ue5-wwise",
        "builder-api",
        "phase3",
        "metasounds",
        "api-reference"
      ],
      "timestamp": "2026-02-06T16:21:53.628Z",
      "context": "Builder API research from official UE5 docs for Phase 3 C++ plugin implementation",
      "accessCount": 1,
      "lastAccessed": "2026-02-07T11:54:06.223Z",
      "lastVerified": "2026-02-06T16:21:53.628Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770395566744_uo1j7e0fj",
      "content": "Completed comprehensive UE5 Blueprint node research covering 7 systems with 100+ nodes documented. File at /Users/radek/Documents/GIthub/UE5-WWISE/research/research_ue5_blueprint_nodes.md. Systems covered: Enhanced Input (UEnhancedInputComponent, triggers, modifiers), Save Game (USaveGame, sync/async save/load), Collision/Traces (line/sphere/box/capsule traces + overlaps, FHitResult 19 fields), Material Parameters (UMaterialInstanceDynamic, full C++ API), Subsystems (5 types: Engine/Editor/GameInstance/World/LocalPlayer), DataTables (10 nodes), Struct operations (Make/Break for FVector, FRotator, FTransform, FLinearColor, FHitResult). All verified against UE 5.7 official docs at dev.epicgames.com.",
      "type": "general",
      "tags": [
        "general",
        "api",
        "ue5",
        "blueprint",
        "research",
        "nodes",
        "enhanced-input",
        "save-game",
        "collision",
        "materials",
        "subsystems",
        "datatables",
        "structs"
      ],
      "timestamp": "2026-02-06T16:32:46.744Z",
      "context": "UE5-WWISE project research for building MCP server knowledge base",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T16:32:46.744Z",
      "lastVerified": "2026-02-06T16:32:46.744Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770395869075_kyszk57eb",
      "content": "UE5 Blueprint Nodes research file at /Users/radek/Documents/GIthub/UE5-WWISE/research/research_ue5_blueprint_nodes.md is already comprehensive with 580+ lines covering: Enhanced Input (UEnhancedInputComponent, UInputAction, UInputMappingContext, triggers, modifiers), Save Game (USaveGame, 7 Blueprint nodes), Collision/Traces (24 trace nodes, 11 overlap nodes, full FHitResult), Material Parameters (MID create/set/get, MPC nodes), Subsystems (5 types with C++ accessors), DataTables (9 nodes), and Struct Break/Make operations. All verified against UE 5.7 docs.",
      "type": "general",
      "tags": [
        "general",
        "ue5",
        "blueprint-nodes",
        "research",
        "documentation"
      ],
      "timestamp": "2026-02-06T16:37:49.075Z",
      "context": "Research validation - the file already existed and is complete",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T16:37:49.075Z",
      "lastVerified": "2026-02-06T16:37:49.075Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770396006090_05ggmyyxc",
      "content": "Completed research on Wwise UE5 Blueprint integration nodes. File: /Users/radek/Documents/GIthub/UE5-WWISE/research/research_wwise_ue5_blueprint_nodes.md\n\nKey findings:\n- UAkGameplayStatics: 40+ static BlueprintCallable functions (PostEvent, SetRTPCValue, SetState, SetSwitch, LoadBank, StopActor, SpawnAkComponentAtLocation, etc.)\n- UAkComponent: 17+ instance functions (PostAkEvent, PostAssociatedAkEvent, Stop, SetRTPCValue, SetSwitch, SeekOnEventBySeconds, SetAttenuationScalingFactor, etc.)\n- Wwise 2022.1+ introduced typed asset classes: UAkRtpc, UAkStateValue, UAkSwitchValue, UAkAudioEvent, UAkTrigger, UAkAuxBus, UAkAudioBank\n- Verified against 3 SDK source dumps (Satisfactory, RadicalHeights, PUBG) + 8 tutorial/blog sources\n- Header: Plugins/Wwise/Source/AkAudio/Classes/AkGameplayStatics.h\n- 85+ total functions documented across all classes",
      "type": "general",
      "tags": [
        "general",
        "wwise",
        "ue5",
        "blueprint",
        "research",
        "api-reference"
      ],
      "timestamp": "2026-02-06T16:40:06.090Z",
      "context": "Research task for UE5-WWISE MCP project. These functions are what our MCP server needs to be able to trigger via the UE5 C++ plugin bridge on port 9877.",
      "accessCount": 1,
      "lastAccessed": "2026-02-07T01:33:25.182Z",
      "lastVerified": "2026-02-06T16:40:06.090Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770396033275_rv33wjk4m",
      "content": "Expanded research_ue5_blueprint_nodes.md from 7 categories (580 lines) to 19 sections (1000+ lines) with 400+ Blueprint nodes. New sections added: Math Comparison (Section 8), Interpolation/Lerp (Section 9), Math Random (Section 10), Damage System (Section 11), Mesh/Static Mesh (Section 12), Audio-Adjacent (Section 13), Viewport/Screen (Section 14), Platform Detection (Section 15), EQS (Section 16), Collision/Overlap Events Extended (Section 17), Struct Operations Extended (Section 18), UGameplayStatics Extended (Section 19). All verified against UE 5.7 official docs at dev.epicgames.com.",
      "type": "general",
      "tags": [
        "general",
        "ue5",
        "blueprint",
        "research",
        "nodes",
        "documentation"
      ],
      "timestamp": "2026-02-06T16:40:33.275Z",
      "context": "UE5-WWISE project blueprint node research expansion",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T16:40:33.275Z",
      "lastVerified": "2026-02-06T16:40:33.275Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770396089625_s2evy82k8",
      "content": "Created comprehensive UE5 Blueprint Function Libraries research at /Users/radek/Documents/GIthub/UE5-WWISE/research/research_ue5_blueprint_libraries.md. Covers 5 major Kismet libraries: UKismetMathLibrary (300+ functions across 15+ categories), UKismetStringLibrary (40+ functions), UKismetSystemLibrary (120+ functions), UKismetArrayLibrary (15+ generic functions), UGameplayStatics (100+ functions). Includes audio-relevant function summary for the UE Audio MCP project. All function names verified from official Epic source code mirrors, Python API, and documentation.",
      "type": "code",
      "tags": [
        "code",
        "python",
        "api",
        "ue5",
        "blueprint",
        "api-reference",
        "kismet",
        "research"
      ],
      "timestamp": "2026-02-06T16:41:29.625Z",
      "context": "UE5-WWISE project research phase",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T16:41:29.625Z",
      "lastVerified": "2026-02-06T16:41:29.625Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770424373888_v1byu7gmk",
      "content": "Epic Tutorial Pages for Agent Knowledge Base — 6 complete guides scraped:\n\n1. MetaSounds Quick Start — Bomb (spatial, explosion variations) + Wind (noise synthesis, LFO filter, velocity-reactive)\n   URL: dev.epicgames.com/documentation/en-us/unreal-engine/metasounds-quick-start\n\n2. Audio Modulation Quick Start — Control Buses (CB_Main, CB_SFX, CB_Music), Sound Classes, Bus Mixes, Level Blueprint control\n   URL: dev.epicgames.com/documentation/en-us/unreal-engine/audio-modulation-quick-start-guide\n\n3. Quartz Quick Start — Sample-accurate timing, Quartz clock, quantized playback, beat-sync actor scaling\n   URL: dev.epicgames.com/documentation/en-us/unreal-engine/quartz-quick-start\n\n4. WaveTables Quick Start — Fixed Resolution + Fixed Sample Rate banks, WaveTable Player, WaveTable Envelope\n   URL: dev.epicgames.com/documentation/en-us/unreal-engine/wavetables-quick-start-in-unreal-engine\n\n5. Procedural Music — Full synthesizer: melody generation (Random Get → Scale to Note Array → MIDI to Freq), sine/saw oscillators, crossfade, ladder filter + LFO (500-5000Hz), AD envelope, stereo delay (ping-pong). Blueprint Actor with 3 trigger zones controlling BPM, crossfade, and melody regeneration.\n   URL: dev.epicgames.com/documentation/en-us/unreal-engine/creating-procedural-music-with-metasounds\n\n6. Audio Gameplay Volumes Quick Start — Reverb zones, Sound Class routing, Audio Gameplay Volumes plugin\n   URL: dev.epicgames.com/documentation/en-us/unreal-engine/audio-gameplay-volumes-quick-start\n\nTotal: ~12 MetaSounds graphs, ~8 Blueprint graphs, ~8 complete audio systems.\nAll instructions follow parseable patterns: \"create X node\", \"drag off Y and create Z\", \"enter V for Pin\", \"connect A to B\".",
      "type": "solution",
      "tags": [
        "solution",
        "ue5",
        "tutorials",
        "workflows",
        "scraping",
        "knowledge-base"
      ],
      "timestamp": "2026-02-07T00:32:53.888Z",
      "context": "Blueprint+MetaSounds workflow sources for agent training data",
      "accessCount": 1,
      "lastAccessed": "2026-02-07T11:54:06.223Z",
      "lastVerified": "2026-02-07T00:32:53.888Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770424679539_84wm8j9pn",
      "content": "Epic Documentation Pages — Additional Reference Material Scraped:\n\n7. MetaSounds Function Nodes Reference — 107+ nodes across 16 categories:\n   General(7), Array(8), Debug(2), Delays(5), Dynamics(5), Envelopes(6), External IO(2), Filters(11), Generators(15), Math(15), Mix(2), Music(4), Random(4), Spatialization(4), Triggers(16)\n   URL: dev.epicgames.com/.../metasound-function-nodes-reference-guide-in-unreal-engine\n\n8. MetaSounds Reference Guide — Type system: 9 pin types (Trigger, Audio, Time, String, UObject, Bool, Float, Int32, Enum), conversion table, 3 interfaces (OneShot, Attenuation, Spatialization), 2 asset types (Source, Patch)\n   URL: dev.epicgames.com/.../metasounds-reference-guide-in-unreal-engine\n\n9. MetaSound Builder API — 109 Blueprint functions: CreateSourceBuilder, AddNode, ConnectNodes, Audition, BuildToAsset, etc. Beta, live updates supported.\n   URL: dev.epicgames.com/.../metasound-builder-api-in-unreal-engine\n\n10. Soundscape Quick Start — Procedural ambient: SoundscapeStates (GameplayTags), Palettes, Colors, Trigger Volumes. Blueprint: OnOverlap → SetState/ClearState via SoundscapeSubsystem.\n    URL: dev.epicgames.com/.../soundscape-quick-start\n\n11. Spatialization Overview — 3 methods: Panning (linear/equal-power/VBAP), Soundfield (Ambisonics), Binaural (HRTF/ITD/ILD). Only mono/stereo sources supported.\n    URL: dev.epicgames.com/.../spatialization-overview-in-unreal-engine\n\n12. Sound Attenuation Reference — 8 subsystems: Volume (5 curve types + shapes), Spatialization (panning/binaural), Air Absorption (LP/HP freq curves), Focus (azimuth-based), Reverb (distance-based send), Occlusion (trace-based LPF), Priority (distance-based), Submix (distance-based routing).\n    URL: dev.epicgames.com/.../sound-attenuation-in-unreal-engine\n\nOur DB comparison: Python catalogues have 112 MetaSounds nodes (close to Epic's 107+ official), 948 Blueprint nodes, 55 Blueprint audio functions. DB tables exist but are empty (seed not run).",
      "type": "troubleshooting",
      "tags": [
        "troubleshooting",
        "python",
        "api",
        "ue5",
        "reference",
        "metasounds",
        "spatial",
        "attenuation",
        "knowledge-base"
      ],
      "timestamp": "2026-02-07T00:37:59.539Z",
      "context": "Additional Epic docs pages scraped for agent knowledge base",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T00:37:59.539Z",
      "lastVerified": "2026-02-07T00:37:59.539Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770427308922_al99133vk",
      "content": "Phase 3 Code Review Complete (2026-02-07). 156 tests pass. Key findings: (1) CRITICAL: No max message size check on TCP recv - uint32 allows up to 4GB allocation. (2) CRITICAL: Socket not cleaned up on send failure - is_connected() false positives. (3) WARNING: _seed_console_commands mutates imported data. (4) WARNING: bp_search/bp_node_info use private _fetch method. (5) WARNING: No validation on source param in bp_search/bp_list_categories. (6) WARNING: bp_search test has vacuous assertion (assert True). (7) SUGGESTION: table_counts() could be a loop. Full review written up with code references.",
      "type": "warning",
      "tags": [
        "warning",
        "code-review",
        "phase3",
        "ue5-plugin",
        "security"
      ],
      "timestamp": "2026-02-07T01:21:48.922Z",
      "context": "Code review of Phase 3 UE5 Plugin Connectivity",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T01:21:48.922Z",
      "lastVerified": "2026-02-07T01:21:48.922Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770428276910_6ceaq94hy",
      "content": "ORCHESTRATION LAYER DESIGN - COMPLETE BUILDING BLOCKS INVENTORY\n\n## 1. TEMPLATES STRUCTURE\nMetaSounds Templates (8 JSON files in src/ue_audio_mcp/templates/metasounds/):\n- gunshot.json: OneShot, random sample selection + pitch variation + ADSR\n- footsteps.json: OneShot, trigger routing by surface type + random sample + AD envelope + lowpass\n- ambient.json: Looping, wave player + LFO modulation + stereo mixer\n- spatial.json: OneShot + Spatialization, wave player + ITD panner for binaural\n- ui_sound.json: OneShot, sine oscillator + AD envelope (procedural click)\n- weather.json: Looping, wave player + InterpTo smoothing + Map Range cutoff + Biquad filter\n- snare.json: (8 days old, added after Phase 2)\n- wind.json: (8 days old, added after Phase 2)\n\nBlueprint Templates (9 JSON files in src/ue_audio_mcp/templates/blueprints/):\n- bomb_fuse.json: BeginPlay → SpawnSound2D → Delay → SetBoolParameter (timer pattern)\n- wind_system.json, audio_modulation.json, quartz_beat_sync.json, etc. (8 more templates)\n\nWwise Templates (5 template_* functions in tools/templates.py):\n- template_gunshot(weapon_name, num_variations, pitch_randomization)\n- template_footsteps(surface_types, with_switch_group)\n- template_ambient(layer_names, rtpc_parameter_name)\n- template_ui_sound(sound_name, bus_path)\n- template_weather_states(weather_states)\nAll wrap WAAPI calls in undo groups for atomic rollback.\n\n## 2. GRAPH SYSTEM (MetaSounds)\nGraphSpec JSON Format (from graph_schema.py):\n- Required fields: name, asset_type, nodes, connections\n- Optional: inputs, outputs, interfaces, descriptions\n- Node sentinel: \"__graph__\" represents graph boundary for I/O wiring\n\nValidation (validate_graph):\n- 7-stage validator: required fields, asset_type, interfaces, nodes, connections, required inputs, interface pins\n- Returns ALL errors in one pass (accumulation, not early exit)\n- Pin type compatibility via PIN_COMPATIBILITY matrix\n- Checks for duplicate IDs, missing nodes, type mismatches\n\nBuilder Command Generation (graph_to_builder_commands):\n- 8-stage sequential command ordering:\n  1. create_builder\n  2. add_interface (per interface)\n  3. add_graph_input (per input)\n  4. add_graph_output (per output)\n  5. add_node (per node with position)\n  6. set_default (per non-None default value)\n  7. connect (per connection)\n  8. build_to_asset\n- Returns list[dict] with \"action\" key for each command\n\nms_graph_from_template tool:\n- Loads template JSON from disk\n- Applies parameter overrides using dotted syntax: \"node_id.input_name\": value\n- Returns spec + validation result\n\n## 3. KNOWLEDGE SEARCH CAPABILITIES\nKnowledgeDB (db.py) - 14 query methods:\n- query_nodes(category, tag, name): MetaSounds nodes\n- query_waapi(namespace, operation): WAAPI functions\n- query_patterns(pattern_type): Audio patterns\n- query_errors(signature): Error learning (SIDKIT pattern)\n- query_tutorial_workflows(tag): Tutorial workflows\n- search_blueprint_curated(query, category): Blueprint audio+core\n- search_blueprint_scraped(query): Blueprints by text search\n- query_builder_api(category): Builder API functions\n- count_nodes_by_category(), table_counts(), is_seeded()\n\nEmbeddingIndex (embeddings.py) - TF-IDF semantic search:\n- Tokenizes name + description + tags\n- 39 stop words removed\n- Builds vocabulary + document frequency\n- L2-normalize vectors for cosine similarity\n- search(query, top_k) returns scored results\n- build_index_from_nodes(METASOUND_NODES) creates index\n- Lightweight: no ML deps, <1ms queries on 400 entries\n\nDatabase Tables (14 total):\n1. metasound_nodes: 112 entries (category, description, inputs/outputs, tags, complexity)\n2. waapi_functions: 32 entries (namespace, operation, description, params, returns)\n3. wwise_types: 19 entries (type_name, category, properties)\n4. audio_patterns: 6 entries (name, pattern_type, description, graph_spec, key_nodes)\n5. error_patterns: 0 entries (grows at runtime via store_error)\n6. ue_game_examples: 5 entries (game, system_type, details)\n7. blueprint_audio: 24 entries (class_name, category, params, returns, tags)\n8. blueprint_core: 36 entries (same structure as blueprint_audio)\n9. blueprint_nodes_scraped: ~200 entries (name, target, category, description, inputs, outputs)\n10. builder_api_functions: 109 entries (Builder API reference)\n11. tutorial_workflows: 8 entries (tutorial, url, layers, tags, bp_template, ms_template)\n12. audio_console_commands: ~20 entries (cmd, category, type, default, description)\n13. spatialization_methods: 6 entries (description, details)\n14. attenuation_subsystems: 8 entries (description, params, details)\n\n## 4. ALL 37 TOOLS INVENTORY\nGrouped by specialization:\n\nWWISE CORE (5 tools - core.py):\n- wwise_connect(url): WAAPI connection\n- wwise_get_info(): Version + platform + project\n- wwise_query(waql, return_fields): WAQL object queries\n- wwise_save(): Save project\n- execute_waapi(uri, args_json, options_json): Raw WAAPI RPC\n\nWWISE OBJECTS (4 tools - objects.py):\n- wwise_create_object(parent_path, object_type, name, on_conflict)\n- wwise_set_property(object_path, property_name, value)\n- wwise_set_reference(object_path, reference_name, value)\n- wwise_import_audio(import_path, destination_parent)\n\nWWISE EVENTS & MIXING (4 tools - events.py):\n- wwise_create_event(name, target_path, action_type, event_parent)\n- wwise_create_game_parameter(name, min_value, max_value, default_value)\n- wwise_assign_switch(object_path, switch_group_id, switch_id)\n- wwise_set_attenuation(object_path, attenuation_curve_json)\n\nWWISE PREVIEW & GENERATION (2 tools - preview.py):\n- wwise_preview(object_path, duration_ms)\n- wwise_generate_banks(language, platform)\n\nWWISE TEMPLATES (5 tools - templates.py):\n- template_gunshot(weapon_name, num_variations, pitch_randomization)\n- template_footsteps(surface_types, with_switch_group)\n- template_ambient(layer_names, rtpc_parameter_name)\n- template_ui_sound(sound_name, bus_path)\n- template_weather_states(weather_states)\n→ All return JSON with IDs, wrap WAAPI calls in undo groups\n\nMETASOUNDS KNOWLEDGE (4 tools - metasounds.py):\n- ms_list_nodes(category, tag): MetaSounds node list\n- ms_node_info(node_name): Full node spec (inputs/outputs/defaults)\n- ms_search_nodes(query): Semantic search via TF-IDF\n- ms_list_categories(): Node category counts\n\nMETASOUNDS GRAPH (3 tools - ms_graph.py):\n- ms_validate_graph(graph_spec): 7-stage validation\n- ms_graph_to_commands(graph_spec): Convert to Builder command sequence\n- ms_graph_from_template(template_name, params): Load + override template\n\nMETASOUNDS BUILDER (7 tools - ms_builder.py):\n- ms_build_graph(graph_spec): Validate + convert + execute full pipeline\n- ms_create_source(name, asset_type): Create builder in UE5\n- ms_add_node(node_type, node_id, position_x, position_y): Add node\n- ms_connect_pins(from_node, from_pin, to_node, to_pin): Wire connection\n- ms_set_default(node_id, input, value): Set default value\n- ms_audition(duration_ms): Preview MetaSound\n- ms_save_asset(name, path): Save to disk\n\nUE5 CORE (3 tools - ue5_core.py):\n- ue5_connect(host, port): TCP connection to plugin (port 9877)\n- ue5_get_info(): Ping plugin for version/features\n- ue5_status(): Combined Wwise + UE5 connection status\n\nBLUEPRINTS (2 tools - blueprints.py):\n- bp_search(query, category, source): Search nodes (curated + scraped)\n- bp_node_info(node_name): Full pin specs from db\n- bp_call_function(node_name, args_json): Execute Blueprint node\n- bp_list_categories(): Category counts\n\nTOOL CHARACTERISTICS:\n- Low-level: Single-action tools (create 1 object, set 1 property, query 1 type)\n- Medium-level: Template tools (3-5 WAAPI calls wrapped in undo)\n- High-level: Pipeline tools (validate + convert + execute full graph)\n- Pattern: All return _ok(dict) or _error(str)\n\n## 5. AUDIO PATTERNS TABLE\n6 patterns stored in db (table: audio_patterns):\n- gunshot: pattern_type=procedural, graph_spec={...}\n- footsteps: pattern_type=procedural\n- ambient: pattern_type=layered\n- spatial: pattern_type=spatialization\n- ui_sound: pattern_type=procedural\n- weather: pattern_type=layered\n\nEach stores: name, pattern_type, description, graph_spec (full JSON), complexity (1-5), key_nodes (list)\n\n## 6. TUTORIAL WORKFLOWS TABLE\n8 tutorials in db:\n- name, tutorial (Epic doc title), url, layers (list), description, tags, bp_template, ms_template\n- Curated from Epic's official Quick Start docs\n- Each entry maps to one Blueprint template + one MetaSound template\n\n## ORCHESTRATION LAYER DESIGN IMPLICATIONS\n\nThe orchestration layer will:\n1. Take high-level description (NL): \"footsteps with surface switching\"\n2. Query tutorial_workflows OR audio_patterns tables to find matching system\n3. Instantiate Blueprint template (Blueprint layer - WHEN game events trigger)\n4. Instantiate MetaSound template (MetaSound layer - WHAT DSP synthesis)\n5. Instantiate Wwise template (Wwise layer - HOW final mixing/spatializ)\n6. Wire layer outputs together via UE5 Remote Control API + AudioLink\n7. Return combined asset spec (paths to all 3 generated objects)\n\nKey orchestration decisions:\n- Use template + parameter overrides as generation primitives\n- Fall back to knowledge search when no exact template match\n- Error learning: store failed generation attempts for future refinement\n- Layer composition: BP → MetaSounds → Wwise (data flow direction)\n- Atomicity: Wrap all 3-layer generation in Wwise undo group for rollback",
      "type": "config",
      "tags": [
        "config",
        "api",
        "database",
        "orchestration",
        "ue-audio-mcp",
        "phase-4-design",
        "templates",
        "graph-system",
        "knowledge-db"
      ],
      "timestamp": "2026-02-07T01:37:56.910Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T01:37:56.910Z",
      "lastVerified": "2026-02-07T01:37:56.910Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770430509907_jq02m2s17",
      "content": "UE5 Plugin Security Review (2026-02-07):\nCRITICAL findings:\n1. ConnectNodes() in AudioMCPBuilderManager.cpp references undeclared members (GraphInputOutputIndices, NodeOutputHandles, NodeHandleIndices, etc.) - code WILL NOT COMPILE\n2. call_function command allows arbitrary UE reflection calls with no allowlist - any Blueprint-exposed function on GameplayStatics/World/GameInstance callable via TCP\n3. ActiveBuilder is raw UObject* without GC protection (UPROPERTY) - dangling pointer risk\n4. Shutdown race: ShutdownModule on game thread blocks in WaitForCompletion while AsyncTask needs game thread - 25s timeout delay\n5. No authentication on TCP server (mitigated by 127.0.0.1 binding)",
      "type": "code",
      "tags": [
        "code",
        "authentication",
        "ue5-plugin",
        "security-review",
        "code-review"
      ],
      "timestamp": "2026-02-07T02:15:09.907Z",
      "context": "Full security and quality review of UE5 C++ plugin at ue5_plugin/UEAudioMCP/",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T02:15:09.907Z",
      "lastVerified": "2026-02-07T02:15:09.907Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770431237386_5i0pk0hf6",
      "content": "UE5 Plugin TCP Server Best Practices - Research Summary\n\nARCHITECTURE PATTERNS:\n1. **blender-mcp gold standard**: Addon (socket server inside app) + MCP server (FastMCP), TCP+JSON, main thread dispatch\n2. **chongdashu/unreal-mcp leader**: Python MCP → TCP socket → C++ plugin (1,370 stars), modular tool files pattern\n3. **Game thread dispatch**: AsyncTask with ENamedThreads::GameThread is standard for worker threads → game thread\n4. **Socket server location**: Inside the DCC app (plugin) NOT in MCP server\n\nKEY FINDINGS:\n\nTHREADING & GAME THREAD SAFETY:\n- FRunnable/FRunnableThread pattern for worker threads (separate async thread)\n- NEVER create/modify/delete UObjects from background threads\n- Use AsyncTask with ENamedThreads::GameThread to dispatch callbacks to game thread\n- CRITICAL: Deadlock risk when GC running + tasks queued on background threads\n- Solution: Use ENamedThreads::AnyHiPriThreadNormalTask (only group that doesn't conflict with GC)\n- Alternative: Do all heavy work on background thread, only spawn UObjects on game thread\n\nOBJECT POINTER MANAGEMENT:\n- TStrongObjectPtr: for holding strong refs inside non-UObject classes (plain C++)\n- NOT for UObject fields (use UPROPERTY instead)\n- Worker threads accessing UObjects: use TWeakObjectPtr.Pin() to get TStrongObjectPtr safely\n- Never directly access UObject from worker thread unless certain it's rooted (AddToRoot)\n- Creating/destroying TStrongObjectPtr is expensive, keep them long-lived\n\nSHUTDOWN DEADLOCK AVOIDANCE:\n- Module shutdown can deadlock if:\n  1. FRunnable thread still running during ~FModule\n  2. Trying to create UObjects as module unloads\n  3. Background task waiting for GC that's waiting for background tasks\n- Solutions:\n  a) Clean stop worker threads BEFORE module cleanup (FRunnable::Stop called early)\n  b) Use weak references instead of strong refs during shutdown\n  c) Fire pending game-thread tasks with bWaitForCompletion=true in ~FModule\n  d) Avoid UObject creation/deletion during shutdown\n\nREMOTE CONTROL API (Epic's Approach):\n- Remote Control plugin allows HTTP/WS clients to trigger Blueprint events remotely\n- Has some form of security/whitelist (ProcessEvent restrictions, but docs not clear)\n- Use as reference for exposing safe game functions to external clients\n- Sources: Epic documentation, but implementation details need source code review\n\nPRACTICAL PATTERN FOR TCP SERVER:\n1. Worker thread (FRunnable) reads TCP socket (blocking I/O safe)\n2. On message received, queue game-thread task: AsyncTask(ENamedThreads::GameThread, [=]() { ... })\n3. Game thread task processes command, calls BP functions, modifies UObjects\n4. Return response to worker thread, send back to socket\n5. On shutdown: Stop() the FRunnable first, wait for pending tasks with bWaitForCompletion\n\nAVOID DEADLOCK ON SHUTDOWN:\n- Module's ~FRunnable::Stop() signals thread to exit cleanly\n- Wait for FRunnableThread::Kill(true) = wait for completion\n- Flush any pending game-thread tasks from that thread BEFORE exiting\n- Use weak refs for any UObject pointers held by worker thread\n",
      "type": "warning",
      "tags": [
        "warning",
        "python",
        "api",
        "ue5",
        "tcp-server",
        "threading",
        "game-thread",
        "plugin-architecture"
      ],
      "timestamp": "2026-02-07T02:27:17.386Z",
      "context": "Research for UE5-WWISE project C++ plugin TCP server implementation",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T02:27:17.386Z",
      "lastVerified": "2026-02-07T02:27:17.386Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770431272737_xwsb4mfw3",
      "content": "UE5 MetaSounds Builder API signatures (UE 5.4+) - Research findings:\n\nCONFIRMED SIGNATURES (from Epic docs):\n\n1. UMetaSoundBuilderSubsystem - Entry Point\n   - CreateSourceBuilder(FName BuilderName, FMetaSoundBuilderNodeOutputHandle& OnPlayNodeOutput, FMetaSoundBuilderNodeInputHandle& OnFinishedNodeInput, TArray<FMetaSoundBuilderNodeInputHandle>& AudioOutNodeInputs, EMetaSoundBuilderResult& OutResult, EMetaSoundOutputAudioFormat OutputFormat, bool bIsOneShot) -> UMetaSoundSourceBuilder*\n   - CreatePatchBuilder(FName BuilderName, EMetaSoundBuilderResult& OutResult) -> UMetaSoundPatchBuilder*\n   - CreateSourcePresetBuilder(FName BuilderName, TScriptInterface<IMetaSoundDocumentInterface>& ReferencedSourceClass, EMetaSoundBuilderResult& OutResult) -> UMetaSoundSourceBuilder*\n   - CreatePatchPresetBuilder(FName BuilderName, TScriptInterface<IMetaSoundDocumentInterface>& ReferencedPatchClass, EMetaSoundBuilderResult& OutResult) -> UMetaSoundPatchBuilder*\n\n2. UMetaSoundBuilderBase (parent class for Source/Patch builders)\n   - AddNode(TScriptInterface<IMetaSoundDocumentInterface>& NodeClass, EMetaSoundBuilderResult& OutResult) -> FMetaSoundNodeHandle\n   - ConnectNodes(FMetaSoundBuilderNodeOutputHandle& NodeOutputHandle, FMetaSoundBuilderNodeInputHandle& NodeInputHandle, EMetaSoundBuilderResult& OutResult) -> void\n   - FindNodeInputByName(FMetaSoundNodeHandle& NodeHandle, FName InputName, EMetaSoundBuilderResult& OutResult) -> FMetaSoundBuilderNodeInputHandle\n   - FindNodeOutputByName(FMetaSoundNodeHandle& NodeHandle, FName OutputName, EMetaSoundBuilderResult& OutResult) -> FMetaSoundBuilderNodeOutputHandle\n   - SetNodeInputDefault(FMetaSoundBuilderNodeInputHandle& NodeInputHandle, FMetasoundFrontendLiteral& Literal, EMetaSoundBuilderResult& OutResult) -> void\n\n3. UMetaSoundSourceBuilder (extends UMetaSoundBuilderBase)\n   - Audition(UObject* Parent, UAudioComponent* AudioComponent, FOnCreateAuditionGeneratorHandleDelegate OnCreateGenerator, bool bLiveUpdatesEnabled) -> void\n   - SetFormat(EMetaSoundOutputAudioFormat OutputFormat, EMetaSoundBuilderResult& OutResult) -> void\n   - SetBlockRateOverride(float BlockRate) -> void\n   - SetSampleRateOverride(int32 SampleRate) -> void\n   - SetQuality(FName Quality) -> void\n\nBLUEPRINT FUNCTIONS (available):\n- Add MetaSound Node By ClassName\n- Add MetaSound Node From Asset Class\n- Connect Nodes\n- Connect Node Inputs to Matching Graph Interface Inputs\n- Set Node Input Default\n- Build And Overwrite MetaSound\n- Build New MetaSound\n- Audition\n\nMISSING/NOT FOUND IN PUBLIC DOCS:\n- BuildToAsset (method)\n- SetNodeLocation (method)\n- AddGraphInputNode/AddGraphOutputNode (method signatures)\n- AddInterface (method signature)\n- Full EMetaSoundBuilderResult enum definition\n- FMetasoundFrontendClassName constructor details\n- Full FMetasoundFrontendLiteral usage\n\nHANDLE TYPES CONFIRMED:\n- FMetaSoundNodeHandle - Handle to a node in graph\n- FMetaSoundBuilderNodeInputHandle - Handle to node input pin\n- FMetaSoundBuilderNodeOutputHandle - Handle to node output pin\n- Handles should NOT be serialized (change between versions)\n\nRESEARCH GAPS:\n- AddNode in C++ takes TScriptInterface, but Blueprint version may take ClassName string\n- BuildToAsset may be on a different builder class or named differently\n- SetNodeLocation may be editor-only (not runtime)\n- EMetaSoundBuilderResult enum values unknown (Success/Failure likely but unconfirmed)",
      "type": "tip",
      "tags": [
        "tip",
        "api",
        "UE5",
        "MetaSounds",
        "Builder API",
        "API signatures",
        "research"
      ],
      "timestamp": "2026-02-07T02:27:52.737Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T02:27:52.737Z",
      "lastVerified": "2026-02-07T02:27:52.737Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770455434866_qtj0f68z9",
      "content": "UE5 C++ Plugin Modernization Complete (2026-02-07):\n8 steps, 13 files modified, 1 new file (AudioMCPNodeRegistry.h).\n\nKey fixes applied:\n1. Build: \"Metasound\" → \"MetaSound\" in .uplugin, added \"UnrealEd\" dep\n2. GC: TStrongObjectPtr<UMetaSoundBuilderBase> replaces raw pointer\n3. API: Audition uses editor world (not nullptr), case-insensitive asset_type, graph input defaults\n4. Shutdown: SignalShutdown() before StopListening() prevents deadlock\n5. Security: Function allowlist (17 safe audio functions), WorldContextObject auto-fill\n6. TCP: SendExact helper, Socket::Wait for data (not polling), thread_local reusable payload buffer, response size guard\n7. Ping: FModuleManager::IsModuleLoaded replaces IPluginManager::FindEnabledPlugin\n8. NodeTypeMap externalized to AudioMCPNodeRegistry.h\n\nCritical bug found & fixed: WorldContextObject not auto-filled for UGameplayStatics ProcessEvent calls.\nFile sizes post-refactor: largest is AudioMCPBuilderManager.cpp at 512 lines (was 539). Total: 1,776 lines across 8 .cpp files.",
      "type": "error",
      "tags": [
        "error",
        "api",
        "ue5-plugin",
        "c++",
        "modernization",
        "fix-log"
      ],
      "timestamp": "2026-02-07T09:10:34.866Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T09:10:34.866Z",
      "lastVerified": "2026-02-07T09:10:34.866Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770455435502_exycz0v3i",
      "content": "UE5 C++ Plugin Review (2026-02-07):\n- 20 files, ~2100 lines reviewed across 13 primary + 7 supporting files\n- All 5 modernization criteria PASS: TStrongObjectPtr consistent, .Get()/.IsValid() correct, shutdown order correct, SendExact for both header/payload, wire protocol matches Python\n- CRITICAL BUG: BlueprintCommands.cpp ProcessEvent on UGameplayStatics CDO does NOT populate WorldContextObject param. All allowlisted functions (PlaySound2D, SpawnSoundAtLocation, etc.) require it. Will crash or silently fail.\n- WARNING: AudioMCPBuilderManager.h forward-declares FMetaSoundBuilderNodeOutputHandle/InputHandle but uses them as TMap value types (needs full definition)\n- WARNING: AudioMCPTcpServer.h missing #include \"HAL/ThreadSafeBool.h\" (used on line 59)\n- WARNING: Null FMetaSoundNodeHandle passed to FindNodeInputByName for graph input defaults (line 167 of BuilderManager.cpp) - fragile, may silently fail",
      "type": "warning",
      "tags": [
        "warning",
        "python",
        "ue5-plugin",
        "code-review",
        "critical-bug",
        "cpp"
      ],
      "timestamp": "2026-02-07T09:10:35.502Z",
      "context": "Full review of UE5 C++ Audio MCP plugin after modernization",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T09:10:35.502Z",
      "lastVerified": "2026-02-07T09:10:35.502Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770457662241_gpzvok6pf",
      "content": "Python-side MCP tools exploration complete. Key findings:\n\n## UE5PluginConnection (connection.py)\n- Location: `/Users/radek/Documents/GIthub/UE5-WWISE/src/ue_audio_mcp/ue5_connection.py`\n- Singleton pattern: `get_ue5_connection()` (line 120-125)\n- TCP socket to 127.0.0.1:9877, 30s timeout, 4-byte big-endian length prefix + UTF-8 JSON\n- Methods:\n  - `connect(host, port)` → returns dict\n  - `disconnect()` → closes socket\n  - `is_connected()` → checks socket via getpeername()\n  - `send_command(command)` → sends JSON dict, receives response dict (line 79-96)\n  - `_recv_response()` → reads length-prefixed JSON (line 98-107)\n\n## MetaSounds Tools (metasounds.py)\n- Location: `/Users/radek/Documents/GIthub/UE5-WWISE/src/ue_audio_mcp/tools/metasounds.py`\n- 4 tools, no Builder API commands (those are in ms_builder.py)\n- Tools: ms_list_nodes, ms_node_info, ms_search_nodes, ms_list_categories\n- All query METASOUND_NODES catalogue, no C++ plugin interaction\n\n## MetaSounds Builder Tools (ms_builder.py)\n- Location: `/Users/radek/Documents/GIthub/UE5-WWISE/src/ue_audio_mcp/tools/ms_builder.py`\n- 7 tools that call send_command via UE5PluginConnection:\n  1. `ms_build_graph()` (line 27-64) - validates, converts, sends all commands\n  2. `ms_create_source()` (line 68-88) - action: \"create_builder\"\n  3. `ms_add_node()` (line 92-120) - action: \"add_node\"\n  4. `ms_connect_pins()` (line 124-152) - action: \"connect\"\n  5. `ms_set_default()` (line 156-183) - action: \"set_default\"\n  6. `ms_save_asset()` (line 187-210) - action: \"build_to_asset\"\n  7. `ms_audition()` (line 214-228) - action: \"audition\"\n\n## Builder Command Protocol\n- Location: `graph_to_builder_commands()` in `/Users/radek/Documents/GIthub/UE5-WWISE/src/ue_audio_mcp/knowledge/graph_schema.py` (line 239-343)\n- Command sequence:\n  1. create_builder {asset_type, name}\n  2. add_interface {interface} (per interface)\n  3. add_graph_input {name, type, default?}\n  4. add_graph_output {name, type}\n  5. add_node {id, node_type, position}\n  6. set_default {node_id, input, value} (per non-None default)\n  7. connect {from_node, from_pin, to_node, to_pin}\n  8. build_to_asset {name, path}\n\n## Orchestration Layer (systems.py)\n- Location: `/Users/radek/Documents/GIthub/UE5-WWISE/src/ue_audio_mcp/tools/systems.py`\n- PATTERNS dict (line 31-143): gunshot, footsteps, ambient, spatial, ui_sound, weather\n- Each pattern has: ms_template, wwise_template, bp_template, default_params, connections\n- `build_audio_system()` tool (line 412-494): orchestrates all 3 layers\n- Helper functions:\n  - `_load_ms_template()` (line 167-191) - loads JSON, applies param overrides\n  - `_load_bp_template()` (line 194-218) - loads BP JSON if exists\n  - `_build_wwise_layer()` (line 221-260) - executes or plans Wwise\n  - `_build_metasounds_layer()` (line 296-355) - loads, validates, converts, executes MS\n  - `_build_blueprint_layer()` (line 358-371) - loads BP template (no execution)\n  - `_build_connection_map()` (line 374-405) - cross-layer wiring\n\n## Preset Support in C++ Plugin\n- Location: `/Users/radek/Documents/GIthub/UE5-WWISE/ue5_plugin/UEAudioMCP/Source/UEAudioMCP/Private/AudioMCPBuilderManager.cpp` (line 71-73)\n- CreatePresetBuilder is already implemented\n- asset_type validation includes \"Preset\" (line 30-36)\n- No dedicated preset-specific commands yet (only create_builder with asset_type=\"Preset\")\n\n## Tests\n- `/Users/radek/Documents/GIthub/UE5-WWISE/tests/test_systems.py` covers offline/wwise-only/full modes\n- No preset-specific tests yet\n",
      "type": "concept",
      "tags": [
        "concept",
        "python",
        "api",
        "UE5-WWISE",
        "MetaSounds",
        "MCP",
        "architecture",
        "exploration"
      ],
      "timestamp": "2026-02-07T09:47:42.241Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T09:47:42.241Z",
      "lastVerified": "2026-02-07T09:47:42.241Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770457665157_8gk77li6q",
      "content": "## UE5 C++ Plugin - Command Dispatch and Builder Architecture\n\n### Command Dispatch System\n**Key File**: AudioMCPCommandDispatcher.cpp (lines 1-127)\n- Dispatch flow: JSON parse → extract \"action\" field → lookup in CommandMap → post AsyncTask to GameThread → wait on FEvent (25s timeout)\n- Thread-safe via TSharedPtr heap-allocated FDispatchState struct containing Result, CompletionEvent, Handler, Params, BuilderMgr\n- SignalShutdown prevents new AsyncTasks during module shutdown (prevents deadlock)\n- All responses include echoed \"action\" field for request-response matching\n\n### Registered Commands (11 Total)\n**Module.cpp lines 64-99** - RegisterCommands():\n1. **ping** → FPingCommand\n2. **create_builder** → FCreateBuilderCommand (asset_type, name)\n3. **add_interface** → FAddInterfaceCommand (interface name)\n4. **add_graph_input** → FAddGraphInputCommand (name, type, optional default)\n5. **add_graph_output** → FAddGraphOutputCommand (name, type)\n6. **add_node** → FAddNodeCommand (id, node_type, optional position [x,y])\n7. **set_default** → FSetDefaultCommand (node_id, input, value)\n8. **connect** → FConnectCommand (from_node, from_pin, to_node, to_pin; handles __graph__ sentinel)\n9. **build_to_asset** → FBuildToAssetCommand (name, path /Game/...)\n10. **audition** → FAuditionCommand (no required params)\n11. **call_function** → FCallFunctionCommand (function, args object; allowlist protection)\n\n### Builder Command Implementations\n**BuilderCommands.cpp**:\n- **create_builder** (13-49): Calls BuilderSubsystem.CreateSourceBuilder/PatchBuilder/PresetBuilder, resets NodeHandles/GraphI/O maps\n- **add_interface** (55-73): Builder.AddInterface(FName)\n- **add_graph_input** (79-182): Builder.AddGraphInputNode(), stores OutputHandle in GraphInputOutputHandles map, applies JSON default value (numeric/bool/string)\n- **add_graph_output** (184-207): Builder.AddGraphOutputNode(), stores InputHandle in GraphOutputInputHandles map\n- **build_to_asset** (149-188): Validates path (must start /Game/, no ..), calls Builder.BuildToAsset(FName path)\n- **audition** (194-210): Calls Builder.Audition(World) after #WITH_EDITOR check\n\n### Node Registry\n**AudioMCPNodeRegistry.h** - 65+ hardcoded mappings via InitNodeTypeMap():\n- Generators: Sine, Noise, WhiteNoise, LFO, Oscillator, Saw, Square, Triangle, Pulse, WaveTable, Granulator\n- Filters: BiquadFilter, StateVariableFilter (UE::State Variable Filter::Audio), Lowpass, Highpass, Bandpass, Ladder, OnePole variants\n- Math: Gain, Multiply, Add, Subtract, Divide, Clamp, MapRange, Interpolate, SampleAndHold\n- Effects: Delay, StereoDelay, Reverb, Chorus, Phaser, Flanger\n- Dynamics: Compressor, Limiter, Gate\n- Triggers: TriggerRepeat, TriggerCounter, TriggerControl, TriggerOnThreshold, TriggerDelay, TriggerRoute\n- Conversions: BPMToSeconds, FreqToMIDI, MIDIToFreq, SemitonesToFreqMultiplier, dBToLinear, LinearToDb, FloatToAudio, AudioToFloat\n- Routing: MonoToStereo, StereoToMono, Send, Receive\n- Spatialization: ITDPanner, StereoPanner\n- Variables: Get, Set\n\n**Lookup Strategy** (BuilderManager.cpp 489-512):\n1. Direct lookup in NodeTypeMap\n2. If DisplayName contains \"::\", use as full class name directly\n3. Else error with suggestion to use ms_search_nodes\n\n### Node/Pin/Graph I/O Management\n**BuilderManager.cpp**:\n- **AddNode** (213-259): Validates NodeId (forbids __graph__ sentinel), calls ResolveNodeType, stores FMetaSoundNodeHandle in NodeHandles map, sets position\n- **SetNodeDefault** (261-319): Looks up node handle, finds input pin by name, converts JSON value to FMetasoundFrontendLiteral (number→float, bool→bool, string→string)\n- **ConnectNodes** (321-405): \n  - From side: if FromNode == \"__graph__\", lookup in GraphInputOutputHandles; else lookup NodeHandles then FindNodeOutputByName\n  - To side: if ToNode == \"__graph__\", lookup in GraphOutputInputHandles; else lookup NodeHandles then FindNodeInputByName\n  - Calls Builder.ConnectNodes(OutputHandle, InputHandle)\n\n### Blueprint Command\n**BlueprintCommands.cpp** (46-100+):\n- **call_function** security: allowlist check (PlaySound2D, SpawnSoundAtLocation, SetSoundMixClassOverride, etc.) — only audio-safe functions allowed\n- Searches: 1) UGameplayStatics.StaticClass(), 2) World, 3) PlayerController\n- Uses reflection: FindFunctionByName, ProcessEvent with params from JSON args object\n- Prevents arbitrary function execution (no QuitGame, DestroyActor, etc.)\n\n### TCP Server Architecture\n**AudioMCPTcpServer.cpp**:\n- One-at-a-time client handling on dedicated FRunnable thread\n- Message format: 4-byte big-endian uint32 length + UTF-8 JSON payload (matches Python ue5_connection.py)\n- Bound to 127.0.0.1:9877 only (localhost security)\n- 60s idle timeout to prevent zombie connections\n- RecvExact/SendExact loop until disconnect or error\n- Socket buffers: 65536 bytes\n\n### Extension Points for New Commands\nTo add new commands (e.g., graph variables, presets, graph pages, transaction listeners):\n1. Create new class in Public/Commands/ inheriting from IAudioMCPCommand\n2. Implement Execute() method returning TSharedPtr<FJsonObject>\n3. Add corresponding builder method to FAudioMCPBuilderManager if needed\n4. Register in FUEAudioMCPModule::RegisterCommands() via Dispatcher->RegisterCommand()\n\nKey data structures already available:\n- NodeHandles: TMap<FString, FMetaSoundNodeHandle> for node references\n- GraphInputOutputHandles: TMap<FString, FMetaSoundBuilderNodeOutputHandle> for graph I/O\n- ActiveBuilder: TStrongObjectPtr<UMetaSoundBuilderBase> for Builder API access",
      "type": "tip",
      "tags": [
        "tip",
        "python",
        "api",
        "ue5-plugin",
        "command-dispatch",
        "builder-api",
        "architecture"
      ],
      "timestamp": "2026-02-07T09:47:45.157Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T09:47:45.157Z",
      "lastVerified": "2026-02-07T09:47:45.157Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770465054026_5o5y3zzgp",
      "content": "Craig Owen Crossfade Tutorial - Complete Weapon Audio System Architecture\n\nTHREE LEVELS:\n1. MetaSoundSource (outer) - WaveAsset array inputs plugged from content, Source.OneShot interface\n2. Routing logic - MSP_Switch for room selection, Trigger Compare (Int32, RoomSize==0) gates outdoor tails, MSP_CrossFade for distance, Stereo Mixer (5) combines both\n3. MSP Patches (inner, reusable) - generic engines that work for any content\n\nKEY NODES (confirmed pins from screenshots):\n- Shuffle (WaveAsset:Array): Next, Shuffle, Reset Seed, In Array, Seed[-1], Auto Shuffle, Enable Shared State → On Next, On Shuffle, On Reset Seed, Value\n- Wave Player (2.0, Stereo): Play, Stop, Wave Asset, Start Time, Pitch Shift, Loop → On Play, On Finished, On Looped, Playback Time, Out Left, Out Right\n- Trigger Compare (Float): Compare, A, B, Type(Enum) → True, False\n- Trigger Compare (Int32): Compare, A, B, Type(Enum) → True, False\n- Stereo Mixer (3): In 0-2 L/R, Gain 0-2 (Lin) → Out L, Out R\n- Mid-Side Encode: In Left, In Right, Spread Amount[0.0], Equal Power → Out Mid, Out Side\n- Mid-Side Decode: In Mid, In Side, Spread Amount[0.5], Equal Power → Out Left, Out Right\n- Trigger Any (3): In 0, In 1, In 2 → Out\n\nCROSSFADE INTERNALS (22 nodes per patch):\n- Layer A: 1 gate (Less Than EndFadeOut+0.01) → Shuffle → WavePlayer → MapRange(1→0) → Mixer Gain 0\n- Layer B: 2 gates (Greater Than StartFadeIn-0.01 AND Less Than EndFadeOut+0.01) → Shuffle → WavePlayer → MapRange(0→1) × MapRange(1→0) = bell curve → Mixer Gain 1\n- Layer C: 1 gate (Greater Than StartFadeIn-0.01) → Shuffle → WavePlayer → MapRange(0→1) → Mixer Gain 2\n- Output: Stereo Mixer (3) → Output_L/R + Mid-Side Encode(0.0)→Decode(0.5)→AudioMono\n- All OnFinished → Trigger Any (3) → OnFinished\n\nPIN METADATA: Sort Order (0,5,10...) for logical grouping, Range (0-100000), Widget (Knob), Value Type (Linear)\n\nDESIGN PRINCIPLES:\n- Sounds plugged OUTSIDE (WaveAsset arrays), patches are generic engines\n- Trigger Compare gates prevent silent voice processing (optimization)\n- Safety offset ±0.01 on boundaries prevents flickering\n- Mid layer uses Multiply trick: two MapRanges × together = bell curve\n- Same patch works for guns, wind, engines, footsteps",
      "type": "concept",
      "tags": [
        "concept",
        "optimization",
        "metasounds",
        "crossfade",
        "weapon-audio",
        "craig-owen",
        "tutorial",
        "patterns",
        "nodes"
      ],
      "timestamp": "2026-02-07T11:50:54.026Z",
      "context": "From Craig Owen video tutorial on crossfade-by-parameter MetaSounds patches, analyzed via multiple UE5 editor screenshots",
      "accessCount": 1,
      "lastAccessed": "2026-02-07T11:54:06.223Z",
      "lastVerified": "2026-02-07T11:50:54.026Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770470251417_r0toyz4p4",
      "content": "TechAudioTools SFX Generator captured (2026-02-07): Added Plate Reverb node to catalogue (125 total nodes, was 124). Created sfx_generator.json MetaSounds template (full synth topology: Generator→Spectral Effects→SVF Filter→ADSR Amplifier→Parallel Send Effects) and sfx_generator_widget.json Blueprint template (Preset Widget controller: Builder init, ViewModel binding, Output Watch delegates, hierarchical randomization with lock/scope). Updated CREDITS.md with Eric Buchholz section. Key architecture: spectral effects in SERIES (WaveShaper→BitCrusher→RingMod), temporal effects in PARALLEL (Delay+Flanger+PlateReverb mixed back). SVF crossfade filter = DJ-style LP↔BP↔HP. Envelope Follower on output detects completion including effect tails. Wave Writer for capturing output to wav. Audio Buses feed mid-graph data to analyzer widgets. TechAudioTools also includes MetaSound Input Migrator and Metadata Editor tools. 21 MetaSounds + 16 Blueprint = 37 total templates.",
      "type": "concept",
      "tags": [
        "concept",
        "templates",
        "sfx-generator",
        "tech-audio-tools",
        "eric-buchholz",
        "metasounds",
        "synthesis"
      ],
      "timestamp": "2026-02-07T13:17:31.417Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T13:17:31.417Z",
      "lastVerified": "2026-02-07T13:17:31.417Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770470894916_pqe47gxyx",
      "content": "Audio-Driven Gameplay Learning Path research complete (2026-02-07). 3 courses, 12+ tutorials on Epic Dev Community. Key patterns: (1) Amplitude via Submix Envelope Following -> game parameter, (2) Frequency via Submix Spectral Analysis (FFT) -> game parameter, (3) Microphone via Audio Capture Component -> Submix -> analysis -> game event, (4) NRT via Synesthesia (LoudnessNRT/ConstantQNRT/OnsetNRT) -> timed events. UE5 equivalents: MetaSounds Envelope Follower node for amplitude, Submix spectral analysis still works, Synesthesia plugin fully available. MetaSounds does NOT have native FFT/spectral nodes. Research file: /Users/radek/Documents/GIthub/UE5-WWISE/research/research_audio_driven_gameplay.md",
      "type": "general",
      "tags": [
        "general",
        "ue5",
        "audio-analysis",
        "blueprint-nodes",
        "metasounds",
        "research",
        "audio-driven-gameplay"
      ],
      "timestamp": "2026-02-07T13:28:14.915Z",
      "context": "Research for UE5-WWISE MCP project - audio-driven gameplay patterns that could be implemented as MCP tools",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T13:28:14.915Z",
      "lastVerified": "2026-02-07T13:28:14.915Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770470912376_7mqv1yy2p",
      "content": "Researched \"Ambient and Procedural Sound Design\" Epic Dev Community learning path by Richard Stevens & Dave Raybould. Course code qR, UE 4.23-4.24, 2h16m runtime, 15 individual tutorials. Covers: area loops, source loops, one-shots (Sound Cue Random+Delay+Loop), 3 occlusion methods (fake switching, ambient zones, raycasting), procedural randomization/modulation/layering, Blueprint audio systems (SpawnSoundAtLocation, AudioComponent control, Spline movement). Key UE5 migration: Sound Cues -> MetaSounds for procedural audio, Audio Volumes -> Audio Gameplay Volumes (5.1+), Soundscape plugin for procedural ambient. Same authors offer UE5 follow-up \"MetaSounds & More\" courses (Foundation + Control & Communication, 7+ hours, $230 each). Full research at research/research_ambient_procedural_sound_design.md",
      "type": "general",
      "tags": [
        "general",
        "ue5",
        "audio",
        "research",
        "epic-dev-community",
        "ambient",
        "procedural",
        "sound-design",
        "metasounds",
        "blueprints",
        "stevens-raybould"
      ],
      "timestamp": "2026-02-07T13:28:32.376Z",
      "context": "Research task for UE5-WWISE project, cataloguing Epic learning paths for game audio",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T13:28:32.376Z",
      "lastVerified": "2026-02-07T13:28:32.376Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770471047280_w5qgz0o63",
      "content": "Quartz Music System research completed (2026-02-07). Key findings:\n- Course by Richard Stevens on Epic Dev Community: 14 tutorials covering looping music, playlists, one-shots, core Quartz, layer mixing (direct/timelines/curves), arrangement switching, quantized transitions, stingers, tempo changes, advanced Quartz\n- Course URL: https://dev.epicgames.com/community/learning/courses/XAw/unreal-engine-quartz-music-system\n- UE 4.27 project on Fab (free), all concepts transfer directly to UE5\n- Core API: UQuartzSubsystem -> CreateNewClock -> UQuartzClockHandle -> PlayQuantized/SubscribeToQuantizationEvent\n- Key struct: FQuartzQuantizationBoundary (Quantization type + Multiplier + CountingReferencePoint)\n- EQuartzCommandQuantization enum: Bar, Beat, WholeNote, HalfNote, QuarterNote, EighthNote, SixteenthNote, ThirtySecondNote, plus dotted/triplet variants\n- Quartz API is STABLE from UE 4.26 through UE 5.7 - no breaking changes\n- UE5 adds MetaSounds integration (triggers driven by Quartz clock) and Harmonix Plugin (UE 5.4+, MIDI sequencing)\n- Above Noise Studios has excellent UE5 vertical remixing tutorial with GitHub project\n- Research file: /Users/radek/Documents/GIthub/UE5-WWISE/research/research_quartz_music_system.md\n- Implications for MCP: need Quartz clock tools in C++ plugin + Blueprint layer, maps to WHEN layer in architecture",
      "type": "concept",
      "tags": [
        "concept",
        "api",
        "quartz",
        "research",
        "ue5",
        "music-system",
        "blueprint"
      ],
      "timestamp": "2026-02-07T13:30:47.280Z",
      "context": "UE5-WWISE project research on Quartz Music System for dynamic/interactive music",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T13:30:47.280Z",
      "lastVerified": "2026-02-07T13:30:47.280Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770473626141_trwk184bt",
      "content": "Ambient & Procedural Sound Design extraction complete (2026-02-07). 5 new Blueprint templates from Stevens & Raybould UE 4.23 project at \"/Volumes/Koshi_T7 1/UN5.3/AmbientandProceduralSound\". Templates: ambient_spline_movement (Timeline→SplineComponent→SetRelativeLocation), ambient_height_wind (SphereOverlap→MapRangeClamped→VolumeMultiplier, creak threshold at 0.8), ambient_weighted_trigger (RandomBoolWithWeight probability gate), player_oriented_sound (Forward/Right/Up vectors + RandomFloatInRange → SpawnSoundAtLocation), audio_visualiser (BP_GetAttenuationSettingsToApply → spawn debug spheres). Sound Class hierarchy: Master→Area_Loops+Source_Loops+One_Shots+Footsteps+Foley+Night_Day+Dialogue. All UE 4.23 node names — may need updating with 20K node database. 42 total templates (21 MS + 21 BP). 243 tests passing.",
      "type": "troubleshooting",
      "tags": [
        "troubleshooting",
        "database",
        "templates",
        "ambient",
        "procedural",
        "stevens-raybould",
        "ue4",
        "extraction"
      ],
      "timestamp": "2026-02-07T14:13:46.141Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T14:13:46.141Z",
      "lastVerified": "2026-02-07T14:13:46.141Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770478466721_fdco4ciyl",
      "content": "MetaSounds Pin/Node Name Changes Required\n\nAll references found in 22 JSON templates under /Users/radek/Documents/GIthub/UE5-WWISE/src/ue_audio_mcp/templates/metasounds/\n\nOLD PIN NAMES TO UPDATE:\n- WaveAsset → Wave Asset (in \"to_pin\" connections to wave_player input)\n- PitchShift → Pitch Shift (in \"to_pin\" connections to wave_player input)  \n- StartTime → Start Time (in wave_player defaults)\n- LoopStart → Loop Start (in wave_player defaults)\n- LoopDuration → Loop Duration (in wave_player defaults)\n- OnFinished → On Finished (output pin from Wave Player)\n- OnLooped → On Looped (output pin from Wave Player)\n- Array → In Array (input to Array Random Get / Random Get)\n- Trigger → Next (input to Array Random Get / Random Get)\n- NoRepeat → No Repeats (default in Array Random Get / Random Get)\n- Audio L → Out Left (output from Stereo Mixer when connected to __graph__)\n- Audio R → Out Right (output from Stereo Mixer when connected to __graph__)\n\nOLD NODE TYPES:\n- \"Array Random Get\" → \"Random Get (WaveAsset:Array)\" or similar pattern\n- Output \"Trigger\" on Array Random Get → \"On Next\"\n\nKEY FINDINGS:\n1. random_playback.json already uses correct NEW names (On Next, In Array, Wave Asset, No Repeats, On Finished)\n2. Older templates use OLD names consistently\n3. Crossfade nodes Output_L/Output_R are NOT changed (keep as-is) - different pin naming convention\n4. Index pin only appears in 2 locations (sound_pad.json, footsteps.json) but NOT being changed by user request\n5. Internal node output pins like \"Audio\", \"Out\", \"Value\" keep their current names\n6. Graph-level output pins vary (Out Left, Out Right, Out Mono, Out Stereo L, etc.) - THESE ARE NOT BEING CHANGED\n\nFiles affected: 22 total templates, 18+ have at least one old name to update",
      "type": "concept",
      "tags": [
        "concept",
        "pin-names",
        "metasounds",
        "wave-player",
        "random-get",
        "templates",
        "wave-asset",
        "pitch-shift"
      ],
      "timestamp": "2026-02-07T15:34:26.721Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T15:34:26.721Z",
      "lastVerified": "2026-02-07T15:34:26.721Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770577128548_g3agiwqst",
      "content": "## MetaSounds FM Synthesis — CONFIRMED POSSIBLE\n\n**I was WRONG** — FM synthesis IS possible in MetaSounds. Here's how:\n\n### Oscillator Pin Layout (Sine/Saw/Square/Triangle — all identical):\n- **Frequency** (Float) — base frequency, block-rate\n- **Modulation** (Audio) — audio-rate frequency modulation input\n- **Phase Offset** (Float) — 0-360 degrees\n- **Sync** (Trigger) — hard sync reset\n- **Glide** (Float) — portamento\n- **Bi Polar** (Bool)\n- **Enabled** (Bool)\n- **Pulse Width** (Float, Square only)\n\n### FM Chain:\nModulator Osc → (Audio out) → Map Range (scale to Hz) → Carrier Osc \"Modulation\" pin\n\n### Key Facts:\n1. **Modulation pin is Audio-rate** — this IS true FM synthesis at sample rate\n2. **Sync pin exists** — Trigger type, can hard-sync oscillators (SID sync!)\n3. **Phase Offset exists** — Float, can set starting phase\n4. Feedback loops work with Delay node breaking the cycle (DAG constraint)\n5. Custom C++ nodes possible via IMetaSoundOperatorFactory\n6. Delay nodes have built-in Feedback pin\n\n### What This Means:\n- SID 6581 emulation: ~95% possible (was 85%, now have Sync!)\n- ESFM/FM synthesis: ~80% possible (was 40%, Modulation pin is the key)\n- Feedback loops: Possible via Delay nodes\n- Custom nodes: Full C++ extensibility for anything missing\n\n### Our Node DB Corrections Needed:\n- Sine/Saw/Square/Triangle nodes need Modulation (Audio), Sync (Trigger), Phase Offset (Float), Glide (Float), Bi Polar (Bool), Enabled (Bool) pins added\n- Delay node has Max Delay Time pin we're missing",
      "type": "general",
      "tags": [
        "general",
        "metasounds",
        "fm-synthesis",
        "correction",
        "oscillator-pins",
        "sid-chip"
      ],
      "timestamp": "2026-02-08T18:58:48.548Z",
      "context": "Correcting earlier wrong assumption that MetaSounds can't do FM synthesis. The Modulation (Audio) pin on all oscillators enables true audio-rate FM.",
      "accessCount": 0,
      "lastAccessed": "2026-02-08T18:58:48.548Z",
      "lastVerified": "2026-02-08T18:58:48.548Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770580962141_psk2mp35l",
      "content": "Epic MetaSounds pin migration complete. 144 nodes, 798 pins, 262 tests passing. Key gotchas: (1) Pin rename dicts must use (node, pin, direction) keys - same pin name for input+output causes dict overwrite. (2) Never do blanket string replacements like _in(\"In\", \"Audio\") -> _in(\"In\", \"Float\") - must scope to specific node block. (3) Epic docs use shorthand notation (In X, A / B, Out Left / Right) that are NOT real API pin names - must be removed from DB. (4) Math nodes (Add, Multiply, etc.) have no pins listed on Epic's page but A/B/Result are the correct API names. (5) ITD Panner: Azimuth→Angle, Audio→In, Audio L/R→Out Left/Right. (6) Scraper: scripts/scrape_metasound_nodes.py, data: scripts/ms_node_specs.json",
      "type": "warning",
      "tags": [
        "warning",
        "api",
        "ue5",
        "metasounds",
        "migration",
        "pins",
        "gotchas"
      ],
      "timestamp": "2026-02-08T20:02:42.141Z",
      "context": "UE5-WWISE project, Epic MetaSounds Function Nodes Reference scraping and pin migration",
      "accessCount": 0,
      "lastAccessed": "2026-02-08T20:02:42.141Z",
      "lastVerified": "2026-02-08T20:02:42.141Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770582373126_8k65njk5k",
      "content": "UE 5.7 MetaSounds Custom Node C++ API research complete. Key findings:\n\n1. Module deps: MetasoundGraphCore + MetasoundFrontend + AudioMixer (already in UEAudioMCP.Build.cs)\n2. TExecutableOperator pattern: FOperator with Execute()+Reset(), state in private members\n3. Stereo outputs: separate FAudioBufferWriteRef per channel (Out Left, Out Right)\n4. Trigger pins: FTriggerReadRef + ExecuteBlock() with lambdas for sample-accurate processing\n5. Enum pins: DECLARE_METASOUND_ENUM + TEnumReadRef<EMyEnum>, use switch() in Execute()\n6. State management: private operator members (phase, envelope level, filter state) persist across Execute() calls\n7. Sample rate: FOperatorSettings.GetSampleRate() / GetNumFramesPerBlock() in constructor\n8. Engine examples: Engine/Plugins/Runtime/Metasound/Source/MetasoundStandardNodes/Private/ (Sine, Biquad, ADSR, LFO, Delay)\n9. Registration: METASOUND_REGISTER_NODE(FMyNode) + FNodeFacade + GetVertexInterface()\n\nResearch doc: /Users/radek/Documents/GIthub/UE5-WWISE/research/research_metasound_custom_nodes_cpp.md (69KB, 850+ lines, 10 sections, complete code examples)",
      "type": "concept",
      "tags": [
        "concept",
        "api",
        "metasounds",
        "custom-nodes",
        "cpp-api",
        "ue5.7",
        "dsp",
        "operator-pattern"
      ],
      "timestamp": "2026-02-08T20:26:13.126Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-08T20:26:13.126Z",
      "lastVerified": "2026-02-08T20:26:13.126Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770585044223_z4ldkiunh",
      "content": "UE5 Plugin Architecture Analysis Complete\n\n## Plugin Structure\n- **Descriptor**: UEAudioMCP.uplugin (PostEngineInit, MetaSound plugin dependency)\n- **Build**: UEAudioMCP.Build.cs (Editor-only, 6 public + 8 private dependencies)\n- **26 source files**: 14 headers + 12 implementations across Public/Private\n\n## Core Architecture\n1. **TCP Server** (FAudioMCPTcpServer)\n   - FRunnable on dedicated thread\n   - Accepts 1 client at a time\n   - 4-byte big-endian length + UTF-8 JSON (4-16MB messages)\n   - Bound to 127.0.0.1:9877, 1s WaitForPendingConnection loop\n   - RecvExact/SendExact handle partial sends/receives\n   - 60s idle timeout per client\n\n2. **Command Dispatcher** (FAudioMCPCommandDispatcher)\n   - Maps action→handler (TMap)\n   - Posts AsyncTask(GameThread) with FDispatchState heap-allocated\n   - FEvent synchronization, 25s timeout (under Python's 30s)\n   - bShuttingDown flag prevents deadlock during module unload\n   - Returns JSON response with echoed action field\n\n3. **Builder Manager** (FAudioMCPBuilderManager)\n   - TStrongObjectPtr<UMetaSoundBuilderBase> prevents GC\n   - Tracks: active builder, node handles, graph I/O maps\n   - NodeTypeMap (165+ entries): display-name→\"UE::Name::Variant\" format\n   - BuildNodeTypeMap() called once on first use\n   - Graph I/O: input outputs feed in, output inputs receive from\n\n4. **Node Registry** (AudioMCPNodeRegistry.h)\n   - Static InitNodeTypeMap() inline function\n   - 165 display-name mappings across 14 categories\n   - Covers oscillators, envelopes, filters, math, effects, spatial, noise, triggers\n\n## Command System (22 total)\n### Builder Lifecycle (3)\n- create_builder, add_interface, add_graph_input, add_graph_output\n\n### Node Operations (3)\n- add_node (with position), set_default (JSON value), connect (handles __graph__)\n\n### Build & Audition (4)\n- build_to_asset, audition, stop_audition, open_in_editor\n\n### Variables (UE 5.7) (3)\n- add_graph_variable, add_variable_get_node, add_variable_set_node\n\n### Preset Conversion (2)\n- convert_to_preset, convert_from_preset\n\n### Query (4)\n- get_graph_input_names, set_live_updates, list_node_classes, get_node_locations\n\n### Utility (2)\n- ping, call_function (Blueprint reflection)\n\n## Command Handler Pattern\n- IAudioMCPCommand interface: Execute(Params, BuilderManager) → JSON\n- Command classes: FCreateBuilderCommand, FAddNodeCommand, etc.\n- Params extracted via TryGetStringField, TryGetArrayField, TryGetBoolField\n- Errors via AudioMCP::MakeErrorResponse()\n- Success via AudioMCP::MakeOkResponse() + field additions\n\n## Wire Protocol Details\n- Header: uint32 big-endian network byte order\n- Payload: UTF-8 JSON (FUTF8ToTCHAR / FTCHARToUTF8)\n- RecvExact/SendExact: loop until Size bytes or error\n- WaitForData: Socket->Wait(ESocketWaitConditions::WaitForRead, timeout)\n- Response: header + payload, size guard at 16MB\n\n## Key Types\n- FMetaSoundNodeHandle: opaque node identifier\n- FMetaSoundBuilderNodeOutputHandle: for graph inputs\n- FMetaSoundBuilderNodeInputHandle: for graph outputs, audio channels\n- FName: UE string type (used for node class names)\n- FString: standard strings\n- TSharedPtr/TSharedRef: smart pointers\n\n## Module Startup/Shutdown\n- StartupModule: CreateBuilder → CreateDispatcher → RegisterCommands → StartTcpServer\n- RegisterCommands: 22 commands registered in order\n- ShutdownModule: SignalShutdown → StopTcpServer → Reset all pointers\n- Prevents in-flight AsyncTasks deadlock via bShuttingDown check\n\n## Blueprint Integration\n- call_function command for Blueprint reflection\n- ProcessEvent with proper InitializeValue/DestroyValue\n- BlueprintCommands.cpp handles reflection details\n\n## Key Gotchas\n- NodeTypeMap keying on display names, resolves via ResolveNodeType()\n- Graph I/O uses __graph__ sentinel for boundary connections\n- Preset creation requires existing Source/Patch (ConvertToPreset flow)\n- All UE API calls on game thread via AsyncTask dispatcher\n- TStrongObjectPtr prevents builder/component GC during operation\n- Builder names stored as FName, not checked for uniqueness\n",
      "type": "code",
      "tags": [
        "code",
        "python",
        "api",
        "ue5-plugin",
        "architecture",
        "tcp-server",
        "metasounds",
        "builder-api"
      ],
      "timestamp": "2026-02-08T21:10:44.223Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-08T21:10:44.223Z",
      "lastVerified": "2026-02-08T21:10:44.223Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770585079546_zq9im5dlj",
      "content": "## reSID C++ API Surface for UE5 MetaSounds Port\n\n### Core Classes & Type Definitions (from siddefs.h)\n- `reg4, reg8, reg12, reg16, reg24`: unsigned int type aliases for register widths\n- `cycle_count`: int for cycle counting\n- `sound_sample`: int for audio samples (16-bit signed)\n- `chip_model enum`: MOS6581 = 0, MOS8580 = 1\n- `sampling_method enum`: SAMPLE_FAST, SAMPLE_INTERPOLATE, SAMPLE_RESAMPLE_INTERPOLATE, SAMPLE_RESAMPLE_FAST\n\n### Main SID16 Class (sid.h)\n**Constructor/Destructor:**\n- `SID16()`: Initialize to MOS6581, 985248Hz clock, SAMPLE_FAST, 44100Hz output\n- `~SID16()`: Cleanup allocated memory\n\n**Configuration:**\n- `set_chip_model(chip_model)`: Switch between MOS6581/MOS8580\n- `enable_filter(bool)`: Toggle main filter\n- `enable_dithering(bool)`: Add noise to reduce quantization artifacts\n- `enable_external_filter(bool)`: Toggle output stage low/high-pass filters\n- `set_sampling_parameters(float clock, sampling_method, float sample_freq, float pass_freq, float filter_scale)`: Configure sampling\n\n**Core Audio I/O:**\n- `void clock()`: Advance 1 cycle\n- `void clock(cycle_count delta_t)`: Advance N cycles\n- `int clock(cycle_count& delta_t, short* buf, int n, int interleave)`: Generate N samples into buffer, return actual count\n- `int output()`: Get current 16-bit output sample (auto-scaled)\n- `int output(int bits)`: Get N-bit output sample\n- `void input(int sample)`: Feed external 16-bit audio (scaled up for mixing)\n\n**Register I/O (SID $D400-$D41F):**\n- `reg8 read(reg8 offset)`: Read register 0-31\n- `void write(reg8 offset, reg8 value)`: Write register 0-31\n- `void readRegisters(unsigned char* p)`: Dump all 32 registers\n\n**State Save/Load:**\n- `State read_state()`: Snapshot accumulator, rate counter, envelope state\n- `void write_state(const State&)`: Restore from snapshot\n\n**Voice Control (3 voices: 0-2):**\n- `setVoiceVolume(int v, int vol)`: 0-282, 256=unity\n- `getVoiceVolume(int v)`: Query voice volume\n- `enableVoiceVolume(bool)`: Master enable per-voice scaling\n- `setFM(int v, int source, int amount)`: FM cross-mod (source: 0=off, 1/2/3=voice)\n- `getFMSource(int v)`, `getFMAmount(int v)`: Query FM state\n- `enableFM(bool)`: Master enable FM\n\n**Filter Control:**\n- `setResBoost(int)`: 0-255, 0=stock, 255=self-oscillation\n- `getResBoost()`, `enableResBoost(bool)`: Resonance boost control\n- `setVoiceFreqDirect(int v, reg24 freq)`: Bypass register, set freq directly for audio-rate modulation\n- `setPulseWidthDirect(int v, reg12 pw)`: Direct pulse width modulation\n- `setFilterCutoffDirect(reg12 fc)`: Direct cutoff frequency\n\n**Monitoring (read-only):**\n- `getVoiceOutput(int v)`: Current voice amplitude after envelope\n- `getEnvelopeOutput(int v)`: Current envelope value\n- `getMasterVolume()`: Filter volume control (0-15)\n- `getFilterCutoff()`: Filter cutoff frequency (0-2047)\n- `getVoiceWaveform(int v)`: Previous waveform output (for FM)\n- `getVoiceFreq(int v)`: Current frequency\n- `getVoiceAccumulator(int v)`: Current phase accumulator\n\n### Voice Class (voice.h / voice_impl.h)\n**Structure:**\n- Contains WaveformGenerator + EnvelopeGenerator\n- Multiplying DAC: output = (waveform - wave_zero) * envelope + voice_DC\n\n**Methods:**\n- `set_chip_model(chip_model)`: Apply chip-specific DC offsets\n- `set_sync_source(Voice*)`: Hardwire sync from another voice\n- `writeCONTROL_REG(reg8)`: Write $D404/$D40B/$D412 (gate, test, sync, ring)\n- `reset()`: Return to initial state\n- `sound_sample output()`: Get current voice output (20-bit)\n\n**MOS6581 Specifics:**\n- wave_zero = 0x380 (12-bit waveform \"zero\" level)\n- voice_DC = 0x800 * 0xff (DC offset for multiplying DAC)\n\n### Waveform Generator (wave.h, 24-bit accumulator)\n**Key State:**\n- `reg24 accumulator`: Phase accumulator (24-bit, incremented by freq each cycle)\n- `reg24 freq`: Frequency register (16-bit, stored in lower 16 bits)\n- `reg12 pw`: Pulse width (12-bit, 0-4095)\n- `reg24 shift_register`: Noise source (23-bit LFSR)\n\n**Control Methods:**\n- `writeFREQ_LO(reg8)`, `writeFREQ_HI(reg8)`: Set frequency\n- `writePW_LO(reg8)`, `writePW_HI(reg8)`: Set pulse width\n- `writeCONTROL_REG(reg8)`: Gate, test (reset accumulator), sync, ring modulation\n- `readOSC()`: Read OSC3 (waveform output at accumulator MSB crossing)\n\n**Output:**\n- `short output()`: 12-bit waveform (0-4095 in MOS6581, 0-4095 in MOS8580)\n- Waveforms: Pulse, Sawtooth, Triangle, Pulse+Tri (ringmod internal)\n\n### Envelope Generator (envelope.h)\n**State Machine:**\n- States: ATTACK, DECAY_SUSTAIN, RELEASE, FREEZED\n- Gate bit = 1: ATTACK → DECAY_SUSTAIN (at max envelope)\n- Gate bit = 0: DECAY_SUSTAIN → RELEASE (or ATTACK → RELEASE)\n- Hold zero when frozen\n\n**Registers:**\n- Attack/Decay ($D405/$D40C): High/Low nibbles\n- Sustain/Release ($D406/$D40D): High/Low nibbles\n- Each rate value 0-15 maps to pre-computed rate counter periods\n- Envelope output: 8-bit value 0-255\n\n**Timing:**\n- Rate counter: 15-bit counter compared against rate_period\n- Exponential counter: Further divides envelope counter clock (1, 2, 4, 8, 16, 30x)\n- 1ms to 8 seconds envelope times\n\n**Key Data:**\n- `rate_counter_period[16]`: {8, 31, 62, 94, 148, 219, 266, 312, 391, 976, 1953, 3125, 3906, 11719, 19531, 31250}\n- `sustain_level[16]`: {0x00, 0x11, 0x22, ..., 0xff} (16 sustain levels)\n\n### Filter (filter.h / filter_impl.h)\n**Two-Integrator-Loop Biquad (MOS6581):**\n- Vhp (highpass) → Resonance summer\n- Vbp (bandpass) → 1st integrator\n- Vlp (lowpass) → 2nd integrator\n- 4 resonance taps (0-15) for feedback\n\n**Control:**\n- `writeFC_LO(reg8)`, `writeFC_HI(reg8)`: Set cutoff frequency (11-bit, 0-2047)\n- `writeRES_FILT(reg8)`: Resonance (bits 4-7), voice routing (bits 0-3)\n- `writeMODE_VOL(reg8)`: Filter mode select (bits 4-6: HP/BP/LP), volume (bits 0-3: 0-15)\n\n**Voice Routing:**\n- Bit 0: Route Voice 1 through filter\n- Bit 1: Route Voice 2 through filter\n- Bit 2: Route Voice 3 through filter\n- Other bits route EXT IN\n\n**Output Modes:**\n- Bit 4: Lowpass (Vlp)\n- Bit 5: Bandpass (Vbp)\n- Bit 6: Highpass (Vhp)\n- Combinations: LP+BP, LP+HP, BP+HP, LP+BP+HP\n\n**Cutoff Frequency:**\n- MOS6581: Non-linear 220Hz-18kHz (with discontinuity at FC=0x80)\n- MOS8580: Linear 30Hz-12kHz\n- Table lookup with spline interpolation\n\n### VICE Filter (filter_new.h / filter_new_impl.h)\n**Superior Accuracy Alternative** with EKV transistor model\n- 6581: Self-biased NMOS inverter op-amps\n- 8580: Real op-amps with temperature compensation\n- Lookup tables: opamp_rev[65536], gain[16][65536], resonance[16][65536], mixer[...], summer[...]\n- Cutoff DAC table: f0_dac[2048]\n\n**Key Difference:**\n- Iterative fixpoint solver: `solve_integrate_6581()`, `solve_integrate_8580()`\n- Voltage-controlled resistor (VCR) with EKV current model\n- Capacitor charge integration via lookup table\n\n**Methods:**\n- `clock(int voice1/2/3)`: Process single cycle\n- `clock(cycle_count dt, int voice1/2/3)`: Process N cycles (max ~3 per iteration)\n- `writeFC_LO/HI()`, `writeRES_FILT()`, `writeMODE_VOL()`: Same as old filter\n- `input(short sample)`: External audio input scaling\n- `output()`: Return 16-bit mixed output\n\n### External Filter (extfilt.h)\n**Output Stage:**\n- Low-pass: 16kHz (STC network)\n- High-pass: 16Hz (AC coupling simulation)\n- Dual integrator: Vlp + Vhp states\n\n**Methods:**\n- `clock()` / `clock(cycle_count delta_t, sound_sample Vi)`: Update filter state\n- `output()`: Return filtered 16-bit sample\n\n### WASM Wrapper (resid_wasm.cpp)\n**Emscripten Bindings** for JavaScript web audio\n- `SIDWrapper` class wraps SID16\n- Exposes all register I/O, clocking, extensions as JS functions\n- Memory: Fixed-point audio output conversion (sample/32768.0f for float)\n- Constants: `MOS6581=0, MOS8580=1`\n\n**Callable Methods:**\n- `.reset()`, `.setChipModel(0|1)`, `.setSampleRate(44100)`\n- `.write(reg, val)`, `.read(reg)` → register access\n- `.clockAndOutput(cycles)` → int sample\n- `.generateSamples(count)` → Float32Array\n- `.fillBuffer(bufferPtr, count)` → zero-copy fill\n- Voice volume: `.setVoiceVolume(v, vol)`, etc.\n- FM: `.setFM(v, src, amt)`, `.enableFM(bool)`\n- Resonance: `.setResBoost(boost)`, `.enableResBoost(bool)`\n- Direct mod: `.setFreqDirect(v, freq)`, `.setPulseWidthDirect(v, pw)`, `.setFilterCutoffDirect(fc)`\n\n### Critical Constants\n- Clock: 985248 Hz (PAL) or ~1000000 Hz (NTSC approx)\n- Sampling: 22-23 cycles per sample @ 44.1kHz output\n- Accumulator: 24-bit (16.24 fixed-point frequency)\n- Pulse width: 12-bit (0-4095 = 0-100%)\n- Envelope: 8-bit (0-255)\n- Filter: 11-bit cutoff (0-2047)\n- Voice output: 20-bit signed (before scaling)\n- Final output: 16-bit signed (-32768 to 32767)\n\n### Registration for UE5\n- 3 voices with independent oscillators + ADSRs + volumes + FM\n- 1 integrated filter (old or VICE) with resonance + mode selection\n- External filter (fixed at 16kHz LP, 16Hz HP)\n- Register write delays + pipeline delays for cycle accuracy\n- State save/restore for composition systems\n\n### Key Gotchas for Port\n1. Frequency is 16-bit only (upper 8 bits) - lower 8 bits discarded\n2. Rate counter never resets (delay before envelope starts)\n3. Exponential decay uses lookup table (not exact exp())\n4. Ring modulation is XOR of waveform MSBs (not traditional FM)\n5. Pulse+Triangle mode produces \"ringmod\" internally (undocumented)\n6. MOS6581 has DC bias; MOS8580 does not\n7. Filter has known discontinuity at FC=0x80 (6581 only)\n8. Resonance Q only reaches ~1.7 (stock), ~5.0 with boost\n9. Soft sync interpolates between hard/soft transitions (SIDKIT v0.1.7)\n10. Per-voice volume applied BEFORE filter mixing (multiplicative)\n",
      "type": "warning",
      "tags": [
        "warning",
        "javascript",
        "api"
      ],
      "timestamp": "2026-02-08T21:11:19.546Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-08T21:11:19.546Z",
      "lastVerified": "2026-02-08T21:11:19.546Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770585794446_srltqf5gx",
      "content": "ReSID MetaSounds Port — COMPLETE (2026-02-08)\n\n5 custom MetaSounds C++ nodes wrapping SIDKIT-modded reSID:\n1. SID Oscillator (SIDKIT::Oscillator::Audio) — 24-bit accumulator, 8 waveforms including combined\n2. SID Envelope (SIDKIT::Envelope::Float) — Non-linear exponential ADSR with delay bug\n3. SID Filter (SIDKIT::Filter::Audio) — THE KILLER NODE. Non-linear 6581/8580 analog filter\n4. SID Voice (SIDKIT::Voice::Audio) — Osc×Env convenience combo\n5. SID Chip (SIDKIT::Chip::Audio) — Full 3-voice SID16 with filter, FM, per-voice volume\n\nArchitecture:\n- Separate Runtime module (SIDMetaSoundNodes) — works in shipped games without MCP server\n- ThirdParty/ReSID/ — 37 files copied from WASM-RESID/reSID/ + VICE filter_new\n- USE_NEW_FILTER=1 enabled — 50MB VICE 1.0 non-linear VCR model (impossible on Teensy, trivial on desktop)\n- Fractional cycle accumulator: SID 985248 Hz → UE5 48kHz = ~20.53 cycles/sample\n- Enum registration: ESIDWaveform (8), ESIDFilterMode (7), ESIDChipModel (2) via DECLARE/DEFINE_METASOUND_ENUM\n\nFiles created:\n- 3 module files (Build.cs, Module .h/.cpp)\n- 2 enum files (SIDNodeEnums.h/.cpp)\n- 5 node files (SIDOscillatorNode.cpp, SIDEnvelopeNode.cpp, SIDFilterNode.cpp, SIDVoiceNode.cpp, SIDChipNode.cpp)\n- 3 templates (sid_bass.json, sid_lead.json, sid_chip_tune.json)\n- 1 test file (test_sid_nodes.py — 26 tests)\n- 5 Python node definitions in metasound_nodes.py (SIDKIT category)\n- sid_synth pattern in orchestrator PATTERNS registry\n\nModified:\n- UEAudioMCP.uplugin (added SIDMetaSoundNodes Runtime module)\n- AudioMCPNodeRegistry.h (added 5 SID node mappings)\n- metasound_nodes.py (added 5 SID nodes, SIDKIT category)\n- systems.py (added sid_synth pattern)\n\n307 tests passing (was 281)",
      "type": "config",
      "tags": [
        "config",
        "python",
        "resid",
        "metasounds",
        "sid",
        "ue5",
        "complete"
      ],
      "timestamp": "2026-02-08T21:23:14.446Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-08T21:23:14.446Z",
      "lastVerified": "2026-02-08T21:23:14.446Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770586270481_9kykxj25q",
      "content": "## MetaSounds Custom Node Display Style Research (2026-02-08)\n\n### FNodeClassMetadata (MetasoundNodeInterface.h)\nFull struct with 13 members:\n- ClassName: FNodeClassName (Namespace, Name, Variant)\n- MajorVersion: int32\n- MinorVersion: int32  \n- DisplayName: FText\n- Description: FText\n- Author: FString\n- PromptIfMissing: FText\n- DefaultInterface: FVertexInterface\n- CategoryHierarchy: TArray<FText> - controls menu placement\n- Keywords: TArray<FText>\n- DisplayStyle: FNodeDisplayStyle - controls visual appearance\n- AccessFlags: ENodeClassAccessFlags\n- bDeprecated: bool\n\n### FNodeDisplayStyle (MetasoundNodeInterface.h)\n5 members:\n- bShowInputNames: bool - show input pin names\n- bShowLiterals: bool - show input literal values\n- bShowName: bool - show node name\n- bShowOutputNames: bool - show output pin names\n- ImageName: FName - icon identifier for the node\n\n### Key Finding: NO direct color control\nMetaSounds does NOT expose a color field in FNodeDisplayStyle or FNodeClassMetadata. Node colors are handled by the EDITOR module (MetasoundEditor), not the node registration API. The editor determines colors based on category or internal logic.\n\n### CategoryHierarchy controls menu placement, not color\nSetting CategoryHierarchy = { LOCTEXT(\"Custom\", \"Branches\") } puts node under \"Branches\" category in right-click menu. Does NOT directly set node color.\n\n### To customize node colors you need to modify the Editor module\nThe MetaSound editor (SMetasoundGraphNode/MetasoundEditorGraphNode) handles visual styling internally. Custom node colors would require:\n1. Subclassing the editor graph node class\n2. Overriding GetNodeTitleColor() / GetNodeBodyTintColor() (standard UE5 SGraphNode pattern)\n3. Or modifying the MetasoundEditor plugin source\n\n### Standard node registration patterns from real plugins:\n- alexirae/unreal-audio-dsp-template-UE5: Uses Info.CategoryHierarchy = { LOCTEXT(..., \"Utils\") }\n- matthewscharles/metasound-branches: Uses Metadata.CategoryHierarchy = { METASOUND_LOCTEXT(\"Custom\", \"Branches\") }\n- Tutorial template: Uses { } empty category + FNodeDisplayStyle{} default\n- FM Generator: Uses FNodeDisplayStyle{} default (no color)",
      "type": "config",
      "tags": [
        "config",
        "api",
        "metasounds",
        "ue5",
        "c++",
        "node-style",
        "research"
      ],
      "timestamp": "2026-02-08T21:31:10.481Z",
      "context": "Research on custom MetaSound node colors and display styling for UE5-WWISE project",
      "accessCount": 0,
      "lastAccessed": "2026-02-08T21:31:10.481Z",
      "lastVerified": "2026-02-08T21:31:10.481Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770586426231_v6i3gkra5",
      "content": "MetaSounds FNodeDisplayStyle does NOT have a color field. The struct only has: bShowInputNames, bShowLiterals, bShowName, bShowOutputNames, ImageName (FName). Node colors in the MetaSounds graph editor are controlled by SMetasoundGraphNode::GetNodeTitleColor() / GetNodeBodyTintColor() in the MetasoundEditor module (engine source), not from node registration. To get custom colors for SIDKIT nodes, would need to either: (1) modify engine source MetasoundEditor module, or (2) create an editor extension that overrides the graph node rendering for the \"ReSID SIDKIT Edition\" category.",
      "type": "general",
      "tags": [
        "general",
        "metasounds",
        "ue5",
        "gotcha",
        "node-colors"
      ],
      "timestamp": "2026-02-08T21:33:46.231Z",
      "context": "Research confirmed via UE5 API docs and multiple GitHub repos (alexirae, matthewscharles, bh247484, Cycling74)",
      "accessCount": 0,
      "lastAccessed": "2026-02-08T21:33:46.231Z",
      "lastVerified": "2026-02-08T21:33:46.231Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770588604556_1gw5mpwt4",
      "content": "UE5-WWISE Project Complete Inventory (2026-02-08)\n\nPROJECT STATS:\n- Python src: 12,250 lines (src/ue_audio_mcp/)\n- C++ plugin: 22,529 lines (ue5_plugin/UEAudioMCP/)\n- Tests: 3,288 lines (tests/)\n- Total tests: 307 passing\n- Templates: 25 MetaSounds + 30 Blueprint + 6 Wwise = 61 total\n- Tools: 52 MCP tools across 12 modules\n- Knowledge DB: 12 Python files defining 144 MetaSounds nodes, 22K+ Blueprint nodes, 66 WAAPI functions\n\nTOOL MODULES (52 tools total):\n1. core.py (5): wwise_connect, wwise_get_info, wwise_query, wwise_save, execute_waapi\n2. objects.py (4): wwise_create_object, wwise_set_property, wwise_set_reference, wwise_import_audio\n3. events.py (4): wwise_create_event, wwise_create_game_parameter, wwise_assign_switch, wwise_set_attenuation\n4. preview.py (2): wwise_preview, wwise_generate_banks\n5. templates.py (6): template_aaa_setup, template_gunshot, template_footsteps, template_ambient, template_ui_sound, template_weather_states\n6. metasounds.py (4): ms_list_nodes, ms_node_info, ms_search_nodes, ms_list_categories\n7. ms_graph.py (3): ms_validate_graph, ms_graph_to_commands, ms_graph_from_template\n8. ms_builder.py (10): ms_build_graph, ms_create_source, ms_add_node, ms_connect_pins, ms_set_default, ms_save_asset, ms_open_in_editor, ms_convert_to_preset, ms_audition, ms_stop_audition\n9. blueprints.py (4): bp_search, bp_node_info, bp_list_categories, bp_call_function\n10. presets.py (3): ms_preset_swap, ms_preset_morph, ms_macro_trigger\n11. variables.py (2): ms_add_variable, ms_add_variable_node\n12. ue5_core.py (3): ue5_connect, ue5_get_info, ue5_status\n13. systems.py (2): build_audio_system, build_aaa_project\n\nMETASOUNDS TEMPLATES (25):\n- Core patterns: gunshot, footsteps, ambient, ui_sound, weather, spatial, wind\n- Synthesis: mono_synth, subtractive_synth, sfx_generator\n- Advanced: preset_morph, macro_sequence, vehicle_engine\n- SID chips: sid_bass, sid_chip_tune, sid_lead\n- Special: snare, sound_pad, weapon_burst, weapon_source, ambient_stingers, crossfade_by_param, random_playback, sample_player, footfalls_simple\n\nBLUEPRINT TEMPLATES (30):\nWeapons: weapon_burst_control, weapon_source\nMovement: footfalls_simple, player_oriented_sound\nAmbient: ambient_height_wind, ambient_spline_movement, ambient_stingers, ambient_weighted_trigger, soundscape_ambient\nMusic: quartz_beat_sync, quartz_multi_clock, quartz_music_playlist, quartz_transitional_states, quartz_vertical_music, triggered_music_stinger\nEffects: audio_input_butterflies, audio_modulation, audio_visualiser, spectral_analysis, submix_recording, submix_spectral_fireflies, physics_audio, synesthesia_stems\nUI: sfx_generator_widget, metasound_preset_widget, sound_pad_control, set_float_parameter\nSpatial: spatial_attenuation, volume_proxy\nOther: bomb_fuse\n\nWWISE TEMPLATES (6):\ngunshot, footsteps, ambient, ui_sound, vehicle_engine, weather\n\nC++ PLUGIN (22,529 lines):\nMain (UEAudioMCP): 3,914 lines across 24 files\n- Core: AudioMCPTcpServer (361), AudioMCPBuilderManager (953), AudioMCPCommandDispatcher (155), UEAudioMCPModule (132)\n- Commands: BuilderCommands (239), BlueprintCommands (309), NodeCommands (138), VariableCommands (116), PresetCommands (50), QueryCommands (300), PingCommand (61)\n- Headers: AudioMCPNodeRegistry (214), AudioMCPBuilderManager.h (131), AudioMCPTypes.h (55)\n\nSID MetaSounds Nodes (1,620 lines): SIDChipNode (494), SIDVoiceNode (286), SIDFilterNode (257), SIDOscillatorNode (218), SIDEnvelopeNode (227)\n\nReSID ThirdParty (37 header-only files): envelope, filter, voice, wave, sid implementations\n\nKNOWLEDGE BASE (12 files, 7,610 lines):\n- metasound_nodes.py (2,062): 144 nodes, 20 categories, 798 pins\n- waapi_functions.py (841): 66 WAAPI functions\n- db.py (861): SQLite 10 tables, singleton\n- blueprint_audio.py (759): GameplayStatics, AudioComponent, Quartz\n- tutorials.py (677): 412-line catalogue, Builder API, spatialization\n- graph_schema.py (449): Graph validation, node types, interfaces\n- embeddings.py (266): TF-IDF semantic search\n- wwise_types.py (183): 19 object types, properties\n- metasound_data_types.py (169): Pin type system\n- seed.py (311): SQLite seed data\n- blueprint_nodes/ (11 submodules): curated 946 nodes across categories\n\nTEST MODULES (307 tests, 3,288 lines):\ntest_systems.py (69 tests), test_sid_nodes.py (26), test_db.py (20), test_preset_tools.py (19), test_graph_schema.py (19), test_templates.py (17), test_ms_builder_tools.py (17), test_blueprint_tools.py (16), test_metasound_knowledge.py (14), test_object_tools.py (13), test_ms_graph_tools.py (12), test_core_tools.py (8), test_event_tools.py (8), test_variable_tools.py (8), test_preview_tools.py (7), test_ue5_core_tools.py (6), test_connection.py (6), test_ue5_connection.py (7)\n\nRESEARCH (16 markdown docs, 512K total):\n- research_waapi_mcp_server.md (38K)\n- research_ue5_blueprint_nodes.md (95K)\n- research_ue5_blueprint_libraries.md (68K)\n- research_ue57_metasounds_builder_api.md (31K)\n- research_metasounds_game_audio.md (32K)\n- research_metasound_custom_nodes_cpp.md (29K)\n- research_metasound_builder_implementations.md (27K)\n- research_wwise_ue5_blueprint_nodes.md (29K)\n- research_quartz_music_system.md (24K)\n- research_audio_driven_gameplay.md (23K)\n- research_ambient_procedural_sound_design.md (25K)\n- research_metasound_save_and_editor.md (19K)\n- research_unreal_mcp_landscape.md (18K)\n- research_metasound_node_display_style.md (15K)\n- research_blueprint_node_database.md (14K)\n- research_blueprint_audio_patterns.md (9.3K)\n\nSCRIPTS (8 Python files):\n- scrape_blueprint_api.py (13K): Playwright scraper for Epic Blueprint API\n- scrape_metasound_nodes.py (18K): Epic MetaSounds Reference scraper\n- parse_metasound_export.py (12K): UE5 \"Copy full snippet\" parser\n- parse_tutorial.py (14K): Epic tutorial instruction parser\n- dump_blueprints_ue5.py (17K): Blueprint JSON extractor\n- extract_uasset_audio.py (16K): Audio asset extraction\n- verify_blueprint_nodes.py (14K): Knowledge DB verification\n- test_live_ue5.py (7.5K): Live UE5 plugin testing\n\nREADME: Complete (273 lines) - covers architecture, tools, templates, quick start, MCP config, A2HW protocol, credits",
      "type": "config",
      "tags": [
        "config",
        "python",
        "api",
        "testing",
        "project-inventory",
        "ue5-wwise",
        "complete-stats"
      ],
      "timestamp": "2026-02-08T22:10:04.556Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-08T22:10:04.556Z",
      "lastVerified": "2026-02-08T22:10:04.556Z",
      "status": "fresh"
    }
  ],
  "lastUpdated": "2026-02-08T22:10:04.556Z"
}