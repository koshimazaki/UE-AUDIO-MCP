{
  "memories": [
    {
      "id": "mem_1770385162176_1q1l3g5xr",
      "content": "## UE5-WWISE Project - Complete Exploration Summary\n\n### Project Overview\n- **Name**: UE Audio MCP (Unreal Engine Audio MCP Server)\n- **Creator**: Koshi (creator of SIDKIT, VibeComfy MCP)\n- **Status**: Early development, building in public\n- **Phase**: Research and planning phase (no implementation code yet)\n- **Goal**: Build complete game audio systems from natural language descriptions using MCP protocol\n\n### Architecture\nThe project applies SIDKIT's agent-generated audio systems philosophy to game engines. Three-layer architecture:\n1. **Blueprint** (WHEN) - Game event detection, parameter setting - UE5 Remote Control API\n2. **MetaSounds** (WHAT) - Procedural DSP synthesis, audio generation - Builder API via plugin\n3. **Wwise** (HOW) - Mixing, buses, spatialization, RTPC - WAAPI (WebSocket :8080)\n\n### File Tree Structure\n```\n/UE5-WWISE/\n├── README.md (11k) - Project vision, architecture, tool groups\n├── ROADMAP.md (9.5k) - 5-phase development plan with dependencies\n├── .gitignore - Standard Python, Node, UE5 ignores\n├── research/ - Research documentation (80KB total)\n│   ├── research_waapi_mcp_server.md (69KB) - Complete WAAPI API reference, 87 functions\n│   └── research_metasounds_game_audio.md (11KB) - MetaSounds patterns and Builder API\n├── src/ - (Directory structure only, no files yet)\n│   ├── tools/\n│   │   ├── wwise/\n│   │   ├── metasounds/\n│   │   └── blueprints/\n│   ├── knowledge/\n│   ├── protocol/\n│   └── systems/\n├── templates/ - (Empty directory)\n├── tests/ - (Empty directory)\n├── .claude/ - (Claude workspace, empty)\n├── logs/ - Application logs (LMStudio health checks)\n└── memories.json - (Empty memories file)\n```\n\n### Git History\n- Commit 5c984e6: \"Add research files, .gitignore, and project structure\" (latest)\n- Commit 33ba52d: \"Initial project setup: UE Audio MCP\"\n- Branch: master (up to date with origin)\n- Untracked: memories.json\n\n### Key MCP Servers Referenced\n1. **SIDKIT** - Hardware synthesis agent, generates C++ firmware for Teensy ARM\n2. **VibeComfy MCP** - ComfyUI nodes (8,400+ nodes) via MCP\n3. **Blender MCP** - Controls Blender via MCP (16.9k stars reference)\n4. **unreal-mcp** - Controls UE5 editor (chongdashu) - no audio support\n\n### Research Documentation Summary\n\n#### WAAPI (Wwise Authoring API)\n- **Protocol**: WAMP (WebSocket) on ws://127.0.0.1:8080/waapi or HTTP POST on :8090\n- **Status**: 87+ API functions, fully documented\n- **Libraries**: waapi-client (official Python), pywwise (Pythonic wrapper)\n- **Key limitation**: Wwise Authoring App MUST be running (no true headless mode)\n- **Functions**:\n  - Object CRUD: create, delete, get, move, copy, setProperty, setReference\n  - Audio import with multiple operation modes (createNew, useExisting, replaceExisting)\n  - Switch containers and state groups with assignments\n  - RTPC curve management\n  - Attenuation curve configuration\n  - SoundBank generation\n  - Transport control for previewing\n  - WAQL (Wwise Authoring Query Language) for object search\n\n#### MetaSounds & Builder API\n- **Asset types**: Source (playable), Patch (reusable subgraph), Preset (parameter overrides)\n- **Graph model**: Flow graph with sample-accurate timing, signal-by-reference\n- **Data types**: Audio, Trigger, Float, Int32, Bool, Time, String, UObject, Enum, WaveAsset, Arrays\n- **80+ nodes**: Generators, Wave Players, Envelopes, Filters, Delays, Dynamics, Triggers, Arrays, Math, Mix, Spatialization, Music, Random\n- **Builder API**: Experimental (UE 5.4+), enables runtime graph creation\n- **Key interfaces**: UE.Source.OneShot, UE.Attenuation, UE.Spatialization\n- **Six game audio patterns**: Gunshots, Footsteps, Ambient, Spatial (Panning), UI Sounds, Weather/State Switches\n\n#### Audio Link Bridge\n- **Purpose**: Enables MetaSounds + Wwise coexistence (UE 5.1+)\n- **Direction**: One-way only (MetaSounds → Wwise via Audio Input Events)\n- **Use**: Procedural audio synthesis through Wwise mixing pipeline\n\n### A2HW Protocol (Agent-to-Hardware)\n- **Purpose**: Shared language between SIDKIT and UE Audio MCP\n- **Concept**: One synthesis description maps to multiple targets:\n  - SIDKIT: SysEx → Teensy ARM (hardware synth)\n  - Browser: JS → ModuleRunner (web preview)\n  - MetaSounds: Builder API → UE5 (game engine)\n  - Wwise: WAAPI → mixing pipeline (middleware)\n- **Status**: Planned Phase 5 (spec and standardization)\n\n### Development Roadmap (5 Phases)\n1. **Phase 1 (Weekend)**: Wwise MCP standalone via WAAPI\n2. **Phase 2 (1-2 days)**: MetaSounds knowledge base (node database)\n3. **Phase 3 (1 week)**: UE5 audio plugin (Builder API bridge)\n4. **Phase 4 (1-2 weeks)**: Systems orchestration layer\n5. **Phase 5 (Ongoing)**: A2HW protocol specification and standardization\n\n### Tech Stack\n- **MCP Server**: Python (FastMCP)\n- **Wwise Bridge**: waapi-client (official Audiokinetic Python library)\n- **UE5 Bridge**: Custom C++ plugin with TCP server (Builder API + Remote Control)\n- **Knowledge Base**: JSON node databases\n- **Templates**: Parameterized patterns for common game audio systems\n\n### Higher-Level Tool Groups\n**Systems Layer** (Phase 4 - orchestrates all three):\n- build_system - Generic audio system from text description\n- build_footsteps - Complete surface-reactive footstep system\n- build_weapon_audio - Gunshot + shell + tail + distance\n- build_ambient - Zone-based ambient with layers\n- build_ui_audio - Procedural UI sound set\n- build_weather - State-driven weather audio system\n\n### Important Notes\n- **No existing Wwise MCP server** - This would be first-of-its-kind\n- **No existing MetaSounds MCP integration** - Gap confirmed\n- **SIDKIT inspiration**: Same 3-layer architecture philosophy applied to game engines\n- **Lyra Starter Game**: Reference implementation for MetaSounds patterns\n- **Builder API experimental**: May change between UE versions\n- **AudioLink setup**: MetaSounds side requires custom patches, UE5 side requires Wwise Audio Input Events\n\n### Current Project State\n- Research phase complete (80KB+ of detailed documentation)\n- Directory structure created but empty (src/, templates/, tests/, .claude/)\n- No implementation code yet\n- Ready for Phase 1 (Wwise MCP) development\n- All dependencies and APIs researched and documented\n",
      "type": "config",
      "tags": [
        "config",
        "python",
        "api",
        "database",
        "UE5-WWISE",
        "MCP-servers",
        "audio-systems",
        "game-audio",
        "architecture",
        "WAAPI",
        "MetaSounds",
        "project-structure"
      ],
      "timestamp": "2026-02-06T13:39:22.175Z",
      "context": "Exploration of UE5-WWISE project at /Users/radek/Documents/GIthub/UE5-WWISE",
      "accessCount": 1,
      "lastAccessed": "2026-02-07T01:33:25.182Z",
      "lastVerified": "2026-02-06T13:39:22.175Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770385395012_sc5fsab52",
      "content": "UE5-WWISE project setup complete. Created .claude/CLAUDE.md (main prompt), 3 slash commands (/ue-agent, /wwise-agent, /build-system), settings.json, and auto memory. Project builds first MCP server for game audio — Wwise + MetaSounds + Blueprint pipeline from natural language. Phase 1 (Wwise MCP) ready to start coding with waapi-client Python library.",
      "type": "config",
      "tags": [
        "config",
        "python",
        "ue5-wwise",
        "project-setup",
        "mcp",
        "game-audio"
      ],
      "timestamp": "2026-02-06T13:43:15.012Z",
      "context": "Initial project agent setup for UE Audio MCP",
      "accessCount": 1,
      "lastAccessed": "2026-02-07T01:33:25.182Z",
      "lastVerified": "2026-02-06T13:43:15.012Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770385564956_5k72eql7d",
      "content": "## SIDKIT Agent Architecture - Complete Reference\n\n### Project Overview\nSIDKIT Agent is a Rust-based LLM-powered C++ code generation system for the SIDKIT synthesizer platform (Teensy 4.1). It features:\n- Agentic tool-use loop with Claude API\n- Autonomous GCC compilation & error fixing\n- Teensy hardware flashing via USB\n- SQLite-based learning (error patterns, build history)\n- Semantic knowledge base search\n- Dual-mode operation: Full agent server vs. LLM-agnostic tool server\n\n### Tech Stack\n- **Language**: Rust 2021 edition\n- **LLM**: Claude API (Haiku/Sonnet/Opus models)\n- **Web Framework**: Axum 0.7 (async HTTP)\n- **Compilation**: arm-none-eabi-gcc wrapper\n- **Hardware**: teensy_loader_cli for flashing\n- **Storage**: SQLite with rusqlite\n- **Serialization**: serde/serde_json\n\n### File Structure\n```\nsidkit-agent/\n├── src/\n│   ├── main.rs                  # CLI entry (Serve/Tools/Build/Flash/Devices)\n│   ├── agent.rs                 # Core agent + ToolExecutor impl\n│   ├── llm/\n│   │   ├── mod.rs              # Exports\n│   │   ├── claude.rs           # Agentic loop, API calls\n│   │   ├── tools.rs            # Tool defs + knowledge types\n│   │   └── prompts.rs          # System prompts, templates\n│   ├── server/\n│   │   ├── mod.rs              # Exports\n│   │   ├── http.rs             # Agentic server (Axum)\n│   │   └── tools.rs            # Pure tool server (no LLM)\n│   ├── knowledge/\n│   │   ├── mod.rs              # SDK reference constants\n│   │   └── base.rs             # Semantic search, JSON loading\n│   ├── storage/\n│   │   ├── mod.rs              # Exports\n│   │   └── db.rs               # SQLite wrapper\n│   ├── toolchain/\n│   │   ├── mod.rs              # Exports\n│   │   ├── gcc.rs              # arm-none-eabi-gcc wrapper\n│   │   └── errors.rs           # Error parsing\n│   └── flasher/\n│       ├── mod.rs              # Exports\n│       ├── teensy.rs           # USB bootloader\n│       └── intel_hex.rs        # HEX file parsing\n├── knowledge/                   # JSON knowledge base\n│   ├── games.json\n│   ├── patches.json\n│   ├── synthesis.json\n│   └── inspirations.json\n├── templates/                   # (empty, templates in code)\n├── migrations/                  # (empty)\n├── scripts/\n│   └── create-macos-app.sh     # macOS menubar build\n├── Cargo.toml\n└── README.md\n```\n\n### Core Components\n\n#### 1. Agent Loop (src/agent.rs)\n- **SidkitAgent**: Main agent orchestrating tools\n- **BuildSession**: Tracks state during build\n- **ToolExecutor trait**: Executes tools for LLM\n- Tools: generate_code, compile, search_knowledge, read_sdk, search_patterns, flash, report_status, complete\n\n#### 2. LLM Client (src/llm/claude.rs)\n- **AgenticClient**: Manages API calls & tool loops\n- **Models**: Haiku, Sonnet, Opus with model IDs\n- **Tool loop**: Call → Get blocks → Execute → Feedback → Repeat\n- System prompt includes SDK reference\n- Max iterations: 10 (configurable)\n\n#### 3. Tool Definitions (src/llm/tools.rs)\n- 8 tools exposed to Claude\n- **Knowledge types**: 19 categories (patches, templates, sdk, synthesis, games, shaders, algorithms, chips, engines, design, inspirations, guides, schemas, patterns, effects, ui-ux, platform, webui, faq)\n- **Metadata**: difficulty, cpu_cost, dependencies, voice_count, author, source\n- Search: embedding-based (if available) + keyword + tag matching\n\n#### 4. HTTP Servers (src/server/)\n\n**Full Agent Server** (/serve):\n- /build (POST) - Start agentic build\n- /build/:id/status - Get status\n- /build/:id/events - Stream events\n- /build/:id/download - Get hex\n- /flash, /devices, /history\n\n**Pure Tool Server** (/tools):\n- /compile (POST) - GCC compile only\n- /flash (POST) - Flash hex\n- /pio/build, /pio/upload - PlatformIO\n- /search (GET) - Knowledge API proxy\n- /doc/:id (GET) - Fetch doc\n- /devices - List Teensy\n\n#### 5. Knowledge Base (src/knowledge/)\n- **SDK constants**: IModule, Display (Adafruit GFX), Audio (48kHz), MIDI, Events, Examples, Templates\n- **File format**: MCP-server JSON with title, category, description, tags, content\n- **Search**: Loads from ~/.sidkit-agent/knowledge/ (or custom dir)\n- Categories indexed by hash maps\n\n#### 6. Storage (src/storage/db.rs)\n- **Location**: ~/.sidkit-agent/sidkit.db (SQLite)\n- **Tables**: \n  - builds (id, prompt, module_type, attempts, final_code, success, duration_ms, created_at)\n  - error_patterns (error_signature, successful_fix, fix_explanation, occurrences, successes)\n- **Auto-learning**: Patterns stored after successful fixes\n\n#### 7. Toolchain (src/toolchain/gcc.rs)\n- **Compiler**: arm-none-eabi-gcc (Cortex-M7)\n- **Flags**: -std=c++17, -O2, cortex-m7, thumb, hard float\n- **Error parsing**: Regex-based GCC output parsing\n- **Output**: firmware.hex (linker step handled externally)\n- **Includes**: SIDKIT_FIRMWARE_PATH env var for SDK headers\n\n#### 8. Flasher (src/flasher/teensy.rs)\n- **Protocol**: teensy_loader_cli binary\n- **USB IDs**: 0x16C0 vendor, 0x0478 bootloader, 0x0476 running\n- **Method**: Looks for teensy_loader_cli in PATH, Homebrew, Teensyduino\n- **Input**: .hex file path\n- **Features**: List devices, detect bootloader, reboot to bootloader\n\n### Agent Execution Flow\n1. User calls `build` with prompt\n2. Agent creates BuildSession\n3. LLM loop (0-10 iterations):\n   - Send prompt + SDK + tools to Claude\n   - Claude picks tool(s) to call\n   - Agent executes tool (generate_code → write file → compile → parse errors)\n   - Feed results back to Claude\n   - Handle special tools: generate_code, compile, complete (signal finish)\n4. Store result: SQLite build record + error patterns learned\n5. Return BuildResult::Success or Failed\n\n### System Prompts & Templates\n**Three module types**:\n- Game (SlotType::ADVANCED, 25 CPU bits, 0 voices)\n- Synth (SlotType::SYNTH, 10 CPU bits, 4 voices, MIDI)\n- Sequencer (SlotType::SEQUENCER, 5 CPU bits, pattern trigger)\n\nTemplates include:\n- Full class structure with virtual methods\n- Example parameter handling\n- Display/MIDI/event handling skeletons\n\n### Knowledge Base Structure\n**Format**: JSON array of entries:\n```json\n{\n  \"id\": \"game-space-shooter\",\n  \"category\": \"games\",\n  \"title\": \"Space Shooter\",\n  \"description\": \"...\",\n  \"content\": \"// C++ code ...\",\n  \"tags\": [\"game\", \"shooter\"],\n  \"metadata\": {\"difficulty\": \"intermediate\", \"cpu_cost\": \"low\"}\n}\n```\n\n### CLI Commands\n```bash\nsidkit-agent serve --port 3001              # Full agentic server\nsidkit-agent tools --port 3002              # Tool server only\nsidkit-agent build \"prompt\" --model haiku   # Agentic CLI build\nsidkit-agent flash firmware.hex             # Flash hex directly\nsidkit-agent devices                        # List Teensy devices\nsidkit-agent history --limit 10             # Build history\nsidkit-agent models                         # Show available models\n```\n\n### Environment Variables\n- ANTHROPIC_API_KEY - Claude API auth\n- SIDKIT_FIRMWARE_PATH - Path to firmware SDK\n- RUST_LOG - Logging level\n\n### Key Design Patterns\n1. **Async throughout**: tokio for concurrency\n2. **Error learning**: Auto-stores fixes in DB\n3. **Semantic search**: Embedding + keyword fallback\n4. **Streaming events**: AgentEvent enum for UI\n5. **Dual servers**: Flexible deployment (agent-only or tool-only)",
      "type": "config",
      "tags": [
        "config",
        "rust",
        "c++",
        "api",
        "deployment",
        "sidkit",
        "architecture",
        "llm",
        "agent",
        "reference"
      ],
      "timestamp": "2026-02-06T13:46:04.956Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T13:46:04.956Z",
      "lastVerified": "2026-02-06T13:46:04.956Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770385795551_sf7oos6bn",
      "content": "UE MCP Landscape Research (2026-02-06):\n\nKEY REPOS:\n1. chongdashu/unreal-mcp (1,370 stars) - Leader. C++ plugin + Python FastMCP. TCP port 55557. Tools: blueprint, editor, node, project, umg. No audio.\n2. flopperam/unreal-engine-mcp (431 stars) - 40+ tools, blueprint analysis, 3D gen. No audio.\n3. kvick-games/UnrealMCP (493 stars) - Basic, inspired by blender-mcp. MetaSound on roadmap.\n4. runreal/unreal-mcp (70 stars) - NO PLUGIN needed, uses UE built-in Python remote execution. TypeScript MCP server.\n5. BilkentAudio/Wwise-MCP (23 stars) - Wwise-only MCP via WAAPI. Python/FastMCP. Comprehensive WAAPI wrapper in wwise_python_lib.py. Plan execution pattern.\n6. ahujasid/blender-mcp (16,899 stars) - Gold standard architecture. Two components: addon (socket server in Blender) + MCP server (FastMCP). JSON over TCP.\n\nDECISION: Build from scratch, NOT fork. Reasons:\n- No existing project combines Wwise + MetaSounds + Blueprint audio\n- Forking means maintaining 80% code we don't need + adding 100% audio code ourselves\n- Adopt PATTERNS not codebases: blender-mcp two-component architecture, chongdashu modular tools, BilkentAudio WAAPI wrapper reference, runreal plugin-free approach for Blueprints\n\nARCHITECTURE:\n- Python FastMCP server with 3 communication channels:\n  1. WAAPI WebSocket (port 8080) -> Wwise\n  2. TCP Socket (port 9877) -> Custom C++ UE Plugin (for MetaSounds Builder API)\n  3. Python Remote Execution -> UE5 Editor (for Blueprint tools, NO plugin needed)",
      "type": "warning",
      "tags": [
        "warning",
        "python",
        "typescript",
        "api",
        "architecture",
        "research",
        "unreal-mcp",
        "wwise-mcp",
        "decision"
      ],
      "timestamp": "2026-02-06T13:49:55.551Z",
      "context": "Research for UE5-WWISE project - deciding build vs fork strategy for game audio MCP server",
      "accessCount": 1,
      "lastAccessed": "2026-02-07T01:33:25.182Z",
      "lastVerified": "2026-02-06T13:49:55.551Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770386499116_3irvp8eno",
      "content": "UE5-WWISE Knowledge Architecture Decision (2026-02-06):\n- Cloudflare D1 for structured knowledge storage (6 tables: metasound_nodes, waapi_functions, wwise_types, audio_patterns, error_patterns, ue_game_examples)\n- Cloudflare Vectorize for semantic search (embeddings over same D1 data)\n- Two search paths: agent queries by TYPE (D1 SQL) or by MEANING (Vectorize embeddings)\n- Share Cloudflare infrastructure with SIDKIT (same account, reuse embedding pipeline)\n- Error learning: SIDKIT pattern — store error_signature + successful_fix in D1, query before generating\n- All UE5 tools (MetaSounds + Blueprint) route through single C++ plugin on port 9877 (not split across Python remote exec)",
      "type": "error",
      "tags": [
        "error",
        "python",
        "ue5-wwise",
        "architecture",
        "cloudflare",
        "d1",
        "vectorize",
        "knowledge-base"
      ],
      "timestamp": "2026-02-06T14:01:39.116Z",
      "context": "Architecture decision for UE Audio MCP knowledge storage",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T14:01:39.116Z",
      "lastVerified": "2026-02-06T14:01:39.116Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770388164433_6bifylmv5",
      "content": "WAAPI Python Code Examples - Exact Implementations\n\n1. WAAPI CONNECTION (waapi-client):\n```python\nfrom waapi import WaapiClient, CannotConnectToWaapiException\nwith WaapiClient() as client:\n    info = client.call(\"ak.wwise.core.getInfo\")\n    handler = client.subscribe(\"ak.wwise.core.object.created\", lambda obj: print(obj))\n```\n\n2. CREATE_OBJECT (ak.wwise.core.object.create):\n```python\nresult = client.call(\"ak.wwise.core.object.create\", {\n    \"parent\": \"\\\\Actor-Mixer Hierarchy\\\\Default Work Unit\",\n    \"type\": \"RandomSequenceContainer\",\n    \"name\": \"Gunshot_Variations\",\n    \"onNameConflict\": \"merge\"\n})\ncontainer_id = result[\"id\"]\n```\n\n3. SET_PROPERTY (ak.wwise.core.object.setProperty):\n```python\nclient.call(\"ak.wwise.core.object.setProperty\", {\n    \"object\": \"\\\\Actor-Mixer Hierarchy\\\\Default Work Unit\\\\Weapons\",\n    \"property\": \"Volume\",\n    \"value\": -3.0\n})\n```\n\n4. SET_REFERENCE (ak.wwise.core.object.setReference):\n```python\nclient.call(\"ak.wwise.core.object.setReference\", {\n    \"object\": \"\\\\Actor-Mixer Hierarchy\\\\Default Work Unit\\\\Weapons\",\n    \"reference\": \"OutputBus\",\n    \"value\": \"\\\\Master-Mixer Hierarchy\\\\Default Work Unit\\\\Master Audio Bus\\\\SFX\"\n})\n```\n\n5. IMPORT_AUDIO (ak.wwise.core.audio.import):\n```python\nresult = client.call(\"ak.wwise.core.audio.import\", {\n    \"importOperation\": \"useExisting\",\n    \"default\": {\"importLanguage\": \"SFX\"},\n    \"imports\": [\n        {\"audioFile\": \"C:\\\\Audio\\\\rifle_shot_01.wav\",\n         \"objectPath\": \"\\\\Actor-Mixer Hierarchy\\\\Default Work Unit\\\\Weapons\\\\Gunshot_Rifle\\\\<Sound>Rifle_Shot_01\"}\n    ]\n})\n```\n\n6. CREATE_EVENT (ak.wwise.core.object.create with Action child):\n```python\nevent_result = client.call(\"ak.wwise.core.object.create\", {\n    \"parent\": \"\\\\Events\\\\Default Work Unit\",\n    \"type\": \"Event\",\n    \"name\": \"Play_Gunshot_Rifle\",\n    \"onNameConflict\": \"merge\",\n    \"children\": [{\n        \"type\": \"Action\",\n        \"name\": \"\",\n        \"@ActionType\": 1,\n        \"@Target\": \"\\\\Actor-Mixer Hierarchy\\\\Default Work Unit\\\\Weapons\\\\Gunshot_Rifle\"\n    }]\n})\n```\n\n7. ASSIGN_SWITCH (ak.wwise.core.switchContainer.addAssignment):\n```python\nclient.call(\"ak.wwise.core.switchContainer.addAssignment\", {\n    \"child\": child_object_id,\n    \"stateOrSwitch\": switch_value_id\n})\n```\n\n8. SET_ATTENUATION (ak.wwise.core.object.setAttenuationCurve):\n```python\nclient.call(\"ak.wwise.core.object.setAttenuationCurve\", {\n    \"object\": attenuation_id,\n    \"curveType\": \"VolumeDryUsage\",\n    \"use\": \"Custom\",\n    \"points\": [\n        {\"x\": 0, \"y\": 0, \"shape\": \"Linear\"},\n        {\"x\": 50, \"y\": -6, \"shape\": \"Linear\"},\n        {\"x\": 100, \"y\": -200, \"shape\": \"Exp3\"}\n    ]\n})\n```\n\n9. SET_RTPC/GENERATE BANKS (ak.wwise.core.soundbank.setInclusions/generate):\n```python\nclient.call(\"ak.wwise.core.soundbank.setInclusions\", {\n    \"soundbank\": soundbank_id,\n    \"operation\": \"add\",\n    \"inclusions\": [{\"object\": event_id, \"filter\": [\"events\", \"structures\", \"media\"]}]\n})\nclient.call(\"ak.wwise.core.soundbank.generate\", {\n    \"soundbanks\": [{\"name\": \"Weapons_Bank\"}]\n})\n```\n\n10. TRANSPORT/PREVIEW (ak.wwise.core.transport.create/executeAction):\n```python\ntransport = client.call(\"ak.wwise.core.transport.create\", {\n    \"object\": \"\\\\Events\\\\Default Work Unit\\\\Play_Gunshot_Rifle\"\n})\nclient.call(\"ak.wwise.core.transport.executeAction\", {\n    \"transport\": transport[\"transport\"],\n    \"action\": \"play\"\n})\n```",
      "type": "code",
      "tags": [
        "code",
        "python",
        "WAAPI",
        "Python",
        "code-examples",
        "exact-specs"
      ],
      "timestamp": "2026-02-06T14:29:24.433Z",
      "context": "Extracted from research_waapi_mcp_server.md - all 10 core WAAPI operations with exact code",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T14:29:24.433Z",
      "lastVerified": "2026-02-06T14:29:24.433Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770388232999_vz3hyj07g",
      "content": "WWISE-MCP AND BLENDER-MCP ARCHITECTURE PATTERNS\n\n## FastMCP Tool Registration Pattern (Wwise-MCP)\n- Single FastMCP instance instantiated without lifespan initially\n- Tools exposed: list_wwise_commands() and execute_plan(plan: list[str])\n- No decorator stacking - direct @mcp.tool() usage\n- Return types: dict with command metadata, dict with results and store\n\n## Blender-MCP Tool Registration Pattern  \n- FastMCP with lifespan context manager: mcp = FastMCP(\"BlenderMCP\", lifespan=server_lifespan)\n- Stacked decorators: @telemetry_tool(\"tool_name\") + @mcp.tool()\n- Global _blender_connection maintained at module level\n- Lazy initialization on first tool call via get_blender_connection()\n- Return types vary: strings, base64 images, JSON strings, exceptions\n\n## WAAPI Connection Management (Wwise-MCP)\n- Single global connection using WaapiClient\n- Thread-safe with locks (_client, _dispatcher, _reconnecting flag)\n- Priority queue-based request scheduling with due_in parameter\n- connect_to_waapi() phases: mark reconnecting → shutdown resources → create new instances → restore globals\n- Blocks new calls during reconnection with \"WAAPI is reconnecting\" error\n\n## WAAPI Wrapper Functions Available (wwise_python_lib.py - 62 KB)\nProject info: get_project_info(), get_all_languages(), get_all_platforms(), get_all_soundbanks()\nGame objects: ensure_game_obj(), set_game_obj_position(), start_position_ramp()\nEvent control: create_event(), list_all_event_names(), post_event(), stop_event()\nGame syncs: create_rtpc(), set_state(), set_switch(), ramp_rtpc()\nObject manipulation: get_object_at_path(), rename_objects(), move_object_by_path(), set_property()\nAudio import: import_audio_files(), list_audio_files_at_path_file_explorer()\nCustom exceptions: WwiseValidationError, WwiseObjectNotFoundError, WwiseApiError\n\n## Wwise-MCP Command Execution Pattern\n- Command dataclass-based registry\n- _run_plan_sync() maintains store dict for inter-step variables\n- Variable resolution: $variable (scalars), $last (previous), $last.id (attribute access), recursive dict/list resolution\n- Validates signatures before execution, logs each step\n\n## Project Configuration (pyproject.toml) Patterns\nWwise-MCP: Python 3.13+, FastMCP-based, modules in app/scripts/\nBlender-MCP: Python 3.10+, FastMCP with mcp[cli]≥1.3.0, src/blender_mcp/ layout\nEntry point format: package_name = \"module.submodule:function_name\"\nExample: blender-mcp = \"blender_mcp.server:main\"\n\n## Connection Health Checking (Blender-MCP)\n- Lazy init via get_blender_connection()\n- Verifies connection validity before reuse\n- Recreates if invalid\n- Socket implementation with chunked JSON handling and timeout resilience",
      "type": "config",
      "tags": [
        "config",
        "python",
        "wwise-mcp",
        "blender-mcp",
        "fastmcp",
        "waapi",
        "architecture",
        "patterns"
      ],
      "timestamp": "2026-02-06T14:30:32.998Z",
      "context": "Research completed on BilkentAudio/Wwise-MCP and ahujasid/blender-mcp repositories to understand MCP server patterns for reference in UE5-WWISE project",
      "accessCount": 1,
      "lastAccessed": "2026-02-07T01:33:25.182Z",
      "lastVerified": "2026-02-06T14:30:32.998Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770388338005_1twg2y130",
      "content": "Phase 1 Implementation Plan designed for UE Audio MCP Wwise server. 10 steps, 20 tools across 5 modules (core, objects, events, preview, templates). File structure: src/ue_audio_mcp/ with server.py, connection.py, tools/*.py, knowledge/wwise_types.py, templates/wwise/*.json. Key decisions: FastMCP + waapi-client, Python 3.10+, sync WAAPI (no async wrapping), JSON returns with status field, mock WaapiClient in tests, undo groups for templates. Must remove old empty scaffolding dirs (src/tools/, src/knowledge/, src/protocol/, src/systems/).",
      "type": "general",
      "tags": [
        "general",
        "python",
        "ue5-wwise",
        "phase1",
        "implementation-plan",
        "architecture"
      ],
      "timestamp": "2026-02-06T14:32:18.005Z",
      "context": "Phase 1 implementation planning for UE5-WWISE project",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T14:32:18.005Z",
      "lastVerified": "2026-02-06T14:32:18.005Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770388761637_6gi97qnig",
      "content": "FastMCP (mcp>=1.26.0) uses `instructions` parameter, NOT `description`. The constructor signature changed from older versions.",
      "type": "general",
      "tags": [
        "general",
        "fastmcp",
        "gotcha",
        "api-change"
      ],
      "timestamp": "2026-02-06T14:39:21.637Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T14:39:21.637Z",
      "lastVerified": "2026-02-06T14:39:21.637Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770389223394_mudx7ho3m",
      "content": "Phase 1 Wwise MCP Server COMPLETE. 20 tools, 48 tests, all passing.\n\nFiles created (23):\n- pyproject.toml\n- src/ue_audio_mcp/__init__.py, server.py, connection.py\n- src/ue_audio_mcp/tools/__init__.py, core.py (5 tools), objects.py (4 tools), events.py (4 tools), preview.py (2 tools), templates.py (5 tools)\n- src/ue_audio_mcp/knowledge/__init__.py, wwise_types.py (19 types, 24 props, 18 actions, 9 paths)\n- src/ue_audio_mcp/templates/wwise/ (5 JSON specs)\n- tests/__init__.py, conftest.py, test_connection.py, test_core_tools.py, test_object_tools.py, test_event_tools.py, test_preview_tools.py, test_templates.py\n\nKey patterns:\n- FastMCP lifespan = asynccontextmanager yielding None\n- mcp defined BEFORE tool imports (blender-mcp pattern)\n- All tools return JSON: {\"status\": \"ok/error\", ...}\n- Templates wrapped in undo groups (beginGroup/endGroup/cancelGroup)\n- MockWaapiClient in conftest.py with set_response() for per-URI mocking",
      "type": "error",
      "tags": [
        "error",
        "phase1",
        "wwise-mcp",
        "complete",
        "architecture"
      ],
      "timestamp": "2026-02-06T14:47:03.394Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T14:47:03.394Z",
      "lastVerified": "2026-02-06T14:47:03.394Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770390564940_mc6034jus",
      "content": "## Phase 2: MetaSounds Knowledge Base - Complete Scope (2026-02-06)\n\n### What Phase 2 Delivers\n**Goal**: Build a node database + graph specification format for MetaSounds. Generates JSON intermediate representation (independent of UE5 at runtime) that maps 1:1 to Builder API calls. Works offline.\n\n**Timeline**: 1-2 days\n**Deliverable**: MetaSounds knowledge base + graph spec generator. Output: JSON specs documenting exact graph structure, useful even without UE5.\n\n### What Data Needs to be in Knowledge Base\n**Source**: research/research_metasounds_game_audio.md (80+ nodes catalogued)\n\n#### Categories (13):\n1. **Generators** (5): Additive Synth, Saw, Sine, Square, Triangle\n2. **Generators Advanced** (5): SuperOscillator, WaveTable Oscillator, WaveTable Player, Low Frequency Noise, LFO, Noise (pink/white), Perlin Noise\n3. **Wave Players** (7): Wave Player Mono/Stereo/Quad/5.1/7.1, properties (Loop, LoopStart, LoopDuration, StartTime, PitchShift)\n4. **Envelopes** (5): AD, ADSR, Crossfade, WaveTable Envelope, Evaluate WaveTable (audio-rate + float-rate versions)\n5. **Filters** (8): Biquad, Dynamic, Ladder, State Variable, One-Pole HP/LP, Sample And Hold, Bitcrusher, Mono/Stereo Band Splitter\n6. **Delays** (4): Delay, Stereo Delay, Delay Pitch Shift, Diffuser, Grain Delay\n7. **Dynamics** (4): Compressor, Limiter, Decibels to Linear Gain, Linear Gain to Decibels\n8. **Triggers** (12): Accumulate, Any, Compare, Control, Counter, Delay, Filter, Once, On Threshold, On Value Change, Pipe, Repeat, Route\n9. **Arrays** (6): Get, Set, Num, Random Get (w/ weight), Shuffle, Concatenate, Subset\n10. **Math** (13): Add, Subtract, Multiply, Divide, Abs, Clamp, Log, Power, Modulo, Map Range, Min, Max, Filter Q To Bandwidth, Linear To Log Frequency\n11. **Mix** (2): Mono Mixer (N→1), Stereo Mixer (N stereo→1)\n12. **Spatialization** (3): ITD Panner, Stereo Panner, Mid-Side Encode/Decode\n13. **Music/Utility** (12+): Frequency To MIDI, MIDI To Frequency, MIDI Note Quantizer, Scale to Note Array, BPM To Seconds, Random Bool/Float/Int/Time, Get Wave Info, Print Log, Audio Bus Reader, Wave Writer, Envelope Follower, Flanger, RingMod, WaveShaper, InterpTo, Get WaveTable From Bank\n\n**Data Per Node**:\n- Node class name (from Builder API discovery via Shift+hover)\n- Category\n- Inputs (pin name, data type: Audio/Trigger/Float/Int32/Bool/Time/String/UObject/Enum/WaveAsset/Array variants)\n- Outputs (same types)\n- Default values\n- Tags/capabilities (e.g., \"synthesis\", \"modulation\", \"spatial\", \"percussive\")\n\n### D1 Schema (6 Tables)\n**Database**: `ue-audio-knowledge` (independent from SIDKIT)\n\n**Table 1: metasound_nodes** (~80 rows)\n```sql\nid (TEXT PK)\nname (TEXT) -- e.g., \"Sine\", \"Biquad Filter\"\ncategory (TEXT) -- Generators, Filters, Envelopes, etc.\nclass_name (TEXT) -- Full C++ class for Builder API, e.g., \"Metasound::FSineNode\"\ndescription (TEXT)\ndata_type (TEXT) -- Primary output type: Audio/Trigger/Float/Int32/Bool\ninputs (JSON) -- [{pin_name, type, default_value}, ...]\noutputs (JSON) -- [{pin_name, type}, ...]\ntags (JSON) -- [\"modulation\", \"percussive\", \"spatial\", ...]\ncomplexity (INT) -- 1-5 for difficulty\n```\n\n**Table 2: waapi_functions** (87 rows from WAAPI reference)\n```sql\nid (TEXT PK)\nnamespace (TEXT) -- e.g., \"ak.wwise.core.object\"\noperation (TEXT) -- e.g., \"create\"\nfull_name (TEXT) -- \"ak.wwise.core.object.create\"\ndescription (TEXT)\nparameters (JSON) -- [{param_name, type, required, description}, ...]\nreturns (JSON) -- [{field_name, type}, ...]\nobject_types (JSON) -- Array of object types it applies to\nexamples (JSON) -- Code snippets\n```\n\n**Table 3: wwise_types** (16 rows)\n```sql\ntype_name (TEXT PK) -- Sound, RandomSequenceContainer, SwitchContainer, etc.\ndescription (TEXT)\nproperties (JSON) -- [{prop_name, type, default, description}, ...]\nhierarchy_allowed (BOOL) -- Can it have children?\nevents_applicable (BOOL) -- Can events play it?\ngame_parameters (JSON) -- [\"Volume\", \"Pitch\", ...]\n```\n\n**Table 4: audio_patterns** (6 rows initially)\n```sql\npattern_type (TEXT PK) -- gunshot, footsteps, ambient, spatial, ui_sound, weather\ndescription (TEXT)\nmetasounds_graph (JSON) -- Template graph spec (nodes + connections)\nwwise_equivalent (JSON) -- Equivalent Wwise structure\nblueprint_logic (TEXT) -- Blueprint trigger/parameter setup\ncomplexity (INT) -- 1-5\ngame_examples (JSON) -- [\"Lyra\", \"Fortnite\", ...]\n```\n\n**Table 5: error_patterns** (grows over time)\n```sql\nerror_hash (TEXT PK) -- hash(error_signature + template + params)\nerror_signature (TEXT) -- e.g., \"node_type_mismatch\"\ntemplate_used (TEXT) -- Which pattern failed\nparameters (JSON) -- What was being generated\nsuccessful_fix (TEXT) -- What worked\nsuccess_rate (FLOAT) -- % of times this fix works\nmetadata (JSON) -- {\"first_seen\": date, \"last_seen\": date}\n```\n\n**Table 6: ue_game_examples** (reference only)\n```sql\ngame_name (TEXT PK)\nsystem_type (TEXT) -- footsteps, weapons, ambient, etc.\ndescription (TEXT)\nreference_docs (JSON) -- Links to source files\nmetasounds_patches (JSON) -- Which patches used\nwwise_hierarchy (JSON) -- Wwise structure\ncomplexity (INT)\n```\n\n### Vectorize Semantic Search\n**Index**: `ue-audio-index` (independent embeddings)\n**Purpose**: Semantic queries alongside D1 structured queries\n\n**Embedding strategy**:\n- Embed node descriptions + tags → `metasound_nodes` index\n- Embed pattern descriptions + use cases → `audio_patterns` index\n- Embed error signatures + fixes → `error_patterns` index\n\n**Example queries**:\n- \"make it sound underwater\" → finds [Lowpass, Biquad, wet reverb pattern]\n- \"add spatial movement\" → finds [ITD Panner, Stereo Panner, Doppler effect]\n- \"weapon fire repetition issue\" → finds stored fixes for gunshot repetition\n\n**Implementation**: \n- Use Cloudflare's built-in embeddings API (same as SIDKIT)\n- Vectorize at seed time (one-time from research data)\n- Update incrementally as errors are learned\n\n### Cloudflare Workers Needed\n**Purpose**: API endpoints for MCP server to query D1 + Vectorize\n\n**Worker 1: D1 Query Endpoint** (`/api/d1-query`)\n```\nPOST /api/d1-query\nBody: {\n  table: \"metasound_nodes\",\n  where: {category: \"Filters\"},\n  limit: 50\n}\nReturns: JSON rows from D1\n```\n\n**Worker 2: Vectorize Search Endpoint** (`/api/vectorize-search`)\n```\nPOST /api/vectorize-search\nBody: {\n  index: \"ue-audio-index\",\n  query: \"make it underwater\",\n  limit: 10\n}\nReturns: Top 10 semantic matches with scores\n```\n\n**Worker 3: Knowledge Upsert** (`/api/upsert-knowledge`)\n```\nPOST /api/upsert-knowledge\nBody: {\n  table: \"metasound_nodes\",\n  data: {...node definition...}\n}\nWrites to D1 + re-embeds for Vectorize\n```\n\n**Worker 4: Error Learning** (`/api/store-error`)\n```\nPOST /api/store-error\nBody: {\n  error_signature: \"...\",\n  template_used: \"...\",\n  successful_fix: \"...\"\n}\nStores to error_patterns table + updates success_rate\n```\n\n### D1 Seeding Strategy\n**One-time bootstrap** (2-3 hours):\n1. Parse `research_metasounds_game_audio.md` → extract 80+ nodes\n2. Generate structured JSON for each node\n3. Parse `research_waapi_mcp_server.md` section 4 (87 WAAPI functions)\n4. Extract Wwise types from CLAUDE.md (16 object types)\n5. Build 6 pattern templates (gunshot, footsteps, etc.) as graph specs\n6. Upload all to D1 via Worker\n7. Run Vectorize embeddings via Cloudflare API\n\n**Ongoing growth**:\n- Each build failure stores error_signature + fix in `error_patterns`\n- New patterns discovered in Phase 4 added to `audio_patterns`\n- Custom nodes from community projects indexed as needed\n\n### Phase 2 Dependencies & Blockers\n**No blockers**: Knowledge base is purely data + offline.\n\n**Dependencies on Phase 2**:\n- Phase 3 (UE5 Plugin) needs Phase 2's node database + graph spec format (to feed to Builder API)\n- Phase 4 (Systems Layer) needs Phase 2's pattern templates + error learning\n\n**External dependencies**:\n- Cloudflare account setup (D1 database + Vectorize index) — ALREADY DONE in previous work\n- waapi-client library documentation (for WAAPI function params) — available\n- UE5 source code access (for node class names) — public, can Shift+hover in Editor\n\n### Key Questions Answered\n1. **\"What goes in the knowledge base?\"** → 80+ MetaSounds nodes, 87 WAAPI functions, 16 Wwise types, 6 game patterns, error→fix mappings, game examples\n2. **\"How is it structured?\"** → 6 D1 tables, Vectorize index for semantic search, Cloudflare Workers for API endpoints\n3. **\"How does it serve Phase 3?\"** → UE5 plugin queries D1 for node class names, validates graph specs against schema before sending to Builder API\n4. **\"How does error learning work?\"** → Same SIDKIT pattern: error_signature (hash of error + context) → successful_fix mapping, stored in D1, queryable for next generation attempt\n5. **\"Cloudflare setup?\"** → Own D1 database `ue-audio-knowledge` + own Vectorize index `ue-audio-index`, separate Workers, fully independent from SIDKIT at runtime\n",
      "type": "config",
      "tags": [
        "config",
        "database",
        "api",
        "phase-2",
        "metasounds",
        "knowledge-base",
        "d1-schema",
        "vectorize",
        "cloudflare-workers",
        "architecture"
      ],
      "timestamp": "2026-02-06T15:09:24.940Z",
      "context": "Phase 2 comprehensive analysis for UE5-WWISE MCP project",
      "accessCount": 2,
      "lastAccessed": "2026-02-07T11:54:06.223Z",
      "lastVerified": "2026-02-06T15:09:24.940Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770393132925_d8harfuq3",
      "content": "Phase 2 (MetaSounds Knowledge Base) COMPLETE — 2026-02-06. 7 new MCP tools, 40 new tests, 92 total passing. SQLite DB with 8 tables (234 entries), TF-IDF semantic search via numpy, 7-stage graph validator, 6 MetaSounds templates. Total project: 27 tools (20 Wwise + 7 MetaSounds). Next: Phase 3 (UE5 C++ Plugin with TCP server on port 9877, UEdGraphSchema_K2 for runtime node discovery).",
      "type": "general",
      "tags": [
        "general",
        "ue5-wwise",
        "phase2",
        "milestone",
        "complete"
      ],
      "timestamp": "2026-02-06T15:52:12.925Z",
      "context": "Phase 2 implementation of UE Audio MCP project",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T15:52:12.925Z",
      "lastVerified": "2026-02-06T15:52:12.925Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770394913628_hmzbx2fol",
      "content": "MetaSound Builder API (UMetaSoundBuilderBase) - 113 public methods documented at dev.epicgames.com. Key functions: CreateSourceBuilder, CreatePatchBuilder, AddNodeByClassName, AddInterface, ConnectNodes, FindNodeInputByName, FindNodeOutputByName, AddGraphInputNode, AddGraphOutputNode, SetNodeInputDefault, SetNodeLocation, BuildNewMetaSound, Build, Audition. Key UStructs: FMetaSoundNodeHandle, FMetaSoundBuilderNodeInputHandle, FMetaSoundBuilderNodeOutputHandle. Limitations: no variable support, paged inputs limited, live updates beta (5.5+). Template nodes only in C++ not Blueprint.",
      "type": "general",
      "tags": [
        "general",
        "api",
        "ue5-wwise",
        "builder-api",
        "phase3",
        "metasounds",
        "api-reference"
      ],
      "timestamp": "2026-02-06T16:21:53.628Z",
      "context": "Builder API research from official UE5 docs for Phase 3 C++ plugin implementation",
      "accessCount": 1,
      "lastAccessed": "2026-02-07T11:54:06.223Z",
      "lastVerified": "2026-02-06T16:21:53.628Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770395566744_uo1j7e0fj",
      "content": "Completed comprehensive UE5 Blueprint node research covering 7 systems with 100+ nodes documented. File at /Users/radek/Documents/GIthub/UE5-WWISE/research/research_ue5_blueprint_nodes.md. Systems covered: Enhanced Input (UEnhancedInputComponent, triggers, modifiers), Save Game (USaveGame, sync/async save/load), Collision/Traces (line/sphere/box/capsule traces + overlaps, FHitResult 19 fields), Material Parameters (UMaterialInstanceDynamic, full C++ API), Subsystems (5 types: Engine/Editor/GameInstance/World/LocalPlayer), DataTables (10 nodes), Struct operations (Make/Break for FVector, FRotator, FTransform, FLinearColor, FHitResult). All verified against UE 5.7 official docs at dev.epicgames.com.",
      "type": "general",
      "tags": [
        "general",
        "api",
        "ue5",
        "blueprint",
        "research",
        "nodes",
        "enhanced-input",
        "save-game",
        "collision",
        "materials",
        "subsystems",
        "datatables",
        "structs"
      ],
      "timestamp": "2026-02-06T16:32:46.744Z",
      "context": "UE5-WWISE project research for building MCP server knowledge base",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T16:32:46.744Z",
      "lastVerified": "2026-02-06T16:32:46.744Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770395869075_kyszk57eb",
      "content": "UE5 Blueprint Nodes research file at /Users/radek/Documents/GIthub/UE5-WWISE/research/research_ue5_blueprint_nodes.md is already comprehensive with 580+ lines covering: Enhanced Input (UEnhancedInputComponent, UInputAction, UInputMappingContext, triggers, modifiers), Save Game (USaveGame, 7 Blueprint nodes), Collision/Traces (24 trace nodes, 11 overlap nodes, full FHitResult), Material Parameters (MID create/set/get, MPC nodes), Subsystems (5 types with C++ accessors), DataTables (9 nodes), and Struct Break/Make operations. All verified against UE 5.7 docs.",
      "type": "general",
      "tags": [
        "general",
        "ue5",
        "blueprint-nodes",
        "research",
        "documentation"
      ],
      "timestamp": "2026-02-06T16:37:49.075Z",
      "context": "Research validation - the file already existed and is complete",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T16:37:49.075Z",
      "lastVerified": "2026-02-06T16:37:49.075Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770396006090_05ggmyyxc",
      "content": "Completed research on Wwise UE5 Blueprint integration nodes. File: /Users/radek/Documents/GIthub/UE5-WWISE/research/research_wwise_ue5_blueprint_nodes.md\n\nKey findings:\n- UAkGameplayStatics: 40+ static BlueprintCallable functions (PostEvent, SetRTPCValue, SetState, SetSwitch, LoadBank, StopActor, SpawnAkComponentAtLocation, etc.)\n- UAkComponent: 17+ instance functions (PostAkEvent, PostAssociatedAkEvent, Stop, SetRTPCValue, SetSwitch, SeekOnEventBySeconds, SetAttenuationScalingFactor, etc.)\n- Wwise 2022.1+ introduced typed asset classes: UAkRtpc, UAkStateValue, UAkSwitchValue, UAkAudioEvent, UAkTrigger, UAkAuxBus, UAkAudioBank\n- Verified against 3 SDK source dumps (Satisfactory, RadicalHeights, PUBG) + 8 tutorial/blog sources\n- Header: Plugins/Wwise/Source/AkAudio/Classes/AkGameplayStatics.h\n- 85+ total functions documented across all classes",
      "type": "general",
      "tags": [
        "general",
        "wwise",
        "ue5",
        "blueprint",
        "research",
        "api-reference"
      ],
      "timestamp": "2026-02-06T16:40:06.090Z",
      "context": "Research task for UE5-WWISE MCP project. These functions are what our MCP server needs to be able to trigger via the UE5 C++ plugin bridge on port 9877.",
      "accessCount": 1,
      "lastAccessed": "2026-02-07T01:33:25.182Z",
      "lastVerified": "2026-02-06T16:40:06.090Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770396033275_rv33wjk4m",
      "content": "Expanded research_ue5_blueprint_nodes.md from 7 categories (580 lines) to 19 sections (1000+ lines) with 400+ Blueprint nodes. New sections added: Math Comparison (Section 8), Interpolation/Lerp (Section 9), Math Random (Section 10), Damage System (Section 11), Mesh/Static Mesh (Section 12), Audio-Adjacent (Section 13), Viewport/Screen (Section 14), Platform Detection (Section 15), EQS (Section 16), Collision/Overlap Events Extended (Section 17), Struct Operations Extended (Section 18), UGameplayStatics Extended (Section 19). All verified against UE 5.7 official docs at dev.epicgames.com.",
      "type": "general",
      "tags": [
        "general",
        "ue5",
        "blueprint",
        "research",
        "nodes",
        "documentation"
      ],
      "timestamp": "2026-02-06T16:40:33.275Z",
      "context": "UE5-WWISE project blueprint node research expansion",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T16:40:33.275Z",
      "lastVerified": "2026-02-06T16:40:33.275Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770396089625_s2evy82k8",
      "content": "Created comprehensive UE5 Blueprint Function Libraries research at /Users/radek/Documents/GIthub/UE5-WWISE/research/research_ue5_blueprint_libraries.md. Covers 5 major Kismet libraries: UKismetMathLibrary (300+ functions across 15+ categories), UKismetStringLibrary (40+ functions), UKismetSystemLibrary (120+ functions), UKismetArrayLibrary (15+ generic functions), UGameplayStatics (100+ functions). Includes audio-relevant function summary for the UE Audio MCP project. All function names verified from official Epic source code mirrors, Python API, and documentation.",
      "type": "code",
      "tags": [
        "code",
        "python",
        "api",
        "ue5",
        "blueprint",
        "api-reference",
        "kismet",
        "research"
      ],
      "timestamp": "2026-02-06T16:41:29.625Z",
      "context": "UE5-WWISE project research phase",
      "accessCount": 0,
      "lastAccessed": "2026-02-06T16:41:29.625Z",
      "lastVerified": "2026-02-06T16:41:29.625Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770424373888_v1byu7gmk",
      "content": "Epic Tutorial Pages for Agent Knowledge Base — 6 complete guides scraped:\n\n1. MetaSounds Quick Start — Bomb (spatial, explosion variations) + Wind (noise synthesis, LFO filter, velocity-reactive)\n   URL: dev.epicgames.com/documentation/en-us/unreal-engine/metasounds-quick-start\n\n2. Audio Modulation Quick Start — Control Buses (CB_Main, CB_SFX, CB_Music), Sound Classes, Bus Mixes, Level Blueprint control\n   URL: dev.epicgames.com/documentation/en-us/unreal-engine/audio-modulation-quick-start-guide\n\n3. Quartz Quick Start — Sample-accurate timing, Quartz clock, quantized playback, beat-sync actor scaling\n   URL: dev.epicgames.com/documentation/en-us/unreal-engine/quartz-quick-start\n\n4. WaveTables Quick Start — Fixed Resolution + Fixed Sample Rate banks, WaveTable Player, WaveTable Envelope\n   URL: dev.epicgames.com/documentation/en-us/unreal-engine/wavetables-quick-start-in-unreal-engine\n\n5. Procedural Music — Full synthesizer: melody generation (Random Get → Scale to Note Array → MIDI to Freq), sine/saw oscillators, crossfade, ladder filter + LFO (500-5000Hz), AD envelope, stereo delay (ping-pong). Blueprint Actor with 3 trigger zones controlling BPM, crossfade, and melody regeneration.\n   URL: dev.epicgames.com/documentation/en-us/unreal-engine/creating-procedural-music-with-metasounds\n\n6. Audio Gameplay Volumes Quick Start — Reverb zones, Sound Class routing, Audio Gameplay Volumes plugin\n   URL: dev.epicgames.com/documentation/en-us/unreal-engine/audio-gameplay-volumes-quick-start\n\nTotal: ~12 MetaSounds graphs, ~8 Blueprint graphs, ~8 complete audio systems.\nAll instructions follow parseable patterns: \"create X node\", \"drag off Y and create Z\", \"enter V for Pin\", \"connect A to B\".",
      "type": "solution",
      "tags": [
        "solution",
        "ue5",
        "tutorials",
        "workflows",
        "scraping",
        "knowledge-base"
      ],
      "timestamp": "2026-02-07T00:32:53.888Z",
      "context": "Blueprint+MetaSounds workflow sources for agent training data",
      "accessCount": 1,
      "lastAccessed": "2026-02-07T11:54:06.223Z",
      "lastVerified": "2026-02-07T00:32:53.888Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770424679539_84wm8j9pn",
      "content": "Epic Documentation Pages — Additional Reference Material Scraped:\n\n7. MetaSounds Function Nodes Reference — 107+ nodes across 16 categories:\n   General(7), Array(8), Debug(2), Delays(5), Dynamics(5), Envelopes(6), External IO(2), Filters(11), Generators(15), Math(15), Mix(2), Music(4), Random(4), Spatialization(4), Triggers(16)\n   URL: dev.epicgames.com/.../metasound-function-nodes-reference-guide-in-unreal-engine\n\n8. MetaSounds Reference Guide — Type system: 9 pin types (Trigger, Audio, Time, String, UObject, Bool, Float, Int32, Enum), conversion table, 3 interfaces (OneShot, Attenuation, Spatialization), 2 asset types (Source, Patch)\n   URL: dev.epicgames.com/.../metasounds-reference-guide-in-unreal-engine\n\n9. MetaSound Builder API — 109 Blueprint functions: CreateSourceBuilder, AddNode, ConnectNodes, Audition, BuildToAsset, etc. Beta, live updates supported.\n   URL: dev.epicgames.com/.../metasound-builder-api-in-unreal-engine\n\n10. Soundscape Quick Start — Procedural ambient: SoundscapeStates (GameplayTags), Palettes, Colors, Trigger Volumes. Blueprint: OnOverlap → SetState/ClearState via SoundscapeSubsystem.\n    URL: dev.epicgames.com/.../soundscape-quick-start\n\n11. Spatialization Overview — 3 methods: Panning (linear/equal-power/VBAP), Soundfield (Ambisonics), Binaural (HRTF/ITD/ILD). Only mono/stereo sources supported.\n    URL: dev.epicgames.com/.../spatialization-overview-in-unreal-engine\n\n12. Sound Attenuation Reference — 8 subsystems: Volume (5 curve types + shapes), Spatialization (panning/binaural), Air Absorption (LP/HP freq curves), Focus (azimuth-based), Reverb (distance-based send), Occlusion (trace-based LPF), Priority (distance-based), Submix (distance-based routing).\n    URL: dev.epicgames.com/.../sound-attenuation-in-unreal-engine\n\nOur DB comparison: Python catalogues have 112 MetaSounds nodes (close to Epic's 107+ official), 948 Blueprint nodes, 55 Blueprint audio functions. DB tables exist but are empty (seed not run).",
      "type": "troubleshooting",
      "tags": [
        "troubleshooting",
        "python",
        "api",
        "ue5",
        "reference",
        "metasounds",
        "spatial",
        "attenuation",
        "knowledge-base"
      ],
      "timestamp": "2026-02-07T00:37:59.539Z",
      "context": "Additional Epic docs pages scraped for agent knowledge base",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T00:37:59.539Z",
      "lastVerified": "2026-02-07T00:37:59.539Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770427308922_al99133vk",
      "content": "Phase 3 Code Review Complete (2026-02-07). 156 tests pass. Key findings: (1) CRITICAL: No max message size check on TCP recv - uint32 allows up to 4GB allocation. (2) CRITICAL: Socket not cleaned up on send failure - is_connected() false positives. (3) WARNING: _seed_console_commands mutates imported data. (4) WARNING: bp_search/bp_node_info use private _fetch method. (5) WARNING: No validation on source param in bp_search/bp_list_categories. (6) WARNING: bp_search test has vacuous assertion (assert True). (7) SUGGESTION: table_counts() could be a loop. Full review written up with code references.",
      "type": "warning",
      "tags": [
        "warning",
        "code-review",
        "phase3",
        "ue5-plugin",
        "security"
      ],
      "timestamp": "2026-02-07T01:21:48.922Z",
      "context": "Code review of Phase 3 UE5 Plugin Connectivity",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T01:21:48.922Z",
      "lastVerified": "2026-02-07T01:21:48.922Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770428276910_6ceaq94hy",
      "content": "ORCHESTRATION LAYER DESIGN - COMPLETE BUILDING BLOCKS INVENTORY\n\n## 1. TEMPLATES STRUCTURE\nMetaSounds Templates (8 JSON files in src/ue_audio_mcp/templates/metasounds/):\n- gunshot.json: OneShot, random sample selection + pitch variation + ADSR\n- footsteps.json: OneShot, trigger routing by surface type + random sample + AD envelope + lowpass\n- ambient.json: Looping, wave player + LFO modulation + stereo mixer\n- spatial.json: OneShot + Spatialization, wave player + ITD panner for binaural\n- ui_sound.json: OneShot, sine oscillator + AD envelope (procedural click)\n- weather.json: Looping, wave player + InterpTo smoothing + Map Range cutoff + Biquad filter\n- snare.json: (8 days old, added after Phase 2)\n- wind.json: (8 days old, added after Phase 2)\n\nBlueprint Templates (9 JSON files in src/ue_audio_mcp/templates/blueprints/):\n- bomb_fuse.json: BeginPlay → SpawnSound2D → Delay → SetBoolParameter (timer pattern)\n- wind_system.json, audio_modulation.json, quartz_beat_sync.json, etc. (8 more templates)\n\nWwise Templates (5 template_* functions in tools/templates.py):\n- template_gunshot(weapon_name, num_variations, pitch_randomization)\n- template_footsteps(surface_types, with_switch_group)\n- template_ambient(layer_names, rtpc_parameter_name)\n- template_ui_sound(sound_name, bus_path)\n- template_weather_states(weather_states)\nAll wrap WAAPI calls in undo groups for atomic rollback.\n\n## 2. GRAPH SYSTEM (MetaSounds)\nGraphSpec JSON Format (from graph_schema.py):\n- Required fields: name, asset_type, nodes, connections\n- Optional: inputs, outputs, interfaces, descriptions\n- Node sentinel: \"__graph__\" represents graph boundary for I/O wiring\n\nValidation (validate_graph):\n- 7-stage validator: required fields, asset_type, interfaces, nodes, connections, required inputs, interface pins\n- Returns ALL errors in one pass (accumulation, not early exit)\n- Pin type compatibility via PIN_COMPATIBILITY matrix\n- Checks for duplicate IDs, missing nodes, type mismatches\n\nBuilder Command Generation (graph_to_builder_commands):\n- 8-stage sequential command ordering:\n  1. create_builder\n  2. add_interface (per interface)\n  3. add_graph_input (per input)\n  4. add_graph_output (per output)\n  5. add_node (per node with position)\n  6. set_default (per non-None default value)\n  7. connect (per connection)\n  8. build_to_asset\n- Returns list[dict] with \"action\" key for each command\n\nms_graph_from_template tool:\n- Loads template JSON from disk\n- Applies parameter overrides using dotted syntax: \"node_id.input_name\": value\n- Returns spec + validation result\n\n## 3. KNOWLEDGE SEARCH CAPABILITIES\nKnowledgeDB (db.py) - 14 query methods:\n- query_nodes(category, tag, name): MetaSounds nodes\n- query_waapi(namespace, operation): WAAPI functions\n- query_patterns(pattern_type): Audio patterns\n- query_errors(signature): Error learning (SIDKIT pattern)\n- query_tutorial_workflows(tag): Tutorial workflows\n- search_blueprint_curated(query, category): Blueprint audio+core\n- search_blueprint_scraped(query): Blueprints by text search\n- query_builder_api(category): Builder API functions\n- count_nodes_by_category(), table_counts(), is_seeded()\n\nEmbeddingIndex (embeddings.py) - TF-IDF semantic search:\n- Tokenizes name + description + tags\n- 39 stop words removed\n- Builds vocabulary + document frequency\n- L2-normalize vectors for cosine similarity\n- search(query, top_k) returns scored results\n- build_index_from_nodes(METASOUND_NODES) creates index\n- Lightweight: no ML deps, <1ms queries on 400 entries\n\nDatabase Tables (14 total):\n1. metasound_nodes: 112 entries (category, description, inputs/outputs, tags, complexity)\n2. waapi_functions: 32 entries (namespace, operation, description, params, returns)\n3. wwise_types: 19 entries (type_name, category, properties)\n4. audio_patterns: 6 entries (name, pattern_type, description, graph_spec, key_nodes)\n5. error_patterns: 0 entries (grows at runtime via store_error)\n6. ue_game_examples: 5 entries (game, system_type, details)\n7. blueprint_audio: 24 entries (class_name, category, params, returns, tags)\n8. blueprint_core: 36 entries (same structure as blueprint_audio)\n9. blueprint_nodes_scraped: ~200 entries (name, target, category, description, inputs, outputs)\n10. builder_api_functions: 109 entries (Builder API reference)\n11. tutorial_workflows: 8 entries (tutorial, url, layers, tags, bp_template, ms_template)\n12. audio_console_commands: ~20 entries (cmd, category, type, default, description)\n13. spatialization_methods: 6 entries (description, details)\n14. attenuation_subsystems: 8 entries (description, params, details)\n\n## 4. ALL 37 TOOLS INVENTORY\nGrouped by specialization:\n\nWWISE CORE (5 tools - core.py):\n- wwise_connect(url): WAAPI connection\n- wwise_get_info(): Version + platform + project\n- wwise_query(waql, return_fields): WAQL object queries\n- wwise_save(): Save project\n- execute_waapi(uri, args_json, options_json): Raw WAAPI RPC\n\nWWISE OBJECTS (4 tools - objects.py):\n- wwise_create_object(parent_path, object_type, name, on_conflict)\n- wwise_set_property(object_path, property_name, value)\n- wwise_set_reference(object_path, reference_name, value)\n- wwise_import_audio(import_path, destination_parent)\n\nWWISE EVENTS & MIXING (4 tools - events.py):\n- wwise_create_event(name, target_path, action_type, event_parent)\n- wwise_create_game_parameter(name, min_value, max_value, default_value)\n- wwise_assign_switch(object_path, switch_group_id, switch_id)\n- wwise_set_attenuation(object_path, attenuation_curve_json)\n\nWWISE PREVIEW & GENERATION (2 tools - preview.py):\n- wwise_preview(object_path, duration_ms)\n- wwise_generate_banks(language, platform)\n\nWWISE TEMPLATES (5 tools - templates.py):\n- template_gunshot(weapon_name, num_variations, pitch_randomization)\n- template_footsteps(surface_types, with_switch_group)\n- template_ambient(layer_names, rtpc_parameter_name)\n- template_ui_sound(sound_name, bus_path)\n- template_weather_states(weather_states)\n→ All return JSON with IDs, wrap WAAPI calls in undo groups\n\nMETASOUNDS KNOWLEDGE (4 tools - metasounds.py):\n- ms_list_nodes(category, tag): MetaSounds node list\n- ms_node_info(node_name): Full node spec (inputs/outputs/defaults)\n- ms_search_nodes(query): Semantic search via TF-IDF\n- ms_list_categories(): Node category counts\n\nMETASOUNDS GRAPH (3 tools - ms_graph.py):\n- ms_validate_graph(graph_spec): 7-stage validation\n- ms_graph_to_commands(graph_spec): Convert to Builder command sequence\n- ms_graph_from_template(template_name, params): Load + override template\n\nMETASOUNDS BUILDER (7 tools - ms_builder.py):\n- ms_build_graph(graph_spec): Validate + convert + execute full pipeline\n- ms_create_source(name, asset_type): Create builder in UE5\n- ms_add_node(node_type, node_id, position_x, position_y): Add node\n- ms_connect_pins(from_node, from_pin, to_node, to_pin): Wire connection\n- ms_set_default(node_id, input, value): Set default value\n- ms_audition(duration_ms): Preview MetaSound\n- ms_save_asset(name, path): Save to disk\n\nUE5 CORE (3 tools - ue5_core.py):\n- ue5_connect(host, port): TCP connection to plugin (port 9877)\n- ue5_get_info(): Ping plugin for version/features\n- ue5_status(): Combined Wwise + UE5 connection status\n\nBLUEPRINTS (2 tools - blueprints.py):\n- bp_search(query, category, source): Search nodes (curated + scraped)\n- bp_node_info(node_name): Full pin specs from db\n- bp_call_function(node_name, args_json): Execute Blueprint node\n- bp_list_categories(): Category counts\n\nTOOL CHARACTERISTICS:\n- Low-level: Single-action tools (create 1 object, set 1 property, query 1 type)\n- Medium-level: Template tools (3-5 WAAPI calls wrapped in undo)\n- High-level: Pipeline tools (validate + convert + execute full graph)\n- Pattern: All return _ok(dict) or _error(str)\n\n## 5. AUDIO PATTERNS TABLE\n6 patterns stored in db (table: audio_patterns):\n- gunshot: pattern_type=procedural, graph_spec={...}\n- footsteps: pattern_type=procedural\n- ambient: pattern_type=layered\n- spatial: pattern_type=spatialization\n- ui_sound: pattern_type=procedural\n- weather: pattern_type=layered\n\nEach stores: name, pattern_type, description, graph_spec (full JSON), complexity (1-5), key_nodes (list)\n\n## 6. TUTORIAL WORKFLOWS TABLE\n8 tutorials in db:\n- name, tutorial (Epic doc title), url, layers (list), description, tags, bp_template, ms_template\n- Curated from Epic's official Quick Start docs\n- Each entry maps to one Blueprint template + one MetaSound template\n\n## ORCHESTRATION LAYER DESIGN IMPLICATIONS\n\nThe orchestration layer will:\n1. Take high-level description (NL): \"footsteps with surface switching\"\n2. Query tutorial_workflows OR audio_patterns tables to find matching system\n3. Instantiate Blueprint template (Blueprint layer - WHEN game events trigger)\n4. Instantiate MetaSound template (MetaSound layer - WHAT DSP synthesis)\n5. Instantiate Wwise template (Wwise layer - HOW final mixing/spatializ)\n6. Wire layer outputs together via UE5 Remote Control API + AudioLink\n7. Return combined asset spec (paths to all 3 generated objects)\n\nKey orchestration decisions:\n- Use template + parameter overrides as generation primitives\n- Fall back to knowledge search when no exact template match\n- Error learning: store failed generation attempts for future refinement\n- Layer composition: BP → MetaSounds → Wwise (data flow direction)\n- Atomicity: Wrap all 3-layer generation in Wwise undo group for rollback",
      "type": "config",
      "tags": [
        "config",
        "api",
        "database",
        "orchestration",
        "ue-audio-mcp",
        "phase-4-design",
        "templates",
        "graph-system",
        "knowledge-db"
      ],
      "timestamp": "2026-02-07T01:37:56.910Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T01:37:56.910Z",
      "lastVerified": "2026-02-07T01:37:56.910Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770430509907_jq02m2s17",
      "content": "UE5 Plugin Security Review (2026-02-07):\nCRITICAL findings:\n1. ConnectNodes() in AudioMCPBuilderManager.cpp references undeclared members (GraphInputOutputIndices, NodeOutputHandles, NodeHandleIndices, etc.) - code WILL NOT COMPILE\n2. call_function command allows arbitrary UE reflection calls with no allowlist - any Blueprint-exposed function on GameplayStatics/World/GameInstance callable via TCP\n3. ActiveBuilder is raw UObject* without GC protection (UPROPERTY) - dangling pointer risk\n4. Shutdown race: ShutdownModule on game thread blocks in WaitForCompletion while AsyncTask needs game thread - 25s timeout delay\n5. No authentication on TCP server (mitigated by 127.0.0.1 binding)",
      "type": "code",
      "tags": [
        "code",
        "authentication",
        "ue5-plugin",
        "security-review",
        "code-review"
      ],
      "timestamp": "2026-02-07T02:15:09.907Z",
      "context": "Full security and quality review of UE5 C++ plugin at ue5_plugin/UEAudioMCP/",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T02:15:09.907Z",
      "lastVerified": "2026-02-07T02:15:09.907Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770431237386_5i0pk0hf6",
      "content": "UE5 Plugin TCP Server Best Practices - Research Summary\n\nARCHITECTURE PATTERNS:\n1. **blender-mcp gold standard**: Addon (socket server inside app) + MCP server (FastMCP), TCP+JSON, main thread dispatch\n2. **chongdashu/unreal-mcp leader**: Python MCP → TCP socket → C++ plugin (1,370 stars), modular tool files pattern\n3. **Game thread dispatch**: AsyncTask with ENamedThreads::GameThread is standard for worker threads → game thread\n4. **Socket server location**: Inside the DCC app (plugin) NOT in MCP server\n\nKEY FINDINGS:\n\nTHREADING & GAME THREAD SAFETY:\n- FRunnable/FRunnableThread pattern for worker threads (separate async thread)\n- NEVER create/modify/delete UObjects from background threads\n- Use AsyncTask with ENamedThreads::GameThread to dispatch callbacks to game thread\n- CRITICAL: Deadlock risk when GC running + tasks queued on background threads\n- Solution: Use ENamedThreads::AnyHiPriThreadNormalTask (only group that doesn't conflict with GC)\n- Alternative: Do all heavy work on background thread, only spawn UObjects on game thread\n\nOBJECT POINTER MANAGEMENT:\n- TStrongObjectPtr: for holding strong refs inside non-UObject classes (plain C++)\n- NOT for UObject fields (use UPROPERTY instead)\n- Worker threads accessing UObjects: use TWeakObjectPtr.Pin() to get TStrongObjectPtr safely\n- Never directly access UObject from worker thread unless certain it's rooted (AddToRoot)\n- Creating/destroying TStrongObjectPtr is expensive, keep them long-lived\n\nSHUTDOWN DEADLOCK AVOIDANCE:\n- Module shutdown can deadlock if:\n  1. FRunnable thread still running during ~FModule\n  2. Trying to create UObjects as module unloads\n  3. Background task waiting for GC that's waiting for background tasks\n- Solutions:\n  a) Clean stop worker threads BEFORE module cleanup (FRunnable::Stop called early)\n  b) Use weak references instead of strong refs during shutdown\n  c) Fire pending game-thread tasks with bWaitForCompletion=true in ~FModule\n  d) Avoid UObject creation/deletion during shutdown\n\nREMOTE CONTROL API (Epic's Approach):\n- Remote Control plugin allows HTTP/WS clients to trigger Blueprint events remotely\n- Has some form of security/whitelist (ProcessEvent restrictions, but docs not clear)\n- Use as reference for exposing safe game functions to external clients\n- Sources: Epic documentation, but implementation details need source code review\n\nPRACTICAL PATTERN FOR TCP SERVER:\n1. Worker thread (FRunnable) reads TCP socket (blocking I/O safe)\n2. On message received, queue game-thread task: AsyncTask(ENamedThreads::GameThread, [=]() { ... })\n3. Game thread task processes command, calls BP functions, modifies UObjects\n4. Return response to worker thread, send back to socket\n5. On shutdown: Stop() the FRunnable first, wait for pending tasks with bWaitForCompletion\n\nAVOID DEADLOCK ON SHUTDOWN:\n- Module's ~FRunnable::Stop() signals thread to exit cleanly\n- Wait for FRunnableThread::Kill(true) = wait for completion\n- Flush any pending game-thread tasks from that thread BEFORE exiting\n- Use weak refs for any UObject pointers held by worker thread\n",
      "type": "warning",
      "tags": [
        "warning",
        "python",
        "api",
        "ue5",
        "tcp-server",
        "threading",
        "game-thread",
        "plugin-architecture"
      ],
      "timestamp": "2026-02-07T02:27:17.386Z",
      "context": "Research for UE5-WWISE project C++ plugin TCP server implementation",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T02:27:17.386Z",
      "lastVerified": "2026-02-07T02:27:17.386Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770431272737_xwsb4mfw3",
      "content": "UE5 MetaSounds Builder API signatures (UE 5.4+) - Research findings:\n\nCONFIRMED SIGNATURES (from Epic docs):\n\n1. UMetaSoundBuilderSubsystem - Entry Point\n   - CreateSourceBuilder(FName BuilderName, FMetaSoundBuilderNodeOutputHandle& OnPlayNodeOutput, FMetaSoundBuilderNodeInputHandle& OnFinishedNodeInput, TArray<FMetaSoundBuilderNodeInputHandle>& AudioOutNodeInputs, EMetaSoundBuilderResult& OutResult, EMetaSoundOutputAudioFormat OutputFormat, bool bIsOneShot) -> UMetaSoundSourceBuilder*\n   - CreatePatchBuilder(FName BuilderName, EMetaSoundBuilderResult& OutResult) -> UMetaSoundPatchBuilder*\n   - CreateSourcePresetBuilder(FName BuilderName, TScriptInterface<IMetaSoundDocumentInterface>& ReferencedSourceClass, EMetaSoundBuilderResult& OutResult) -> UMetaSoundSourceBuilder*\n   - CreatePatchPresetBuilder(FName BuilderName, TScriptInterface<IMetaSoundDocumentInterface>& ReferencedPatchClass, EMetaSoundBuilderResult& OutResult) -> UMetaSoundPatchBuilder*\n\n2. UMetaSoundBuilderBase (parent class for Source/Patch builders)\n   - AddNode(TScriptInterface<IMetaSoundDocumentInterface>& NodeClass, EMetaSoundBuilderResult& OutResult) -> FMetaSoundNodeHandle\n   - ConnectNodes(FMetaSoundBuilderNodeOutputHandle& NodeOutputHandle, FMetaSoundBuilderNodeInputHandle& NodeInputHandle, EMetaSoundBuilderResult& OutResult) -> void\n   - FindNodeInputByName(FMetaSoundNodeHandle& NodeHandle, FName InputName, EMetaSoundBuilderResult& OutResult) -> FMetaSoundBuilderNodeInputHandle\n   - FindNodeOutputByName(FMetaSoundNodeHandle& NodeHandle, FName OutputName, EMetaSoundBuilderResult& OutResult) -> FMetaSoundBuilderNodeOutputHandle\n   - SetNodeInputDefault(FMetaSoundBuilderNodeInputHandle& NodeInputHandle, FMetasoundFrontendLiteral& Literal, EMetaSoundBuilderResult& OutResult) -> void\n\n3. UMetaSoundSourceBuilder (extends UMetaSoundBuilderBase)\n   - Audition(UObject* Parent, UAudioComponent* AudioComponent, FOnCreateAuditionGeneratorHandleDelegate OnCreateGenerator, bool bLiveUpdatesEnabled) -> void\n   - SetFormat(EMetaSoundOutputAudioFormat OutputFormat, EMetaSoundBuilderResult& OutResult) -> void\n   - SetBlockRateOverride(float BlockRate) -> void\n   - SetSampleRateOverride(int32 SampleRate) -> void\n   - SetQuality(FName Quality) -> void\n\nBLUEPRINT FUNCTIONS (available):\n- Add MetaSound Node By ClassName\n- Add MetaSound Node From Asset Class\n- Connect Nodes\n- Connect Node Inputs to Matching Graph Interface Inputs\n- Set Node Input Default\n- Build And Overwrite MetaSound\n- Build New MetaSound\n- Audition\n\nMISSING/NOT FOUND IN PUBLIC DOCS:\n- BuildToAsset (method)\n- SetNodeLocation (method)\n- AddGraphInputNode/AddGraphOutputNode (method signatures)\n- AddInterface (method signature)\n- Full EMetaSoundBuilderResult enum definition\n- FMetasoundFrontendClassName constructor details\n- Full FMetasoundFrontendLiteral usage\n\nHANDLE TYPES CONFIRMED:\n- FMetaSoundNodeHandle - Handle to a node in graph\n- FMetaSoundBuilderNodeInputHandle - Handle to node input pin\n- FMetaSoundBuilderNodeOutputHandle - Handle to node output pin\n- Handles should NOT be serialized (change between versions)\n\nRESEARCH GAPS:\n- AddNode in C++ takes TScriptInterface, but Blueprint version may take ClassName string\n- BuildToAsset may be on a different builder class or named differently\n- SetNodeLocation may be editor-only (not runtime)\n- EMetaSoundBuilderResult enum values unknown (Success/Failure likely but unconfirmed)",
      "type": "tip",
      "tags": [
        "tip",
        "api",
        "UE5",
        "MetaSounds",
        "Builder API",
        "API signatures",
        "research"
      ],
      "timestamp": "2026-02-07T02:27:52.737Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T02:27:52.737Z",
      "lastVerified": "2026-02-07T02:27:52.737Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770455434866_qtj0f68z9",
      "content": "UE5 C++ Plugin Modernization Complete (2026-02-07):\n8 steps, 13 files modified, 1 new file (AudioMCPNodeRegistry.h).\n\nKey fixes applied:\n1. Build: \"Metasound\" → \"MetaSound\" in .uplugin, added \"UnrealEd\" dep\n2. GC: TStrongObjectPtr<UMetaSoundBuilderBase> replaces raw pointer\n3. API: Audition uses editor world (not nullptr), case-insensitive asset_type, graph input defaults\n4. Shutdown: SignalShutdown() before StopListening() prevents deadlock\n5. Security: Function allowlist (17 safe audio functions), WorldContextObject auto-fill\n6. TCP: SendExact helper, Socket::Wait for data (not polling), thread_local reusable payload buffer, response size guard\n7. Ping: FModuleManager::IsModuleLoaded replaces IPluginManager::FindEnabledPlugin\n8. NodeTypeMap externalized to AudioMCPNodeRegistry.h\n\nCritical bug found & fixed: WorldContextObject not auto-filled for UGameplayStatics ProcessEvent calls.\nFile sizes post-refactor: largest is AudioMCPBuilderManager.cpp at 512 lines (was 539). Total: 1,776 lines across 8 .cpp files.",
      "type": "error",
      "tags": [
        "error",
        "api",
        "ue5-plugin",
        "c++",
        "modernization",
        "fix-log"
      ],
      "timestamp": "2026-02-07T09:10:34.866Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T09:10:34.866Z",
      "lastVerified": "2026-02-07T09:10:34.866Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770455435502_exycz0v3i",
      "content": "UE5 C++ Plugin Review (2026-02-07):\n- 20 files, ~2100 lines reviewed across 13 primary + 7 supporting files\n- All 5 modernization criteria PASS: TStrongObjectPtr consistent, .Get()/.IsValid() correct, shutdown order correct, SendExact for both header/payload, wire protocol matches Python\n- CRITICAL BUG: BlueprintCommands.cpp ProcessEvent on UGameplayStatics CDO does NOT populate WorldContextObject param. All allowlisted functions (PlaySound2D, SpawnSoundAtLocation, etc.) require it. Will crash or silently fail.\n- WARNING: AudioMCPBuilderManager.h forward-declares FMetaSoundBuilderNodeOutputHandle/InputHandle but uses them as TMap value types (needs full definition)\n- WARNING: AudioMCPTcpServer.h missing #include \"HAL/ThreadSafeBool.h\" (used on line 59)\n- WARNING: Null FMetaSoundNodeHandle passed to FindNodeInputByName for graph input defaults (line 167 of BuilderManager.cpp) - fragile, may silently fail",
      "type": "warning",
      "tags": [
        "warning",
        "python",
        "ue5-plugin",
        "code-review",
        "critical-bug",
        "cpp"
      ],
      "timestamp": "2026-02-07T09:10:35.502Z",
      "context": "Full review of UE5 C++ Audio MCP plugin after modernization",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T09:10:35.502Z",
      "lastVerified": "2026-02-07T09:10:35.502Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770457662241_gpzvok6pf",
      "content": "Python-side MCP tools exploration complete. Key findings:\n\n## UE5PluginConnection (connection.py)\n- Location: `/Users/radek/Documents/GIthub/UE5-WWISE/src/ue_audio_mcp/ue5_connection.py`\n- Singleton pattern: `get_ue5_connection()` (line 120-125)\n- TCP socket to 127.0.0.1:9877, 30s timeout, 4-byte big-endian length prefix + UTF-8 JSON\n- Methods:\n  - `connect(host, port)` → returns dict\n  - `disconnect()` → closes socket\n  - `is_connected()` → checks socket via getpeername()\n  - `send_command(command)` → sends JSON dict, receives response dict (line 79-96)\n  - `_recv_response()` → reads length-prefixed JSON (line 98-107)\n\n## MetaSounds Tools (metasounds.py)\n- Location: `/Users/radek/Documents/GIthub/UE5-WWISE/src/ue_audio_mcp/tools/metasounds.py`\n- 4 tools, no Builder API commands (those are in ms_builder.py)\n- Tools: ms_list_nodes, ms_node_info, ms_search_nodes, ms_list_categories\n- All query METASOUND_NODES catalogue, no C++ plugin interaction\n\n## MetaSounds Builder Tools (ms_builder.py)\n- Location: `/Users/radek/Documents/GIthub/UE5-WWISE/src/ue_audio_mcp/tools/ms_builder.py`\n- 7 tools that call send_command via UE5PluginConnection:\n  1. `ms_build_graph()` (line 27-64) - validates, converts, sends all commands\n  2. `ms_create_source()` (line 68-88) - action: \"create_builder\"\n  3. `ms_add_node()` (line 92-120) - action: \"add_node\"\n  4. `ms_connect_pins()` (line 124-152) - action: \"connect\"\n  5. `ms_set_default()` (line 156-183) - action: \"set_default\"\n  6. `ms_save_asset()` (line 187-210) - action: \"build_to_asset\"\n  7. `ms_audition()` (line 214-228) - action: \"audition\"\n\n## Builder Command Protocol\n- Location: `graph_to_builder_commands()` in `/Users/radek/Documents/GIthub/UE5-WWISE/src/ue_audio_mcp/knowledge/graph_schema.py` (line 239-343)\n- Command sequence:\n  1. create_builder {asset_type, name}\n  2. add_interface {interface} (per interface)\n  3. add_graph_input {name, type, default?}\n  4. add_graph_output {name, type}\n  5. add_node {id, node_type, position}\n  6. set_default {node_id, input, value} (per non-None default)\n  7. connect {from_node, from_pin, to_node, to_pin}\n  8. build_to_asset {name, path}\n\n## Orchestration Layer (systems.py)\n- Location: `/Users/radek/Documents/GIthub/UE5-WWISE/src/ue_audio_mcp/tools/systems.py`\n- PATTERNS dict (line 31-143): gunshot, footsteps, ambient, spatial, ui_sound, weather\n- Each pattern has: ms_template, wwise_template, bp_template, default_params, connections\n- `build_audio_system()` tool (line 412-494): orchestrates all 3 layers\n- Helper functions:\n  - `_load_ms_template()` (line 167-191) - loads JSON, applies param overrides\n  - `_load_bp_template()` (line 194-218) - loads BP JSON if exists\n  - `_build_wwise_layer()` (line 221-260) - executes or plans Wwise\n  - `_build_metasounds_layer()` (line 296-355) - loads, validates, converts, executes MS\n  - `_build_blueprint_layer()` (line 358-371) - loads BP template (no execution)\n  - `_build_connection_map()` (line 374-405) - cross-layer wiring\n\n## Preset Support in C++ Plugin\n- Location: `/Users/radek/Documents/GIthub/UE5-WWISE/ue5_plugin/UEAudioMCP/Source/UEAudioMCP/Private/AudioMCPBuilderManager.cpp` (line 71-73)\n- CreatePresetBuilder is already implemented\n- asset_type validation includes \"Preset\" (line 30-36)\n- No dedicated preset-specific commands yet (only create_builder with asset_type=\"Preset\")\n\n## Tests\n- `/Users/radek/Documents/GIthub/UE5-WWISE/tests/test_systems.py` covers offline/wwise-only/full modes\n- No preset-specific tests yet\n",
      "type": "concept",
      "tags": [
        "concept",
        "python",
        "api",
        "UE5-WWISE",
        "MetaSounds",
        "MCP",
        "architecture",
        "exploration"
      ],
      "timestamp": "2026-02-07T09:47:42.241Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T09:47:42.241Z",
      "lastVerified": "2026-02-07T09:47:42.241Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770457665157_8gk77li6q",
      "content": "## UE5 C++ Plugin - Command Dispatch and Builder Architecture\n\n### Command Dispatch System\n**Key File**: AudioMCPCommandDispatcher.cpp (lines 1-127)\n- Dispatch flow: JSON parse → extract \"action\" field → lookup in CommandMap → post AsyncTask to GameThread → wait on FEvent (25s timeout)\n- Thread-safe via TSharedPtr heap-allocated FDispatchState struct containing Result, CompletionEvent, Handler, Params, BuilderMgr\n- SignalShutdown prevents new AsyncTasks during module shutdown (prevents deadlock)\n- All responses include echoed \"action\" field for request-response matching\n\n### Registered Commands (11 Total)\n**Module.cpp lines 64-99** - RegisterCommands():\n1. **ping** → FPingCommand\n2. **create_builder** → FCreateBuilderCommand (asset_type, name)\n3. **add_interface** → FAddInterfaceCommand (interface name)\n4. **add_graph_input** → FAddGraphInputCommand (name, type, optional default)\n5. **add_graph_output** → FAddGraphOutputCommand (name, type)\n6. **add_node** → FAddNodeCommand (id, node_type, optional position [x,y])\n7. **set_default** → FSetDefaultCommand (node_id, input, value)\n8. **connect** → FConnectCommand (from_node, from_pin, to_node, to_pin; handles __graph__ sentinel)\n9. **build_to_asset** → FBuildToAssetCommand (name, path /Game/...)\n10. **audition** → FAuditionCommand (no required params)\n11. **call_function** → FCallFunctionCommand (function, args object; allowlist protection)\n\n### Builder Command Implementations\n**BuilderCommands.cpp**:\n- **create_builder** (13-49): Calls BuilderSubsystem.CreateSourceBuilder/PatchBuilder/PresetBuilder, resets NodeHandles/GraphI/O maps\n- **add_interface** (55-73): Builder.AddInterface(FName)\n- **add_graph_input** (79-182): Builder.AddGraphInputNode(), stores OutputHandle in GraphInputOutputHandles map, applies JSON default value (numeric/bool/string)\n- **add_graph_output** (184-207): Builder.AddGraphOutputNode(), stores InputHandle in GraphOutputInputHandles map\n- **build_to_asset** (149-188): Validates path (must start /Game/, no ..), calls Builder.BuildToAsset(FName path)\n- **audition** (194-210): Calls Builder.Audition(World) after #WITH_EDITOR check\n\n### Node Registry\n**AudioMCPNodeRegistry.h** - 65+ hardcoded mappings via InitNodeTypeMap():\n- Generators: Sine, Noise, WhiteNoise, LFO, Oscillator, Saw, Square, Triangle, Pulse, WaveTable, Granulator\n- Filters: BiquadFilter, StateVariableFilter (UE::State Variable Filter::Audio), Lowpass, Highpass, Bandpass, Ladder, OnePole variants\n- Math: Gain, Multiply, Add, Subtract, Divide, Clamp, MapRange, Interpolate, SampleAndHold\n- Effects: Delay, StereoDelay, Reverb, Chorus, Phaser, Flanger\n- Dynamics: Compressor, Limiter, Gate\n- Triggers: TriggerRepeat, TriggerCounter, TriggerControl, TriggerOnThreshold, TriggerDelay, TriggerRoute\n- Conversions: BPMToSeconds, FreqToMIDI, MIDIToFreq, SemitonesToFreqMultiplier, dBToLinear, LinearToDb, FloatToAudio, AudioToFloat\n- Routing: MonoToStereo, StereoToMono, Send, Receive\n- Spatialization: ITDPanner, StereoPanner\n- Variables: Get, Set\n\n**Lookup Strategy** (BuilderManager.cpp 489-512):\n1. Direct lookup in NodeTypeMap\n2. If DisplayName contains \"::\", use as full class name directly\n3. Else error with suggestion to use ms_search_nodes\n\n### Node/Pin/Graph I/O Management\n**BuilderManager.cpp**:\n- **AddNode** (213-259): Validates NodeId (forbids __graph__ sentinel), calls ResolveNodeType, stores FMetaSoundNodeHandle in NodeHandles map, sets position\n- **SetNodeDefault** (261-319): Looks up node handle, finds input pin by name, converts JSON value to FMetasoundFrontendLiteral (number→float, bool→bool, string→string)\n- **ConnectNodes** (321-405): \n  - From side: if FromNode == \"__graph__\", lookup in GraphInputOutputHandles; else lookup NodeHandles then FindNodeOutputByName\n  - To side: if ToNode == \"__graph__\", lookup in GraphOutputInputHandles; else lookup NodeHandles then FindNodeInputByName\n  - Calls Builder.ConnectNodes(OutputHandle, InputHandle)\n\n### Blueprint Command\n**BlueprintCommands.cpp** (46-100+):\n- **call_function** security: allowlist check (PlaySound2D, SpawnSoundAtLocation, SetSoundMixClassOverride, etc.) — only audio-safe functions allowed\n- Searches: 1) UGameplayStatics.StaticClass(), 2) World, 3) PlayerController\n- Uses reflection: FindFunctionByName, ProcessEvent with params from JSON args object\n- Prevents arbitrary function execution (no QuitGame, DestroyActor, etc.)\n\n### TCP Server Architecture\n**AudioMCPTcpServer.cpp**:\n- One-at-a-time client handling on dedicated FRunnable thread\n- Message format: 4-byte big-endian uint32 length + UTF-8 JSON payload (matches Python ue5_connection.py)\n- Bound to 127.0.0.1:9877 only (localhost security)\n- 60s idle timeout to prevent zombie connections\n- RecvExact/SendExact loop until disconnect or error\n- Socket buffers: 65536 bytes\n\n### Extension Points for New Commands\nTo add new commands (e.g., graph variables, presets, graph pages, transaction listeners):\n1. Create new class in Public/Commands/ inheriting from IAudioMCPCommand\n2. Implement Execute() method returning TSharedPtr<FJsonObject>\n3. Add corresponding builder method to FAudioMCPBuilderManager if needed\n4. Register in FUEAudioMCPModule::RegisterCommands() via Dispatcher->RegisterCommand()\n\nKey data structures already available:\n- NodeHandles: TMap<FString, FMetaSoundNodeHandle> for node references\n- GraphInputOutputHandles: TMap<FString, FMetaSoundBuilderNodeOutputHandle> for graph I/O\n- ActiveBuilder: TStrongObjectPtr<UMetaSoundBuilderBase> for Builder API access",
      "type": "tip",
      "tags": [
        "tip",
        "python",
        "api",
        "ue5-plugin",
        "command-dispatch",
        "builder-api",
        "architecture"
      ],
      "timestamp": "2026-02-07T09:47:45.157Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T09:47:45.157Z",
      "lastVerified": "2026-02-07T09:47:45.157Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770465054026_5o5y3zzgp",
      "content": "Craig Owen Crossfade Tutorial - Complete Weapon Audio System Architecture\n\nTHREE LEVELS:\n1. MetaSoundSource (outer) - WaveAsset array inputs plugged from content, Source.OneShot interface\n2. Routing logic - MSP_Switch for room selection, Trigger Compare (Int32, RoomSize==0) gates outdoor tails, MSP_CrossFade for distance, Stereo Mixer (5) combines both\n3. MSP Patches (inner, reusable) - generic engines that work for any content\n\nKEY NODES (confirmed pins from screenshots):\n- Shuffle (WaveAsset:Array): Next, Shuffle, Reset Seed, In Array, Seed[-1], Auto Shuffle, Enable Shared State → On Next, On Shuffle, On Reset Seed, Value\n- Wave Player (2.0, Stereo): Play, Stop, Wave Asset, Start Time, Pitch Shift, Loop → On Play, On Finished, On Looped, Playback Time, Out Left, Out Right\n- Trigger Compare (Float): Compare, A, B, Type(Enum) → True, False\n- Trigger Compare (Int32): Compare, A, B, Type(Enum) → True, False\n- Stereo Mixer (3): In 0-2 L/R, Gain 0-2 (Lin) → Out L, Out R\n- Mid-Side Encode: In Left, In Right, Spread Amount[0.0], Equal Power → Out Mid, Out Side\n- Mid-Side Decode: In Mid, In Side, Spread Amount[0.5], Equal Power → Out Left, Out Right\n- Trigger Any (3): In 0, In 1, In 2 → Out\n\nCROSSFADE INTERNALS (22 nodes per patch):\n- Layer A: 1 gate (Less Than EndFadeOut+0.01) → Shuffle → WavePlayer → MapRange(1→0) → Mixer Gain 0\n- Layer B: 2 gates (Greater Than StartFadeIn-0.01 AND Less Than EndFadeOut+0.01) → Shuffle → WavePlayer → MapRange(0→1) × MapRange(1→0) = bell curve → Mixer Gain 1\n- Layer C: 1 gate (Greater Than StartFadeIn-0.01) → Shuffle → WavePlayer → MapRange(0→1) → Mixer Gain 2\n- Output: Stereo Mixer (3) → Output_L/R + Mid-Side Encode(0.0)→Decode(0.5)→AudioMono\n- All OnFinished → Trigger Any (3) → OnFinished\n\nPIN METADATA: Sort Order (0,5,10...) for logical grouping, Range (0-100000), Widget (Knob), Value Type (Linear)\n\nDESIGN PRINCIPLES:\n- Sounds plugged OUTSIDE (WaveAsset arrays), patches are generic engines\n- Trigger Compare gates prevent silent voice processing (optimization)\n- Safety offset ±0.01 on boundaries prevents flickering\n- Mid layer uses Multiply trick: two MapRanges × together = bell curve\n- Same patch works for guns, wind, engines, footsteps",
      "type": "concept",
      "tags": [
        "concept",
        "optimization",
        "metasounds",
        "crossfade",
        "weapon-audio",
        "craig-owen",
        "tutorial",
        "patterns",
        "nodes"
      ],
      "timestamp": "2026-02-07T11:50:54.026Z",
      "context": "From Craig Owen video tutorial on crossfade-by-parameter MetaSounds patches, analyzed via multiple UE5 editor screenshots",
      "accessCount": 1,
      "lastAccessed": "2026-02-07T11:54:06.223Z",
      "lastVerified": "2026-02-07T11:50:54.026Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770470251417_r0toyz4p4",
      "content": "TechAudioTools SFX Generator captured (2026-02-07): Added Plate Reverb node to catalogue (125 total nodes, was 124). Created sfx_generator.json MetaSounds template (full synth topology: Generator→Spectral Effects→SVF Filter→ADSR Amplifier→Parallel Send Effects) and sfx_generator_widget.json Blueprint template (Preset Widget controller: Builder init, ViewModel binding, Output Watch delegates, hierarchical randomization with lock/scope). Updated CREDITS.md with Eric Buchholz section. Key architecture: spectral effects in SERIES (WaveShaper→BitCrusher→RingMod), temporal effects in PARALLEL (Delay+Flanger+PlateReverb mixed back). SVF crossfade filter = DJ-style LP↔BP↔HP. Envelope Follower on output detects completion including effect tails. Wave Writer for capturing output to wav. Audio Buses feed mid-graph data to analyzer widgets. TechAudioTools also includes MetaSound Input Migrator and Metadata Editor tools. 21 MetaSounds + 16 Blueprint = 37 total templates.",
      "type": "concept",
      "tags": [
        "concept",
        "templates",
        "sfx-generator",
        "tech-audio-tools",
        "eric-buchholz",
        "metasounds",
        "synthesis"
      ],
      "timestamp": "2026-02-07T13:17:31.417Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T13:17:31.417Z",
      "lastVerified": "2026-02-07T13:17:31.417Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770470894916_pqe47gxyx",
      "content": "Audio-Driven Gameplay Learning Path research complete (2026-02-07). 3 courses, 12+ tutorials on Epic Dev Community. Key patterns: (1) Amplitude via Submix Envelope Following -> game parameter, (2) Frequency via Submix Spectral Analysis (FFT) -> game parameter, (3) Microphone via Audio Capture Component -> Submix -> analysis -> game event, (4) NRT via Synesthesia (LoudnessNRT/ConstantQNRT/OnsetNRT) -> timed events. UE5 equivalents: MetaSounds Envelope Follower node for amplitude, Submix spectral analysis still works, Synesthesia plugin fully available. MetaSounds does NOT have native FFT/spectral nodes. Research file: /Users/radek/Documents/GIthub/UE5-WWISE/research/research_audio_driven_gameplay.md",
      "type": "general",
      "tags": [
        "general",
        "ue5",
        "audio-analysis",
        "blueprint-nodes",
        "metasounds",
        "research",
        "audio-driven-gameplay"
      ],
      "timestamp": "2026-02-07T13:28:14.915Z",
      "context": "Research for UE5-WWISE MCP project - audio-driven gameplay patterns that could be implemented as MCP tools",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T13:28:14.915Z",
      "lastVerified": "2026-02-07T13:28:14.915Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770470912376_7mqv1yy2p",
      "content": "Researched \"Ambient and Procedural Sound Design\" Epic Dev Community learning path by Richard Stevens & Dave Raybould. Course code qR, UE 4.23-4.24, 2h16m runtime, 15 individual tutorials. Covers: area loops, source loops, one-shots (Sound Cue Random+Delay+Loop), 3 occlusion methods (fake switching, ambient zones, raycasting), procedural randomization/modulation/layering, Blueprint audio systems (SpawnSoundAtLocation, AudioComponent control, Spline movement). Key UE5 migration: Sound Cues -> MetaSounds for procedural audio, Audio Volumes -> Audio Gameplay Volumes (5.1+), Soundscape plugin for procedural ambient. Same authors offer UE5 follow-up \"MetaSounds & More\" courses (Foundation + Control & Communication, 7+ hours, $230 each). Full research at research/research_ambient_procedural_sound_design.md",
      "type": "general",
      "tags": [
        "general",
        "ue5",
        "audio",
        "research",
        "epic-dev-community",
        "ambient",
        "procedural",
        "sound-design",
        "metasounds",
        "blueprints",
        "stevens-raybould"
      ],
      "timestamp": "2026-02-07T13:28:32.376Z",
      "context": "Research task for UE5-WWISE project, cataloguing Epic learning paths for game audio",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T13:28:32.376Z",
      "lastVerified": "2026-02-07T13:28:32.376Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770471047280_w5qgz0o63",
      "content": "Quartz Music System research completed (2026-02-07). Key findings:\n- Course by Richard Stevens on Epic Dev Community: 14 tutorials covering looping music, playlists, one-shots, core Quartz, layer mixing (direct/timelines/curves), arrangement switching, quantized transitions, stingers, tempo changes, advanced Quartz\n- Course URL: https://dev.epicgames.com/community/learning/courses/XAw/unreal-engine-quartz-music-system\n- UE 4.27 project on Fab (free), all concepts transfer directly to UE5\n- Core API: UQuartzSubsystem -> CreateNewClock -> UQuartzClockHandle -> PlayQuantized/SubscribeToQuantizationEvent\n- Key struct: FQuartzQuantizationBoundary (Quantization type + Multiplier + CountingReferencePoint)\n- EQuartzCommandQuantization enum: Bar, Beat, WholeNote, HalfNote, QuarterNote, EighthNote, SixteenthNote, ThirtySecondNote, plus dotted/triplet variants\n- Quartz API is STABLE from UE 4.26 through UE 5.7 - no breaking changes\n- UE5 adds MetaSounds integration (triggers driven by Quartz clock) and Harmonix Plugin (UE 5.4+, MIDI sequencing)\n- Above Noise Studios has excellent UE5 vertical remixing tutorial with GitHub project\n- Research file: /Users/radek/Documents/GIthub/UE5-WWISE/research/research_quartz_music_system.md\n- Implications for MCP: need Quartz clock tools in C++ plugin + Blueprint layer, maps to WHEN layer in architecture",
      "type": "concept",
      "tags": [
        "concept",
        "api",
        "quartz",
        "research",
        "ue5",
        "music-system",
        "blueprint"
      ],
      "timestamp": "2026-02-07T13:30:47.280Z",
      "context": "UE5-WWISE project research on Quartz Music System for dynamic/interactive music",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T13:30:47.280Z",
      "lastVerified": "2026-02-07T13:30:47.280Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770473626141_trwk184bt",
      "content": "Ambient & Procedural Sound Design extraction complete (2026-02-07). 5 new Blueprint templates from Stevens & Raybould UE 4.23 project at \"/Volumes/Koshi_T7 1/UN5.3/AmbientandProceduralSound\". Templates: ambient_spline_movement (Timeline→SplineComponent→SetRelativeLocation), ambient_height_wind (SphereOverlap→MapRangeClamped→VolumeMultiplier, creak threshold at 0.8), ambient_weighted_trigger (RandomBoolWithWeight probability gate), player_oriented_sound (Forward/Right/Up vectors + RandomFloatInRange → SpawnSoundAtLocation), audio_visualiser (BP_GetAttenuationSettingsToApply → spawn debug spheres). Sound Class hierarchy: Master→Area_Loops+Source_Loops+One_Shots+Footsteps+Foley+Night_Day+Dialogue. All UE 4.23 node names — may need updating with 20K node database. 42 total templates (21 MS + 21 BP). 243 tests passing.",
      "type": "troubleshooting",
      "tags": [
        "troubleshooting",
        "database",
        "templates",
        "ambient",
        "procedural",
        "stevens-raybould",
        "ue4",
        "extraction"
      ],
      "timestamp": "2026-02-07T14:13:46.141Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T14:13:46.141Z",
      "lastVerified": "2026-02-07T14:13:46.141Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770478466721_fdco4ciyl",
      "content": "MetaSounds Pin/Node Name Changes Required\n\nAll references found in 22 JSON templates under /Users/radek/Documents/GIthub/UE5-WWISE/src/ue_audio_mcp/templates/metasounds/\n\nOLD PIN NAMES TO UPDATE:\n- WaveAsset → Wave Asset (in \"to_pin\" connections to wave_player input)\n- PitchShift → Pitch Shift (in \"to_pin\" connections to wave_player input)  \n- StartTime → Start Time (in wave_player defaults)\n- LoopStart → Loop Start (in wave_player defaults)\n- LoopDuration → Loop Duration (in wave_player defaults)\n- OnFinished → On Finished (output pin from Wave Player)\n- OnLooped → On Looped (output pin from Wave Player)\n- Array → In Array (input to Array Random Get / Random Get)\n- Trigger → Next (input to Array Random Get / Random Get)\n- NoRepeat → No Repeats (default in Array Random Get / Random Get)\n- Audio L → Out Left (output from Stereo Mixer when connected to __graph__)\n- Audio R → Out Right (output from Stereo Mixer when connected to __graph__)\n\nOLD NODE TYPES:\n- \"Array Random Get\" → \"Random Get (WaveAsset:Array)\" or similar pattern\n- Output \"Trigger\" on Array Random Get → \"On Next\"\n\nKEY FINDINGS:\n1. random_playback.json already uses correct NEW names (On Next, In Array, Wave Asset, No Repeats, On Finished)\n2. Older templates use OLD names consistently\n3. Crossfade nodes Output_L/Output_R are NOT changed (keep as-is) - different pin naming convention\n4. Index pin only appears in 2 locations (sound_pad.json, footsteps.json) but NOT being changed by user request\n5. Internal node output pins like \"Audio\", \"Out\", \"Value\" keep their current names\n6. Graph-level output pins vary (Out Left, Out Right, Out Mono, Out Stereo L, etc.) - THESE ARE NOT BEING CHANGED\n\nFiles affected: 22 total templates, 18+ have at least one old name to update",
      "type": "concept",
      "tags": [
        "concept",
        "pin-names",
        "metasounds",
        "wave-player",
        "random-get",
        "templates",
        "wave-asset",
        "pitch-shift"
      ],
      "timestamp": "2026-02-07T15:34:26.721Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T15:34:26.721Z",
      "lastVerified": "2026-02-07T15:34:26.721Z",
      "status": "fresh"
    },
    {
      "id": "mem_1770506732556_bzfia470n",
      "content": "## Wwise MCP Architecture - Complete Exploration Results\n\n### Connection Layer (connection.py)\n- **WwiseConnection singleton class**: manages WebSocket connection to WAAPI\n- Uses official `waapi-client` library (WaapiClient wrapper)\n- Default URL: `ws://127.0.0.1:8080/waapi`\n- Core methods: connect(), disconnect(), is_connected(), call(uri, args, options)\n- Single global instance via get_wwise_connection() singleton function\n- Error handling: RuntimeError if not connected before calling call()\n\n### Helper Utilities (tools/utils.py)\n- `_ok(data)`: Returns JSON string with status=\"ok\", strips any 'status' key from data to prevent overwrites\n- `_error(message)`: Returns JSON string with status=\"error\" + message\n- All tools return JSON strings, not dicts\n- Pattern: parse result with json.loads() in tests/clients\n\n### Template Tools Architecture (tools/templates.py)\n**5 Complete Template Functions:**\n\n1. **template_gunshot(weapon_name, num_variations, pitch_randomization)**\n   - Creates RandomSequenceContainer + N Sound children\n   - Sets PitchModMin/PitchModMax on each Sound\n   - Creates Play Event targeting container\n   - Returns: container_id, sound_ids[], event_id\n\n2. **template_footsteps(surface_types JSON, with_switch_group bool)**\n   - Optional SwitchGroup creation with Switch values per surface\n   - Creates SwitchContainer with reference to SwitchGroup\n   - Per-surface RandomSequenceContainers with assignments\n   - Play Event targeting container\n\n3. **template_ambient(layer_names JSON, rtpc_parameter_name)**\n   - Creates GameParameter (RTPC)\n   - Creates BlendContainer with looped Sound children\n   - Each Sound has IsLoopingEnabled=True, IsLoopingInfinite=True\n   - Play Event\n\n4. **template_ui_sound(sound_name, bus_path)**\n   - Creates UI ActorMixer container\n   - Single Sound child\n   - Bus routing via setReference (OutputBus)\n   - Play Event\n\n5. **template_weather_states(weather_states JSON)**\n   - Creates StateGroup with State values\n   - SwitchContainer with StateGroup reference\n   - Per-state Sound children with looping\n   - Assignments via addAssignment\n   - Play Event\n\n**Common Undo Pattern:**\n- All templates wrap operations: _begin_undo() → operations → _end_undo()\n- On exception: _cancel_undo() called\n- Undo label set from conn._undo_label = label\n- WAAPI calls: ak.wwise.core.undo.beginGroup, endGroup, cancelGroup\n\n**Helper Functions:**\n- _create(conn, parent, obj_type, name): Creates object with onNameConflict=\"merge\"\n- _set_prop(conn, obj_id, prop, value): Sets single property\n- _create_event(conn, name, target_id, action): Creates Event with Action child using EVENT_ACTION_TYPES lookup\n\n### Core Tools (tools/core.py)\n1. **wwise_connect(url)**: Connect to WAAPI, returns version info\n2. **wwise_get_info()**: Get active project info\n3. **wwise_query(waql, return_fields JSON)**: Execute WAQL queries\n4. **wwise_save()**: Save project\n5. **execute_waapi(uri, args_json, options_json)**: Raw escape hatch for any WAAPI call\n\n### Object CRUD Tools (tools/objects.py)\n1. **wwise_create_object(parent_path, object_type, name, on_conflict)**: \n   - Validates type against OBJECT_TYPES set\n   - Validates on_conflict against NAME_CONFLICT_MODES\n   - Parent paths use backslashes: `\\\\Actor-Mixer Hierarchy\\\\Default Work Unit`\n\n2. **wwise_set_property(object_path, property_name, value)**:\n   - Parses value as JSON, falls back to string\n   - Logs warning for unknown properties (but passes through)\n\n3. **wwise_set_reference(object_path, reference, value)**:\n   - References: OutputBus, Attenuation, SwitchGroupOrStateGroup, Conversion, Effect0-3\n\n4. **wwise_import_audio(audio_files JSON, import_operation, language)**:\n   - Batch limit: 100 items max\n   - Each entry: {\"audioFile\": path, \"objectPath\": hierarchy_path}\n   - Operations: createNew, useExisting, replaceExisting\n\n### Event & Mixing Tools (tools/events.py)\n1. **wwise_create_event(name, target_path, action_type, event_parent)**:\n   - Action types: Play(1), Stop(2), StopAll(3), Pause(4), Resume(5), etc.\n   - Creates Event with Action child using @ActionType integer mapping\n\n2. **wwise_create_game_parameter(name, min_value, max_value, default_value)**:\n   - Creates GameParameter then setProperty for RangeMin, RangeMax, InitialValue\n\n3. **wwise_assign_switch(switch_container_path, child_path, switch_value)**:\n   - Calls ak.wwise.core.switchContainer.addAssignment\n\n4. **wwise_set_attenuation(name, curve_type, curve_points JSON)**:\n   - Creates Attenuation ShareSet\n   - Calls setAttenuationCurve with points array\n   - Curve types: VolumeDryUsage, LowPassFilterUsage, HighPassFilterUsage, etc.\n   - Points: {x, y, shape}\n\n### Preview Tools (tools/preview.py)\n1. **wwise_preview(object_path, action=\"play\")**:\n   - Actions: play, stop, pause\n   - Stop: gets transport list, filters by object_path, destroys each transport\n   - Play/Pause: creates transport, executes action\n\n2. **wwise_generate_banks(bank_names JSON)**:\n   - Calls ak.wwise.core.soundbank.generate with bank list\n\n### Knowledge Base (knowledge/wwise_types.py)\n**Static dictionaries:**\n- OBJECT_TYPES: 19 types (Sound, RandomSequenceContainer, SwitchContainer, etc.)\n- WWISE_TYPE_DESCRIPTIONS: Human descriptions\n- COMMON_PROPERTIES: 25+ property names (Volume, Pitch, Lowpass, IsLoopingEnabled, etc.)\n- COMMON_REFERENCES: 8 reference types\n- DEFAULT_PATHS: Hierarchy paths (actor_mixer, events, switches, states, game_parameters, triggers, soundbanks, master_bus, attenuations)\n- EVENT_ACTION_TYPES: 18 integer mappings\n- NAME_CONFLICT_MODES: merge, rename, replace, fail\n- IMPORT_OPERATIONS: createNew, useExisting, replaceExisting\n- CURVE_TYPES: 7 attenuation curve types\n- CURVE_SHAPES: 8 point shapes (Linear, Log1-3, SCurve, Exp1-3, Constant)\n- TRANSPORT_ACTIONS: play, stop, pause\n\n### MCP Server Registration (server.py)\n- FastMCP instance created with name=\"ue-audio-mcp\"\n- Tools registered via @mcp.tool() decorators on functions\n- Tools imported AFTER mcp object defined (order matters)\n- Lifespan context manager tries connecting to Wwise/UE5 on startup, warns if unavailable\n- Tool modules: core, objects, events, preview, templates, metasounds, ms_graph, ue5_core, ms_builder, blueprints, variables, presets, systems\n\n### Test Fixtures & Mocking (conftest.py)\n- **MockWaapiClient**: Records calls, returns pre-programmed responses\n- **wwise_conn fixture**: Injects MockWaapiClient into WwiseConnection singleton\n- **MockUE5Plugin**: Mimics UE5 C++ TCP server\n- **Test Pattern**: _setup_mock() helpers for template tests, call counting, _parse(json_str) helpers\n\n### Call Pattern Examples\n```python\n# Create object with undo\n_begin_undo(conn, \"Template: Gunshot\")\ncontainer = _create(conn, parent, \"RandomSequenceContainer\", f\"Gunshot_{weapon_name}\")\ncid = container[\"id\"]\n_set_prop(conn, cid, \"RandomOrSequence\", 0)\n_end_undo(conn)\n\n# WAAPI calls: 3-part structure\nconn.call(\"ak.wwise.core.object.create\", args={...}, options=None)\nconn.call(\"ak.wwise.core.object.setProperty\", args={...}, options=None)\nconn.call(\"ak.wwise.core.switchContainer.addAssignment\", args={...}, options=None)\n```\n\n### Error Handling Pattern\n- Input validation first (JSON parse, type checks, range checks)\n- Return _error() early on validation failures\n- Connect check (is_connected()) for graceful degradation\n- Exception handling in try-except, return _error(str(e))\n- Status key never returned from WAAPI data (stripped in _ok())\n",
      "type": "warning",
      "tags": [
        "warning",
        "python",
        "wwise",
        "waapi",
        "architecture",
        "implementation",
        "mcp-server"
      ],
      "timestamp": "2026-02-07T23:25:32.556Z",
      "accessCount": 0,
      "lastAccessed": "2026-02-07T23:25:32.556Z",
      "lastVerified": "2026-02-07T23:25:32.556Z",
      "status": "fresh"
    }
  ],
  "lastUpdated": "2026-02-07T23:25:32.556Z"
}